1.计算机系统概述
## 1.1 计算机系统层次结构
### 1.1.1 计算机系统的大致组成
- 计算机系统
  - 中央处理器 (CPU)
    - 控制器 (CU)
    - 运算器 (ALU)
  - 存储器
    - 主存储器 (主存, RAM)
    - 辅助存储器（外存）
      - 硬盘驱动器 (Hard Disk Drive)
      - 固态硬盘 (Solid State Drive)
      - 光盘驱动器 (CD/DVD Drive)
  - I/O设备
  - 总线 (Bus)
    - 数据总线 (Data Bus)
    - 地址总线 (Address Bus)
    - 控制总线 (Control Bus)
> 组成原理中主机的定义一般只包含CPU和主存，其余部分称为外设。上面呈现的是计算机硬件部分
### 1.1.2 计算机硬件
1. 冯.诺依曼机基本思想
    冯.诺依曼提出了==存储程序==的概念，其基本思想是：将事先编制好的程序和原始数据送入主存后才能执行，一旦程序被启动执行，就无需操作人员干预，计算机自动逐条执行指令，直至程序执行结束。
2. 计算机的功能部件
- 输入设备
- 输出设备
- 存储器（现代计算机的核心）
  - 主存储器（内存储器）：存储体存放二进制信息，地址寄存器（MAR）存放访存地址，经过地址译码后找到对应存储单元。数据寄存器（MDR）用于暂存要从存储器中读或写的信息。时序控制逻辑用于产生存储器操作所需的各种信号。
    - MAR用于寻址，其位数对应存储单元个数。==MAR长度与程序计数器PC一致==
    - MDR用于暂存数据，==MDR位数与机器字长一致==
  > MAR和MDR虽然属于存储器，但现代计算机已经将这两个寄存器集成在CPU中

  - 辅助存储器（外存储器）：如固态硬盘，机械硬盘等。
- 运算器
    运算器的核心是算数逻辑单元（Arithmetic and Logical Unit,ALU）。运算器包含若干通用寄存器，用于暂存操作数和中间结果，如==累加器（ACC）==；==程序状态字寄存器（PSW），也称标志寄存器==；乘商寄存器（MQ）；操作数寄存器（X）；变址寄存器（IX）；基址（BR）寄存器等。
- 控制器
    控制器是计算机的指挥中心，由其控制各部件自动协调的进行工作。控制器由程序计数器（PC）；指令寄存器（IR）和控制单元（CU）组成。
    PC用来存放当前欲执行指令的地址（准确来说指向要执行的下一条指令的地址），具有自动加“1”的功能（1指的是跳转到下一条要执行的指令的地址），它与主存的MAR直接有一条直接通路。
    IR用来存放当前的指令，其内容来自主存的MDR。指令中的操作码OP(IR)送至CU，用以生成分析指令并发出各种微操作命令序列；而地址码Ad(IR)送往MAR，用以取操作数。

下图为冯.诺依曼结构的模型机。CPU包含ALU；通用寄存器组GPRs；标志寄存器；控制器；指令寄存器IR；程序计数器PC；存储器地址寄存器MAR；存储器数据寄存器MDR。同中从控制器发出的虚线为控制信号，实线表示的是各部件之间的总线，用于数据传输。
![Screenshot_2023-07-21-16-23-22-016_com.newskyer.draw.png](../_resources/Screenshot_2023-07-21-16-23-22-016_com.newskyer.dr.png)
### 1.1.2 计算机软件
1. 系统软件和应用软件
    软件按其功能分类，可分为系统软件和应用软件。
  - 系统软件（比如操作系统，数据库管理系统等）是一组保证计算机系统高效；真确运行的基础软件，通常作为系统资源提供给用户使用，==是最接近硬件的软件==。
  - 应用软件是指用户为解决某个应用领域中的各类问题而编制的程序，如各种科学计算类程序等等。
2. 三个级别的语言
  - 机器语言。又称二进制代码语言，机器语言是计算机唯一可以直接识别和执行的语言。
  - 汇编语言。使用汇编语言用英文单词或其缩写代替二进制的指令代码，更容易为人们记忆和理解。使用汇编语言编辑的程序，必须经过一个称为汇编程序的系统软件的翻译，将其转换为机器语言程序后，才能在计算机的硬件系统上执行。
  - 高级语言。高级语言（如C，C++，Java，Pyhton等）通常需要经过编译程序编译成汇编语言程序，然后经过汇编操作得到机器语言程序，或直接由高级语言程序直接翻译成机器语言程序。

将高级语言程序转换为机器语言程序的软件系统称为翻译程序，翻译程序有以下三类：
- 汇编程序（汇编器）。将汇编语言程序翻译成机器语言程序。
- 编译程序（编译器）。将高级语言程序翻译成汇编语言或机器语言。
> 编译型语言：如C，C++
- 解释程序（解释器）。将源程序中的语句按执行顺序逐条翻译成机器指令并立即执行。
> 解释型语言：如Python

3. 软件和硬件的逻辑功能等价性
其实就是说相同的功能既可以由硬件来实现，也可以由软件来实现，这两种方法在功能上完全等价，不同的只是执行的效率不同，一般来说硬件实现功能效率更高。
### 1.1.3 计算机系统的工作原理
1.“存储方式”的工作方式
“存储方式”的工作方式规定，程序执行前，需要将程序所含的指令和数据送入主存，一旦程序被启动运行，就无须操作人员的干预，自动逐条完成指令的取出和执行任务。
2. 从源程序到可执行文件
以$UNIX$系统中的GCC编译程序为例，读取源程序文件`hello.c`，将其翻译成一个可执行目标文件`hello`，整个翻译过程可分4个阶段完成，如下所示：
![Screenshot_2023-07-25-15-24-14-339_com.newskyer.draw.png](../_resources/Screenshot_2023-07-25-15-24-14-339_com.newskyer.dr.png)
- 预处理阶段：预处理器(cpp)对源程序中的头文件进行处理
- 编译阶段：编译器(cll)对预处理后的源程序进行编译，汇编语言源程序中的每条语句都以一种文本格式描述了一条低级机器语言指令
- 汇编阶段：汇编器(as)将`hello.s`翻译成机器语言指令，把这些指令打包成一个称为可重定位目标文件的`hello.o`，其是一种二进制文件。
- 链接阶段：链接器(ld)将多个重定位目标文件和标准库函数合并为一个可执行文件，或简称可执行文件。

3. 指令执行过程的描述
可执行文件代码段是由一条一条机器指令构成的，指令是用0和1表示的一串0/1序列，用来指示CPU完成一个特定的==原子操作==。例如，取数指令从存储单元中取出一个数据送到CPU的寄存器中，存数指令将CPU寄存器的内容写入一个存储单元，ALU指令将两个寄存器的内容进行某种算术或逻辑运算后送到一个CPU寄存器中，等等。

## 1.2 计算机的性能指标
### 1.字长
指令字长：一个指令字中包含的二进制代码的位数
存储字长：一个存储单元存储的二进制代码的位数
机器字长通常是指CPU内部用于整数运算的数据通路的宽度，因此字长等于CPU内部用于整数运算的运算器位数和通用寄存器宽度。
### 2.数据通路带宽
数据通路带宽是指数据总线一次所能并行传送信息的位数，这里所说的数据通路宽度是指==外部总线的宽度==，其与CPU内部总线宽度有可能不同。
### ==3.主存容量==
主存容量是指主存储器所能存储信息的最大容量，通常以字节来衡量，也可以用字数×字长（如$512K×16$位）来表示存储容量。其中，MAR的位数反应了存储单元的个数，MDR的位数反映了存储单元的字长。例如，MAR为$16$位，表示$2^{16}=65536=64K$，即此存储体内有$65536$个存储单元，若MDR为$32$位，则表示存储容量为$64K \times 32位$或者$64K \times 4B$。
### 4.运算速度
（1）吞吐量和响应时间。
- 吞吐量。指系统在单位时间内处理请求的数量，它主要取决于主存的存储周期。
- 响应时间。指从用户向计算机发送一个请求，到系统对该请求做出响应并获得所需结果的时间。通常包含CPU时间（运行一个程序所花费的时间）与等待时间（用于磁盘访问，存储器访问，I/O操作，操作系统开销等时间）。

（2）==主频和CPU时钟周期==
- CPU时钟周期。通常为节拍脉冲或$T$周期，即==主频的倒数==，它是CPU中最小的时间单位，执行指令的每个动作至少需要1个时钟周期。
- 主频（CPU时钟频率）。机器内部主时钟的频率，是衡量机器速度的重要参数。对于同一型号的计算机，其主频越高，完成指令的一个执行步骤所用的时间越短，执行指令的速度越快。
> CPU时钟周期=1/主频，主频通常以Hz(赫兹)为单位，1Hz表示每秒1次。

（3）==CPI（Cycle Per Instruction）==，即执行一条指令所需的时钟周期数。
    不同指令的时钟周数可能不同，因此对于一个程序或一台机器，其CPI指该程序或该指令集中的所有指令执行所需的平均时钟周期数，此时CPI为平均值。
（4）==CPU执行时间==，即执行一个程序所花费的时间
$$
CPU执行时间=CPU时钟周期/主频=(指令条数 \times CPI)/主频
$$
上式表明，CPU的性能（CPU执行时间）取决于三个要素：1.主频（时钟频率）2.每条指令执行所用的时钟周期数（CPI）3.指令条数
（5）==MIPS(Million Instructions Per Second)==，即每秒执行多少==百万条==指令。
$$
MIPS=指令条数/(执行时间 \times 10^6)=主频/(CPI \times 10^6)
$$
（6）==MFLOPS;GFLOPS;TFLOPS;PFLOPS;EFLOPS;ZFLOPS==
- MFLOPS，即每秒执行多少==百万==次浮点运算。
$MFLOPS=浮点操作次数/(执行时间 \times 10^6)$
- GFLOPS，即每秒执行多少==十亿==次浮点运算。
$GFLOPS=浮点操作次数/(执行时间 \times 10^9)$
- TFLOPS，即每秒执行多少==万亿==次浮点运算。
$TFLOPS=浮点操作次数/(执行时间 \times 10^{12})$
- 此外，还有$PFLOPS=浮点操作次数/(执行时间 \times 10^{15})$，$EFLOPS=浮点操作次数/(执行时间 \times 10^{18})$，$ZFLOPS=浮点操作次数/(执行时间 \times 10^{21})$

> 计算机性能指标这部分几乎年年都有一个小题，应重视上面高亮的有关性能指标的计算公式

> 在CS领域中，透明指的是不可见，站在某类用户的角度，若感觉不到某个事物或属性的存在，即“看”不到某个事物或属性，则称为“对该用户而言，某个事物或属性是透明的”。这与日常生活中的透明（公开，看得见）概念正好相反。

# 2.数据的表示和运算
## 2.1 数制与编码
### 2.1.1 进制计数制及其相互转换
主要注意十进制小数转换为任意小数，整数部分一般采用除基取余法，小数部分用乘基取整法，下面给出了一个十进制小数转二进制的过程。
> 对于二进制与十进制直接的互相转换，更快的方法是背2的常见次幂然后开凑

![Screenshot_2023-07-25-16-55-35-915_com.newskyer.draw.png](../_resources/Screenshot_2023-07-25-16-55-35-915_com.newskyer.dr.png)
> 注意：任意一个整数都可以用二进制表示，但并不是每个十进制小数都可以准确的用二进制表示，比如0.3，无论经过多少次乘二取整转换都无法得到精确的结果，但任意一个二进制小数都可以用十进制小数表示。

### 2.1.2 定点数的编码表示
根据小数点的位置是否固定，在计算机中有两种数据格式：定点表示和浮点表示。在现代计算机中，通常用定点补码整数表示整数，用定点原码小数表示浮点数的尾数部分，用移码表示浮点数的阶码部分。
### *==原码；补码；反码；移码==
- 原码
正数的原码是其本身，负数的原码是其符号位取反，其余不变，例如（机器字长为8位）：
$$
if \quad x_1=+1110 \quad :[x_1]_原=0,0001110 \\
if \quad x_2=-1110 \quad :[x_2]_原=1,0001110
$$
若机器字长为$n+1$，则带符号整数原码的表示范围为$-(2^n-1) \leq x \leq 2^n-1$（关于原点对称）
>带符号小数原码的表示范围为：$-(1-2^{-n}) \leq x \leq 1-2^{-n}$
>真值0的原码表示有正0和负0两种形式，即$[+0]_原=00000$和$[-0]_原=10000$
- 补码
正数的补码是其本身，负数的补码是符号位不变（取1），反码加1，即“原码各位取反，末位加1”，负数补码转换为真值，同样符号位不变，数值部分各位由补码“各位取反，末位加1”。
这里有一种更快速的转换方法：从右往左找到第一个1，这个1左边的所有非符号位一并按位取反，右边保持不变。例如：
$$
if \quad x_1=+1010 \quad :[x_1]_补=0,0001010 \\
if \quad x_2=-1101 \quad :[x_2]_补=1,1110011
$$
若机器字长为$n+1$，则带符号整数补码的表示范围为$-2^n \leq x \leq 2^n-1$（比原码多表示$-2^n$）
>带符号小数补码的表示范围为$-1 \leq x \leq 1-2^{-n}$
>0的补码表示是唯一的，即$[+0]_补=[-0]_补=0.0000$。整数补码比原码多表示一个“$-2^n$”，小数补码比原码多表示一个“$-1$”

上面的快速方法可以扩展到$[B]_补$与$[-B]_补$的相互转换：
正常的操作是全部位（包括符号位）按位取反，末位加一。
快速的转换方法是：从右往左找到第一个1，左边（包括符号位）全部按位取反，右边不变。
- 反码
正数的反码是其本身，负数的反码是除符号位外，各位取反。
带符号反码整数表示的范围与原码一致
- 移码
移码通常用来表示浮点数的阶码，==它只能表示整数==
移码的定义是在真值X上加上一个常数偏置，通常这个数取$2^n$。
当偏置值取$2^n$时，移码就是在补码的基础上将符号位进行取反。
>注意：偏置值不为$2^n$时这条规则失效，比如IEEE中的移码定义偏置值不是$2^n$

带符号移码整数能表示的范围与补码一致，均为$-2^n \leq x \leq 2^n-1$。
移码具有以下特点：
1.移码中0的表示唯一，$[+0]_移=[-0]_移=10000000$
2.移码全0时，对应真值的最小值$-2^n$；移码全1时，对应真值的最大值$2^n-1$
3.移码保持了数据原有的大小顺序，移码大真值大，移码小真值就小。

原码很容易判断大小，而负数的反码，补码很难直接判断大小，可采用下面的规则快速判断反码，补码大小：
==对于负数，数值部分越大，绝对值越小，真值越大（更靠近0）==
### 2.1.3 整数的表示
无符号整数和带符号整数的表示区别就在于最高位是否有符号位，对于无符号整数而言，由于省略了最高位符号位，所以在字长相同的情况下，它能表示的最大数比带符号整数能表示的大，例如：8位无符号整数的表示范围为$[0,2^8-1]$，即最大数为255，而8位有符号整数的最大数为127。
## 2.2 运算方法和运算电路
### 2.2.1 定点数的移位运算
1. 算术移位
   算术移位的对象是==有符号==，在移位的过程中==符号位==保持不变。
   对于正数，由于其原码等于反码等于补码等于真值，因此不论左移还是右移均添0。对于负数由于，原，反，补码形式各不相同，移位时添补的规则也不同，具体如下表所示：
<center>
<img src="../_resources/Screenshot_2023-07-27-17-39-08-282_com.newskyer.dr.png" alt="图片描述" width="400" height="300">
</center>
    对于带符号数，左移一位若不产生溢出，相当于乘以2（类似十进制左移一位乘10），右移一位，若不考虑舍去的末位尾数，则相当于除2。

2. 逻辑移位
逻辑移位将操作数视为无符号数。
移位规则：逻辑左移时，高位移丢，低位添0；逻辑右移时，低位移丢，高位添0。

3. 循环移位
    循环移位分为带进位标志位CF的循环移位（大循环）和不带进位标志位的循环移位（小循环），其主要区别在于循环移动时是否将标志位加入循环移位，过程如下：
![Screenshot_2023-07-28-16-06-56-942_com.newskyer.draw.png](../_resources/Screenshot_2023-07-28-16-06-56-942_com.newskyer.dr.png)

### 2.2.2 定点数的加减运算
1. 补码的加减法运算规则（手算）
    计算机内部的加减法运算都是使用同一套加法电路来实现的，对于加法而言，分别对其补码进行按位想加即可得到结果，而对于减法而言，只需要将减数的补码转化为其负数的补码，再想加即得到减法的结果即$[A-B]_补=[A]_补+[-B]_补$。
> 求$[-B]_补$可以用上面提到的快速方法

   补码运算的特点如下：
   - 按二进制运算法则运算，逢二进一
   - 若做加法，两数的补码直接想加；若做减法，则将被减数与减数的机器负数相加
   - 符号位与数值位一起参与运算，加；减运算结果的符号位也在运算中直接得出
   - 最终运算结果的高位丢弃，保留$n+1$(机器字长)位，运算结果也是补码。
2. 补码加减运算电路（机算）
![Screenshot_2023-07-28-16-43-02-922_com.newskyer.draw.png](../_resources/Screenshot_2023-07-28-16-43-02-922_com.newskyer.dr.png)
上图中，$Sub$信号量控制是否进行减法运算，当$Sub=1$ 时，多路选择器$MUX$ 1段被接通，Y各位全部取反送入加法器，而$Sub$信号传入$C_{in}$，即$C_{in}=1$，通过这种方式完成$[-Y]_补$的转换，而进行加法时，$Sub=0$，此时$C_{in}=Sub=0$，多路选择器$MUX$0段被接通，直接将操作数Y传入加法器中。
下面重点探讨上图中各标志位的生成以及有关意义:
- 零标志位$ZF=1$时当且仅当$F=0$(即全0)，表示运算结果为0，不论对于无符号运算还是有符号运算，$ZF$都有意义。
- 溢出标志位的逻辑表达式为$OF=C_n \oplus C_{n-1}$（最高位进位和次低位进位异或），其值为1时表示带符号运算时发生溢出，无符号运算时$OF$无意义。
- 符号标志位$SF$就是和F最高位，对于无符号运算$SF$无意义。
- 进位/借位标志$CF=C_{out} \oplus C_{in}$，用于判断无符号整数运算时的进位/借位，判断是否发生溢出。加法时，$C_{in}=0$，$CF$值等于进位输出$C_{out}$，$CF=1$时表示加法有进位。减法时，$C_{in}=1$，$CF$值等于进位输出$C_{out}$取反，$CF=1$时表示减法有借位。对于带符号运算，$CF$无意义。
> 上面标志位的生成是小题的常考考点，对于零标志位和符号标志位由于生成简单，考察概率较小，应重点关注溢出标志位以及进/借标志位的生成规则

1. 溢出判别方法
（1）采用单符号位
- 由于减法运算使用加法电路实现，因此无论是加法运算还是减法运算，只要参加操作的两个数符号相同，结果又与原操作数符号不同，则表示结果溢出。比如两个正数相加得到了负数说明此时发生了上溢；两个负数相加得到了正数说明此时发生了下溢；一个负数减去一个正数却得到了一个正数说明发生了下溢
- 采用单符号位时也可以通过符号位的进位$C_s$与最高位数值位进位$C_1$的异或值来判断是否发生溢出，简单来看，两个进位不同时即发生了溢出
<center>

| |符号位进位$C_s$|最高位数值位进位$C_1$|
|-|-|-|
|上溢|0|1|
|下溢|1|0|

</center>

>事实上，这种溢出判别方法与下面的双符号位类似

（2）采用双符号位
即采用两个符号位$S_{s1}S_{s2}$表示运算结果的符号已经溢出情况，各种情况如下：
- $S_{s1}S_{s2}=00$；表示结果为正数，无溢出
- $S_{s1}S_{s2}=01$；表示结果上溢（正溢）
- $S_{s1}S_{s2}=10$；表示结果下溢（负溢）
- $S_{s1}S_{s2}=11$；表示结果为负数，无溢出
双符号位溢出逻辑判断表达式为$V=S_{s1} \oplus S_{s2}$ ，$V=0$表示无溢出，$V=1$表示有溢出。

>这部分内容王道书上还详细介绍了各基本运算部件的逻辑电路和定点数的乘除运算，但由于其十分复杂，考察概率及复习性价比极低。不作重点要求，但需要知道下面的基本知识

3. 乘除法的溢出判别方法
- 乘法
    - 无符号乘法。n位乘n位，结果用2n位保存中间结果，最后结果取低n位时，==当且仅当前n位都为0时，结果不溢出==
    - 带符号乘除。n位乘n位，结果用2n位保存中间结果，最后结果取低n位时，==当且仅当前n+1位相同时，结果不溢出==
### 2.2.3 ==C语言中的整数类型以及类型转换==
> 在C语言中定点整数都是用补码形式来存储的

C语言中的关键字`unsigned`是将有符号数转化为无符号数，但物理存储上，数据的内容没有发生改变，只是改变了解释方式，比如下面这段程序：
```c
int main(){
    short x=-4321;
    unsigned short y=(unsigned short)x; //无符号数与有符号数，不改变数据内容，只改变解释方式

    // 长整数变短整数
    int a=165537,b=-34991; //int 4B ,short 2B
    short c=(short)a,d=(short)b; //长整数变短整数：高位截断，保留低位
    
    //短整数变长整数,符号扩展
    short x=-4321;
    int m=x; //负数补码高位扩1
    unsigned short n=(unsigned short)x;
    unsigned int p=n; //正数补码高位扩0
    //高位扩什么看其原码的符号位，符号位为什么即扩什么
}

```

### 2.2.4 数据的存储和排列
> 注意这里老头容易挖坑

1. 数据的“大端方式”和“小端方式”存储
    在存储数据时，数据从低位到高位可以按从左到右排列，也可以按从右到左排列。其实只需要记住：==人看的视角就是大端方式（从左到右，左高位右低位），机器看的视角就是小端方式（从右到左，左低位右高位）==
2. 数据按“边界对齐”方式存储
    假设存储字长为32位，可按字节，半字，和字寻址。对于机器字长为32位的计算机，数据以边界对齐方式存放，半字地址一定是2的整数倍，字地址一定是4的整数倍，这样无论所取数据是字节，半字还是字，均可一次取出，所存储数据不满足上述要求时，通过填充空白字节使其符合要求。这种方式属于牺牲一定的空间换取时间的做法。
    数据不按边界对齐方式存储时，可以充分利用存储空间，但半字长或字长的指令可能会存储在两个存储字中，此时需要两次访存，并且对高低字节的位置进行调整，连接之后才能得到所要的指令或数据，从而大大影响指令执行效率。
![Screenshot_2023-07-29-14-53-02-721_com.newskyer.draw.png](../_resources/Screenshot_2023-07-29-14-53-02-721_com.newskyer.dr.png)

## 2.3 浮点数的表示与运算
### 2.3.1 浮点数的表示
1. 浮点数的表示格式
通常浮点数表示为
$$
N=(-1)^S \times M \times R^E
$$
其中，S取值0或1，用来表示浮点数的符号，M是一个二进制定点小数，称为尾数，一般用定点原码或补码小数表示，E是一个二进制定点整数，称为阶码或者指数，一般用移码表示。R是基数（隐含，一般默认为2，也可以是2的整数次幂）。下面是一个32位短浮点数格式的举例：
![Screenshot_2023-07-29-15-37-46-970_com.newskyer.draw.png](../_resources/Screenshot_2023-07-29-15-37-46-970_com.newskyer.dr.png)
阶码的值反映了浮点数的小数点的实际位置；阶码的位数反映浮点数的表示范围；尾数的位数反映浮点数的精度。
> 浮点数的表示形式与十进制的科学计数法类似，可以类比学习

2. 浮点数的规格化
与十进制的科学计数法类似，浮点数的规格化是指通过调整一个非规格化浮点数的尾数和阶码的大小，使非零的浮点数在尾数的最高数位上保证是一个有效值（即非0为1）。
- 左规：当尾数的最高数位不是有效位时；需要进行左规，左规时，尾数每左移一位，阶码减一（基数为2时）。左规可能进行多次，直到最高数位非0
- 右规：当尾数的有效位进到小数点前面时，需要进行右规，将尾数右移一位，阶码加一（基数为2时）。需要右规时，只需进行一次（双符号运算发生溢出时，可以通过右规得到正确值）
用原码表示的尾数进行规格化时：
- 正数用$0.1\times \times ...\times$的形式，其最大值表示为$0.11...1$；最小值表示为$0.10...0$。尾数的表示范围为$1/2 \leq M \leq (1-2^{-n})$
- 负数用$1.1\times \times ...\times$的形式，其最大值表示为$1.10...0$；最小值表示为$1.11...1$。尾数的表示范围为$-(1-2^{-n}) M \leq -1/2$
用补码表示的尾数进行规格化时：
- 正数与原码一致
- 负数用$1.0\times \times ...\times$的形式，其最大值表示为$1.01...1$；最小值表示为$1.00...0$。尾数的表示范围为$-1 M \leq -(1/2+2^{-n})$
> 表示范围不太可能考，记住尾数用补码表示时，对负数进行规格化最高数值有效位应该为0

### 2.3.2 $IEEE754标准$
按照$IEEE754$标准，常用浮点数的格式如图所示：
![Screenshot_2023-07-29-17-01-21-012_com.newskyer.draw.png](../_resources/Screenshot_2023-07-29-17-01-21-012_com.newskyer.dr.png)
其中，$IEEE754$标准规定尾数使用==原码==表示，而阶码使用移码表示，但是需要注意$IEEE754$标准规定移码的偏置值与一般的移码偏置值不同，一般移码的偏置值为$2^{n-1}$（n为原码长度）,而$IEEE754$标准规定的移码偏置值为$2^{n-1}-1$，这就导致了计算移码时与补码仅相差符号位取反这个规律失效（但仍可以用这条规律计算），下面给出$IEEE754$标准中各浮点数的格式：
![Screenshot_2023-07-29-17-05-28-253_com.newskyer.draw.png](../_resources/Screenshot_2023-07-29-17-05-28-253_com.newskyer.dr.png)
在$IEEE754$标准中，以短浮点数为例，基数隐含为2，最高位为数符位，其后8位为阶码，用移码表示，阶码的偏置值为$2^7-1=127$；其后23位是原码表示的尾数数值位，需要注意的是，在阶码为非全0或全1时(阶码全0或全1时有其他含义)，尾数的数值位默认已经进行了规格化，即为了能使尾数多表示一位有效位，将最高数值有效位的“1”隐藏，即真实的尾数为$1.M$。因此23位尾数实际上表示了24位有效数字，例如，$(12)_{10}=(1100)_2$，将其规格化为$1.1 \times 2^3$，其中整数部分的“1”将不存储在23位尾数内。
> 短浮点数`short`和长浮点数`double`都采用隐藏尾数最高数位的方法，但需要注意这个前提是阶码为非全1或全0

下面重点探讨如何对阶码的真值与其$IEEE754$标准的移码进行互相转换:
1. 从定义上看，移码的定义即原码加上偏置值，所以真值转移码时可以直接用阶码的真值加上偏置值，再将结果用无符号整数二进制形式表示即可，比如短浮点数的移码偏置值为127，假设阶码真值为3，则移码表示的阶码为$127+3=130$，使用无符号整数二进制表示为$1000,0010$，对应16进制为$82H$，反之，将移码转化为阶码真值时，也可以先将移码看做无符号表示转换为其十进制，再减去偏置值即可得到阶码真值。
2. 从一般移码（即偏置值为$2^{n-1}$）与补码的规律推广，也可以得到$IEEE754$标准下与其补码的规律，即补码转移码在补码基础上符号位取反再减1，而移码转补码先加1再对其符号位取反即得到补码。得到补码后在还原阶码真值即可。

$IEEE754$标准单精度浮点型能表示的最小绝对值和最大绝对值：
- 最小绝对值：尾数全为0，阶码真值最小$－126$（移码范围为$[-128,127]$，全0即-127，全1即-128用作其他用途），此时整体的真值为$(1.0)_2\times2^{-126}$
- 最大绝对值：尾数全为1，阶码真值最大$127$，此时整体的真值为$(1.111...11)_2\times2^{127}$

因此在$IEEE754$标准中，只有当$1\leq E \leq 254$(即阶码不全为0或不全为1)时： 
规格化单精度浮点数：
$$
真值=(-1)^S\times1.M\times2^{E-127}
$$
规格化双精度浮点数:
$$
真值=(-1)^S\times1.M\times2^{E-1023}
$$
==当阶码E全为0或全1时的特殊用途：==
- 当阶码E全为0，尾数M不全为0时，表示非规格化小数$\pm(0.\times\times...\times)\times2^{-126}$，（其中0为隐藏位，尾数应为$0.M$，阶码固定值为－126）
> 2023 408真题
- 当阶码E全为0，尾数M全为0时，表示真值$\pm0$
- 当阶码E全为1，尾数M全为0时，表示无穷大$\pm\infty$
- 当阶码E全为1，尾树M不全为0时，表示非数值`NaN`(Not a Number)

### 2.3.3 浮点数的加减运算
浮点数的运算可以类比学习十进制的科学计数法的运算过程，具体加减运算分为以下几步：
1. 对阶
    对阶的目的是使得两个操作数的阶码相等，为此先求阶差，然后以==小阶向大阶==看齐的原则，将阶码小的尾数右移一位，阶数加1，直到阶码对齐。尾数右移可能会舍弃有效位，进而丢失精度。
2. 尾数求和
   将对阶后的尾数按定点数加减运算。运算后的尾数不一定是规格化的，因此可能需要进一步处理。
3. 规格化
   这里的规格化操作与上述浮点数规格化一致，不在赘述，主要就是左规右规保持最高数值位有效，且小数点左侧只有一位符号位(双符号表示则两位)。
4. 舍入
   在对阶和尾数右规时，可能会对尾数进行右移，这时需要对运算结果进行舍入，常见的舍入方法有：==0舍1入法==，==恒置1法==，==直接截断法==
5. 溢出判断
   在尾数规格化和尾数舍入时，可能会对阶码执行加/减运算。因此可能会造成指数溢出的问题，指数上溢抛出异常，指数下溢置0处理。
   1）右规和尾数舍入。数值很大的尾数舍入时，可能因为末位加1而发生尾数溢出，此时需要通过右规来调整尾数和阶。右阶加1可能导致阶数上溢。
   2）左规。左规减1，导致阶减少，可能导致阶数下溢。
   因此，溢出的判断主要取决于阶数是否发生溢出，尾数的溢出通常可以通过规格化消除。
> 有些题目可能会指定尾数或阶码用补码表示，通常采用双符号位，当尾数求和结果发生溢出时，双符号位表示的补码可以通过规格化处理溢出恢复正确的数值。

### 2.3.4 C语言中的浮点数类型与强制类型转换
在32位机器中，C语言中各数据类型占用空间如下：
<center>
    
| |char|short|int|long|long long|float|double|
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|                                   
|bit|8|16|32|32|64|32|64|

</center>

强制类型转换：
- `char->int->long->double`和`float/int->double`，二者从前到后范围和精度都是从小到大，转换过程不会产生损失。
- int转换为float时，虽然不会发生溢出，但int的有效数值位为31，float有效数值位为24（包含隐藏位），所以可能造成精度损失。
- double转换为float时，float表示范围更小，所以可能会发生溢出，尾数有效位数变少可能造成精度损失。
- float或double转换为int时，因为int只能表示整数，因此数据会向0方向截断，所以可能导致精度损失，此外，int表示范围更小，因此可能发生溢出。
>看强制类型转换是否发生溢出或者精度丢失主要看转换前后数据类型的表示范围以及尾数位数，表示范围由大变小可能造成溢出，尾数位数（有效位数）由大变小可能造成精度损失。反之则不会造成影响。

# 3. 存储系统
## 3.1 存储器概述
### 3.1.1 存储器分类
1. 按在计算机中的作用（层次）分类
- 主存储器（内存）
- 辅助存储器（外存）
- 高速缓冲存储器（Cache）
2. 按存储介质分类
- 磁表面存储器（磁盘，磁带）
- 磁芯存储器
- 半导体存储器（MOS型存储器）
- 光存储器（光盘）
3. 按存取方式分类
- 随机存储器（RAM）。存储器的任意一个存储单元都可以随机存储，而且存储时间与存储单元的物理位置无关。读写方便，使用灵活，主要作用主存和高速缓冲存储器。
> RAM又可以分为DRAM和SRAM，后序会详细介绍

- 只读存储器（ROM）。存储器的内容只能随机读而不能写入，信息一旦写入存储器就固定不变，即使断电，内容也不会丢失，比如集成在主板上的BIOS芯片。
> 由ROM衍生出的存储器也包含可反复重写的类型（比如固态硬盘中的闪存芯片），ROM和RAM的存取方式均为随机存取。广义上的只读存储器已可通过电擦除等方式进行写入，“只读”概念并未保留，但仍保留了其断电内容保留，随机存取特性，但其写入速度一般比读取速度慢得多。

- 串行访问存储器。对存储单元进行读/写操作时，需按其物理位置的先后进行顺序寻址，包括顺序存取存储器（如磁带）和直接存取存储器（如磁盘和光盘）

4. 按信息的可保存性分类
- 易失性存储器。如RAM，断电后，存储信息即消失。
- 非易失性存储器。如ROM，磁表面存储器和光存储器。断电后信息仍然保持。
> 如读信息时，导致原存储信息被破坏，则称破坏性读出，反之，称非破坏性读出。具有破坏性读出的存储器每次读出操作后，必须紧接一个再生操作，恢复被破坏的信息。

### 3.1.2 存储器的性能指标
1. 存储容量=存储字长×字长（如1M×8位）
2. 单位成本：每位价格=总成本/总容量
3. 存储速度：数据传输率=数据的宽度/存取周期（或称存储周期）
- ==存取时间($T_a$)==：存取时间指从启动一次存储器操作到完成该操作所经历的时间，分为读出时间和写入时间。
- ==存取周期($T_m$)==：存取周期又称读写周期或访问周期。它是指连续两次独立访问存储器操作（读或写操作）中间所需的最小时间间隔，一般由存取时间和恢复时间组成
- 主存带宽($B_m$)：主存带宽又称数据传输率，即每秒从主存进出信息的最大数量，单位为字/秒，字节/秒或位/秒。
存取时间并不等于存取周期，通常来说，存取周期大于存取时间，因为对于任意存储器，进行读写操作后需要一段恢复内部状态的恢复时间。其关系如下所示：
![Screenshot_2023-07-31-15-34-48-923_com.newskyer.draw.png](../_resources/Screenshot_2023-07-31-15-34-48-923_com.newskyer.dr.png)
### 3.1.3 多级层次的存储系统
具体层次结构将会在后面详细介绍，记住下图即可：
![Screenshot_2023-07-31-15-37-38-589_com.newskyer.draw.png](../_resources/Screenshot_2023-07-31-15-37-38-589_com.newskyer.dr.png)
> 注意：在Cache－主存和主存－辅存层中，上一层的内容都只是下一层内容中的副本，也即在Cache中存在的信息在主存中也一定存在

## 3.2 主存储器
### 3.2.1 SRAM芯片和DRAM芯片
1. SRAM的工作原理
   SRAM的存储元是双稳态触发器（六晶体管MOS）来存储信息，因此信息被读出后，它保持其原状态不需要再生（非破坏性读出）
   SARM的存取速度快，但集成度低，成本较高，一般用于==高速缓冲存储器==
2. DRAM的工作原理
   与SRAM的存储元不同，DRAM的存储元利用电路中的栅极电容上的电荷存储信息，信息读出后，信息被破坏（破坏性读出），但DRAM的集成度高，造价低，相应的存取速度比SRAM慢，一般用于大容量的主存芯片。
   DRAM需要每个一段时间（通常间隔为2ms）进行刷新，每次刷新一行存储单元，常见的刷新方式有3种：
- 集中刷新：即在一个刷新周期内，利用一段固定的时间，依次对所有存储器的所有行进行逐一刷新，在此刷新期间停止一切读写操着，称为“死时间”，又称访存“死区”。优点是读写操作不受刷新影响；缺点是在死区内无法访存。
- 分散刷新：把对每行的刷新分散到各个工作周期中，这样，一个存储器的系统工作周期分为两部分：前半部分用于正常读，写或保持；后半部分用于刷新，这种刷新方式增加了系统的存取周期，但==没有死区==，缺点是加长了系统的存取周期，降低整机速度。
- 异步刷新：异步刷新是前两种方式的结合，它既可以缩短“死时间”（==注意是缩短非消除==），又能充分利用最大刷新间隔为2ms的特点。具体做法是将刷新周期除以行数，得到两次刷新操作之间的时间间隔t，利用逻辑电路每隔t产生一次刷新请求。
> 刷新对CPU是透明的，即刷新不依赖于外部的访问；DRAM的刷新单位是行，由芯片内部自行产生行地址；刷新操作类似于读操作，但又有所不同。此外，刷新时不需要选片，整个存储器中的所有芯片同时被刷新

3. SRAM和DRAM的比较
![Screenshot_2023-07-31-16-31-23-607_com.newskyer.draw.png](../_resources/Screenshot_2023-07-31-16-31-23-607_com.newskyer.dr.png)
在上表中，DRAM的送行列地址分两次送其实是采用了==地址线复用技术==，即不同于SRAM行列地址同时传输，DRAM的容量较大，如果同时传输行列地址可能导致地址引脚过多，所以一般采用地址复用技术，分两次送，存储其中有行列地址缓冲器，地址线复用技术可以让==地址线，地址引脚数减半==。

### 3.2.2 只读存储器（ROM）
1. 只读存储器的特点
    ROM和RAM都是支持随机存取的存储器，其中SRAM和DRAM均为易失性半导体存储器，而ROM中一旦有信息，就不能轻易改变，即使掉电也不会消失，它在计算机系统中是“只读”的存储器。其优点是：结构简单，位密度高；具有非易失性，可靠度高。
2. ROM的类型
- 掩模式只读存储器（MROM），写入后无法改变其内容，可靠性高，集成度高，价格便宜，但灵活性差。
- 一次可编程只读存储器（PROM），允许用户利用专门的设备（编程器）写入自己的程序，一旦写入，内容就无法改变。
- 可擦除可编程只读存储器（EPROM），可以由用户利用编程器写入信息，而且可以进行多次改写，但无法取代RAM，因为编程次数有限且写入时间较长
- Flash存储器，可以进行快速的擦除和重写，价格便宜，集成度高
- 固态硬盘（Solid State Drives，SSD），基于闪存芯片的固态电子存储芯片阵列制成的硬盘，保留了Flash存储器长期保存信息，快速擦除与重写的特性。对比传统硬盘速度快，功耗低，但价格较贵。

### 3.2.3 主存储器的基本组成
存储芯片地址引脚至少有以下部分：
- 地址线 MAR位数
- 数据线 MDR位数
- 片选线 通常1位
- 读写/信号控制线 1位或2位
> 如果在DRAM中采用了地址复用技术，行列地址分两次传输，则地址引脚数可以减半

![Screenshot_2023-07-31-17-10-08-323_com.newskyer.draw.png](../_resources/Screenshot_2023-07-31-17-10-08-323_com.newskyer.dr.png)
对于存储容量常见的描述比如：$8K \times 8bit$  即  $2^{13} \times 8bit$，其中13为MAR位数，8为MDR位数
### 3.2.4 多模块存储器
多模块存储器是一种空间并行技术，利用多个结构完全相同的存储模块的并行工作来提高存储器的吞吐率。常用的有单体多字存储器和多体低位交叉存储器。
1. 单体多字存储器
    单体多字系统的特点是存储器中只有一个存储体，每个存储单元存储m个字，总线宽度也为m个字，一次并行读出m个字，地址必须顺序排列并处于同一存储单元。
    其缺点在于指令和数据在主存必须是==连续存放==的，一旦遇到转移指令，或操作数不能连续存放，这种方法的效果就不明显。
2. ==多体并行存储器==
    多体并行存储器由多体模块组成。每个模块都有相同的容量和存取速度，多体并行存储器分为高位交叉编制和低位交叉编址两种。
- 高位交叉编址（顺序方式，“多根内存条”）
    高位地址表示体号，低位表体内地址，如下所示，存储器有4个模块$M_0 \sim M_3$，每个模块有n个单元。高位交叉方式下，数据存放的方式按每块顺序存放，访问一个连续主存块时，总是在先一个模块内访问，等到这个模块访问完才转到下一个模块访问，各模块不能被并行访问，因而无法提高存储器的吞吐率。
> 模块内的地址是连续的，存取方式仍是串行存取，因此这种存储器仍然是顺序存储器

![Screenshot_2023-08-01-15-19-59-286_com.newskyer.draw.png](../_resources/Screenshot_2023-08-01-15-19-59-286_com.newskyer.dr.png)
- 低位交叉编址（交叉方式，“双通道”）
    低位地址表示体号，高位表体内地址，如下所示，每个模块按“模m”交叉编址，模块号=单元地址%m。低位交叉方式下，数据存放的方式按横向存储体间交叉存放，因此称采用此编制方式的存储器为交叉存储器，采用低位交叉编制后，可在不改变每个模块存取周期的前提下，采用流水线的方式并行存取，提高存储器带宽。
> 在408的历年真题描述中，交叉编制方式指的就是低位交叉编制

![Screenshot_2023-08-01-15-36-09-334_com.newskyer.draw.png](../_resources/Screenshot_2023-08-01-15-36-09-334_com.newskyer.dr.png)
假设模块存取一个字的存取周期为$T$，总线传送周期（也称存取时间）为$r$，为了实现流水线方式存取，存储器交叉模块数量应大于等于：
$$
m \geq T/r
$$
其中模块数量m的最佳取值应为不小于$T/r$的最大整数，这样，连续存取$m$个字所需要的总时间为：
$$
t_1=T+(m-1)r
$$
而顺序方式连续读取m个字所需的时间为$t_2=mT$。可见低位交叉存储器的带宽大大提高。

## 3.3 主存储器与CPU的连接
### 3.3.1 连接原理
- 主存储器通过数据总线，地址总线和控制总线与CPU连接
- 地址总线的位数决定了可寻址的最大内存空间
- 控制总线（读/写）指出总线周期的类型和本次I/O操作完成的时刻
<center>
<img src="../_resources/Screenshot_2023-08-01-16-08-50-111_com.newskyer.dr.png" alt="图片描述" width="400" height="300">
</center>

### 3.3.2 ==主存容量的扩展==
1. 位扩展法
    CPU的数据总线与存储芯片的数据位数不一定相等，此时必须对存储芯片扩位（即进行位扩展，用多个存储器件对字长进行扩充，增加存储字长），使其数据位数与CPU的数据线数相等。
    如下所示，用8片8K×1位的RAM芯片组成8K×8位的存储器。8片RAM芯片的地址线$A_{12} \sim A_0,\overline{CS},\overline{WE}$都分别连着一起，每片的数据线依次作为CPU数据线的一位。    
![Screenshot_2023-08-01-16-20-23-925_com.newskyer.draw.png](../_resources/Screenshot_2023-08-01-16-20-23-925_com.newskyer.dr.png)
2. 字扩展法
    字扩展是指增加存储器中字的容量，而位数不变。字扩展将芯片的地址线，数据线，读写控制线相应并联，由片选信号区分各芯片的地址范围。
    如下所示，用4片16K×8位的RAM芯片组成64K×8位的存储器。4片RAM芯片的数据线$D_0 \sim D_7$和$\overline{WE}$都分别连在一起，将$A_{15}A_{14}$用作片选信号，两位构成2/4译码器。
![Screenshot_2023-08-01-16-25-32-594_com.newskyer.draw.png](../_resources/Screenshot_2023-08-01-16-25-32-594_com.newskyer.dr.png)
3. 字位同时扩展法
    实际上，更常见的情况是存储器往往需要同时扩展字位，字位扩展是指既增加存储字的数量，又增加存储字长。
    如下所示，用8片16K×4位的RAM芯片组成64K×8位的存储器。每两片构成一组16K×8位的存储器（位扩展），4组便构成64K×8位的存储器（字扩展）。地址线$A_{15}A_{14}$经译码器得到4个片选信号。
![Screenshot_2023-08-01-16-37-07-394_com.newskyer.draw.png](../_resources/Screenshot_2023-08-01-16-37-07-394_com.newskyer.dr.png)
### 3.3.3 存储芯片的地址分配和片选
- 线选法：在上面的例子中，假设有4个芯片需要进行片选，线选法的做法是从地址总线出分出4位进行片选，哪一位为低电平（0）即选中哪一片，这样的做法不需要地址译码器，线路简单，但是地址空间不连续，选片的地址线必须分时为低电平，无法充分利用系统的存储器空间，造成地址资源浪费。
- 译码片选法：译码片选法使用除片内寻址外的高位空闲地址线通过地址译码器芯片产生片选信号。如8片8K×8位的存储芯片组成64K×8位存储器（地址线16位，数据线8位），需要产生8个片选信号，若采用线选法，则需要8为空闲地址位，无法产生8个片选信号，因此采用译码片选法，用一片74LS138（3/8译码器）作为地址译码器。
>读/写命令线的连接：CPU读/写命令线一般可直接与存储芯片的读/写控制段相连，通常高电平为读，低电平为写。有些CPU的读写信号是分开的(读为$\overline{RD}$，写为$\overline{WE}$，均为低电平有效

## 3.4 外部存储器
### 3.4.1 磁盘存储器
磁盘存储器的优点：(1)存储容量大，位价格低；(2)记录介质可重复使用；(3)记录信息可长期保存而不丢失，甚至可脱机存档；(4)非破坏性读出，读出时不需再生。缺点：存取速度慢，机械结构复杂，对工作环境要求较高。
1.磁盘存储器
（1）磁盘存储器的组成
- 磁盘存储器的组成。磁盘存储器由磁盘驱动器，磁盘控制器和盘片组成。
    - 磁盘驱动器。核心部件是磁头组件和盘片组件。
    - 磁盘控制器。磁盘存储器和主机的接口。
- 存储区域。一块硬盘含有若干记录面，每个记卤面划分为若干磁道，而每条磁道又划分为若干扇区，扇区（块）是磁盘读写的最小单位，即磁盘按块存取
    - 磁头数：即记录面数，表示硬盘共有多少个磁头，磁头用于读取/写入盘片上记录面的信息，一个记录面对应一个磁头
    - 柱面数：表示硬盘每面盘片上有多少条磁道。不同记录面的相同编号（位置）的各磁道构成一个圆柱面
    - 扇区数：表示每条磁道上有多少个扇区
（2）磁盘的性能指标
- 记录密度。通常同一个扇区不同磁道上存储的二进制位数相同，越外面（半径越大）的磁道位密度越低。
- 磁盘容量。磁盘容量分为非格式化容量和格式化容量。格式化后的容量要比非格式化容量要小。
- ==平均存取时间==。平均存取时间由寻道时间（磁头移动到目的磁道的时间），旋转延迟时间（磁头定位到要读扇区的时间）和传输时间（传输数据所花费时间）三部分构成。寻道时间和旋转延迟时间通常取==平均值==。
- 数据传输率。磁盘存储器在单位时间内向主机传送数据的字节数，称为数据传输率。若磁盘转数r转/秒，每条磁道容量为N字节，则数据传输率为$D_r=rN$。
（3）磁盘地址
假设系统中有4个驱动器，每个驱动器带一个磁盘，每个磁盘256个磁道，16个盘面，每个盘面划分为16个扇区，则每个扇区需要18位地址。如下：
<center>
    
|驱动器号(2bit)|柱面(磁道)号(8bit)|盘面号(4bit)|扇区号(4bit)|
|-----|-------|-----|-----|
</center>

>硬盘属于机械式部件，其读写操作是串行的，不可能在同一时刻既读又写，也不可能在同一时刻读两组数据或写两组数据

1. 磁盘阵列
RAID（独立冗余磁盘阵列）是指将多个独立的物理磁盘组成一个独立的逻辑盘，数据在多个物理盘上分割交叉存储，并行访问，具有更好的存储性能，可靠性和安全性。
RAID的分级如下所示。
- RAID0：无冗余和无校验的磁盘阵列
- RAID1：镜像磁盘阵列
- RAID2：采用纠错的海明码的磁盘阵列
- RAID3：位交叉奇偶校验的磁盘阵列
- RAID4：块交叉奇偶校验的磁盘阵列
- RAID5：无独立校验的奇偶校验磁盘阵列
其中，RAID0把连续多个数据块交叉存放在不同的物理磁盘扇区中，交叉并行读写，不仅扩大容量，同时提高了访存速度，但没有容错能力。
而RAID1使两个磁盘同时进行读写，互为备份，一个磁盘出现故障，可以从另一个磁盘中读出数据，但由于有一个磁盘存储的是重复信息，故而整体存储容量减半。
### 3.4.2 固态硬盘（新考点）
- 原理：基于闪存技术Flash Memory，属于电可擦除ROM，即EEPROM。
- 组成：
    - 闪存翻译层：负责翻译逻辑块号，找到对应页
    - 存储介质：多个闪存芯片（Flash Chip），每个芯片包含多个块，每个块包含多个页。
- 读写性能特性：
    - 以==页为单位读/写==,相当于磁盘的“扇区”
    - 以==块==为单位擦除，擦干净的块，其中的每页都可以写一次，读无限次
    - 支持随机访问，系统给定一个逻辑地址，闪存翻译层可通过电路迅速定位到对应物理地址
    - 读快，写慢，要写的页如果有数据，则不能写入，需要将块内存有数据的页复制到一个新（最近擦除过）的块中，再写入新的页
- 与机械硬盘相比的特点：
    - SSD读写速度快，随机访问性能高，用电路控制访问位置，机械硬盘用移动磁臂旋转磁盘控制访问位置，有寻道时间和旋转延迟
    - SSD安静无噪音，耐摔抗震，能耗低，但造价更高
    - ==SSD的一个块被擦除次数过多（重复写同一个块）可能会损坏==，而机械硬盘不会因为重复读写同一扇区而损坏。
- 磨损均衡技术，思想：将擦除均匀的分布在每个块上，以提高整体的使用寿命
    - 动态磨损均衡：写入数据时，优先选择累计擦除次数少的新闪存块
    - 静态磨损均衡：SSD监测并自动进行数据分配，迁移，让老旧的闪存块承担以读为主的任务，新的闪存块承担更多的写任务。
## 3.5 ==Cache高速缓冲存储器==
### 3.5.1 程序访问的局部性原理
程序访问的局部性原理包括==时间局部性和空间局部性==。时间局部性是指在最近的未来要用到的信息，很可能是现在正在使用的信息，因为在程序中存在循环。（可能要反复使用的指令或数据）。空间局部性是指在最近的未来要用到的信息，很可能是与现在正在使用的信息在==存储空间上是相邻的==（比如连续访问数组元素，而数组元素在内存中往往物理上相邻存放）。
### 3.5.2 Cache的基本工作原理
Cache位于存储器层次结构顶层，通常由SRAM构成。
为方便与Cache和主存间交换信息，Cache和主存都被划分为相等的块，Cache块又称Cache行，每块由若干字节组成，块的长度称为块长（或Cache行长）。Cache的容量一般远小于主存的容量，故Cache中一般只保存主存中最近CPU使用频率最高的数据的副本。
当CPU发出读请求时，若访问地址在Cache命中，则将此地址转换为Cache地址，直接在Cache中操作，不对主存进行访问；若Cache未命中，则仍需访问主存，并把次字所在的块一次性从主存调入Cache中。若此时Cache已满，则需要根据某种置换算法，用这个块置换Cache中的某个块。整个过程由硬件电路实现。
>注意：CPU与Cache之间的数据交换以字为单位，而Cache与主存之间的数据交换则以块为单位
>有些计算机中也采用指令同时访问Cache和内存的策略，此时当Cache命中时，则主存访问终止，否则访问主存并写入（置换）Cache

CPU欲访问到信息已在Cache中的比率称为Cache的名字率。设一个程序执行期间，Cache的总命中次数为$N_c$，访问主存的总次数为$N_m$，则命中率H为：
$$
H=N_c/(N_c+N_m)
$$
可见，当命中率H越接近1，访问效率越高。设$t_c$为命中Cache访问时间，$t_m$为未命中时的访问时间，$1-H$表示未命中率，则采用同时访问Cahc和主存的策略下Cache－主存系统的平均访问时间$T_a$为：
$$
T_a=Ht_c+(1-H)t_m
$$
> 若采用先访问Cache再访问主存，则时间应为$T_a=Ht_c+(1-H)(t_m+t_c)$

### 3.5.3 Cache和主存的映射方式
地址映射是指把主存地址空间映射到Cache地址空间，即把存放在主存中的信息按照某种规则装入Cache。
1. ==直接映射==
   主存中的每一块只能装入Cache的唯一位置。若这个位置已存在内容，则产生块冲突，原来的块将无条件被替换（无需使用置换算法）。直接映射实现简单，但不够灵活，这使得直接映射到块冲突概率最高，空间利用率最低。
   直接映射到关系可定义为
$$
Cache 行号=主存块号 \% Cache 总行数
$$
直接映射的地址结构为：
<center>
    
|标记tag(主存块号)|Cache行号|块(行)内地址|
|-----|-----|-----|
</center>
CPU访存过程如下所示，首先根据访存地址中间的c位，找到对应的Cache行，将对应Cache行中的标记和主存地址的高t位标记进行比较，若相等且有效位为1，则访问Cache命中，此时根据主存地址中低位的块内地址，在对应的Cache行中存取信息；若不相等或有效位为0，则未命中，此时CPU从主存读出该地址所在的一块信息置换对应Cache行中，同时将有效位置1，并将标记设置为地址中的高t位，同时将地址内容送入CPU。

![Screenshot_2023-08-02-16-24-58-160_com.newskyer.draw.png](../_resources/Screenshot_2023-08-02-16-24-58-160_com.newskyer.dr.png)
2. 全相联映射
主存中的每一块可以装入Cache中的任意位置，每行的标记用于指出该行取自主存的哪一块，所以CPU访存时需要与所有Cache行的标记进行比较。全相联映射的优点在于灵活，Cache块的冲突概率低，空间利用率高，命中率高，缺点是要比较所有的Cache行标记，比较速度慢，实现成本较高。全相联映射到地址结构为：
<center>
    
|标记tag(主存块号)|块(行)内地址|
|-----------|----|
</center>

![Screenshot_2023-08-02-16-26-45-410_com.newskyer.draw.png](../_resources/Screenshot_2023-08-02-16-26-45-410_com.newskyer.dr.png)
3. ==组相联映射==
将Cache分为Q个大小相等的组，每个主存块可以装入固定的任意一行，即组间采用直接映射，组内采用全相联映射，如下所示，它是对直接映射和全相联映射到折中方式，当Q=1时即为全相联映射，当Q=Cache行数时即为直接映射。假设每组有r个Cache行，则称其为r路组相联。下图中展示的即为二路组相联。
组相联映射的关系可以定义为：
$$
Cache 组号=主存块号 \% Cache 组数(Q)
$$
组相联映射的地址结构为：
<center>
    
|标记tag(主存块号)|组号|块(组)内地址|
|-----|-----|-----|
</center>

![Screenshot_2023-08-02-16-49-28-106_com.newskyer.draw.png](../_resources/Screenshot_2023-08-02-16-49-28-106_com.newskyer.dr.png)
CPU访存过程如下：首先根据访存地址中间的组号找到对应Cache组；将对应的Cache组中每个行的标记与主存地址的高位标记进行比较，若有一个相等且该有效位为1，则Cache命中，此时根据主存地址中的块内地址，在对应Cache行中存取信息，若都不相等或虽相等但有效位为0，则Cache未命中，此时CPU从主存中读出该地址所在的一块信息送到对应Cache组的任意一个空闲行中，将有效位置1，并设置标记，同时该地址内容送CPU。

### 3.5.4 Cache中主存块的替换算法
>可结合OS中的置换算法进行类比学习

在采用全相联映射或组相联映射方式时，从主存向Cache写一个新块，当Cache或Cache组中的空间已满时，就需要使用置换算法置换Cache行。而采用直接映射时，由于一个主存块映射到Cache的唯一行，所以如果这行已经存有数据，只能进行强制置换，无需考虑置换算法。
常用的置换算法有随机（RAND）算法，先进先出（FIFO）算法，近期最少使用（LRU）算法和最不经常使用（LFU）算法，LRU算法常考察。
- 随机算法：随机的确定替换的Cache块，实现简单，但未遵循程序访问的局部性原理，命中率较低
- 先进先出：选择最早调入的行进行调换，实现简单，但仍未遵循局部性原理，因为最早调入的主存块也可能是目前经常要使用的
- ==近期最少使用算法(LRU)==：依据程序访问的局部性原理，选择近期内长久未访问过的Cache行作为替换的行，平均命中率要比FIFO高，是堆栈类算法。
> 计算LRU算法时，可以从当前时刻往前回看，在当前的Cache中，哪个块是最久没有被访问过的，则替换这个块。
> 当集中访问的存储区超过Cache组的大小时，命中率可能变得很低，发生抖动现象。抖动现象的更多信息会在OS中详细介绍

- 最不经常使用算法：将一段时间内被访问次数最少的存储行换出，这种算法与LRU类似，但不完全相同。
### 3.5.5 Cache写策略
由于Cache中的内容是主存块的副本，当对Cache中的内容进行更新时，需要选用写操作策略使Cache内容和主存内容保持一致。此时分写命中和写不命中：
对于Cache写命中时，有两种处理方法：
- 全写法（写直通法，write-through）。当CPU对Cache写命中时，必须把数据同时写入Cache和主存。当某一块需要替换时，不必把这一块写回主存，直接置换即可，这种方式实现简单，且每次写时都保证了主存数据的准确性，但缺点是增加了访存次数，降低了Cache效率。可以采用写缓冲来缓解这个问题：在Cache和主存间加一个写缓冲，CPU同时写数据到Cache和写缓冲中，写缓冲再控制将内容写入主存。写缓冲是一个FIFO队列，写缓冲可以缓解速度不匹配的问题，但若出现频繁写，容易造成缓冲区溢出。
- 回写法（写回法，write-back）。当CPU对Cache命中时，只把数据写入Cache，而不立刻写回内存，只有当此块被置换时才写回主存，这种方式减少了访存次数，但存在数据不一致的隐患，为了实现这种方式，需要在每个Cache行设置一个修改位（脏位）。若修改位为1，则对应Cache行的块被修改过，被置换时需要写回内存，反之，则没有被修改过，置换时无需写回内存。
对于Cache写未命中时，同样有两种处理方法：
- 写分配法（write-allocate）。加载主存中的块到Cache中，然后更新这个Cache块，其试图利用空间局部性原理，但缺点是每次不命中都要从主存中调块。
- 非写分配法（non-write-allocate）。只写入内存，不进行调块到Cache。
非写分配法一般与全写法组合使用，写分配法一般和回写法组合使用。
> 现代计算机通常设置多级Cache，比如3级Cache缓存，按离CPU的远近各命名为L1 Cache,L2 Cache,L3 Cache，离CPU越远，访问速度越慢，容量越大。指令Cache与数据Cache分离一般在L1级，此时通常用写分配法和回写法合用。（稍作了解。考察概率不大）
>408的Cache小题计算中，经常要考虑每一行的Cache行长问题，每行Cache中记录了标记tag，实际的数据（每一块的实际位数），以及有效位，脏位和替换算法控制位，其中，有效位一定存在，脏位与替换位根据题目所给信息判断。（行，组号不存储，Cache的顺序物理地址隐含了行，组号）
> 在组相联映射中，m组相联表示的是将Cache分为n个大小为m的组，主存每隔n个主存块可映射到同一组，即组间直接映射，组内全相联映射。

## 3.6 ==虚拟存储器==
> 这部分属于与OS的公共考点，十分重要，在408中一般容易与前面的Cache结合考察

### 3.6.1 虚拟存储器的基本概念
虚拟存储器将主存和辅存的地址空间统一编制，形成一个庞大的地址空间，在这个空间内，用户可以自由编程，而不必在乎实际的主存容量和程序在主存中实际的存放位置。
用户编程允许设计的地址称为虚地址或逻辑地址，虚地址对应的存储空间称为虚拟空间或程序空间。实际的主存单元地址称为实地址或物理地址，实地址对应的是主存地址空间。逻辑地址要比物理地址大很多。
CPU使用逻辑地址时，由辅助硬件找出逻辑地址与物理地址之间的映射关系，并判断这个逻辑地址对应的存储单元是否已经读入主存。若已在主存中，则通过地址变换，CPU可直接访问主存的实际单元；若不在主存中，则把包含这个字的一页或一段调入主存后再由CPU访问，若主存已满，则采用置换算法置换主存中的交换页面。
虚拟存储器与Cache类似，将辅存中经常访问的数据副本存放到主存中。但是由于缺页访问辅存代价太大（需要调用中断进行I/O）。所以虚拟存储机制采用全相联映射，提高命中率。此外，当进行写操作时，不能每次写操作都写回磁盘，也需要进行回写法进行处理。
### 3.6.2 页式虚拟存储器
页式虚拟存储器以页为基本单位。虚拟空间与主存空间都被划分成同样大小的页，主存的页称为实页，页框，虚存的页称为虚页。把虚拟地址分为两个字段：虚页号和页内地址。虚拟地址到物理地址的转换是由页表转换的。页表是一张存放在主存中的虚页号和实页号的对照表，它记录程序的虚存调入主存时被安排在主存的位置。（==即页表记录逻辑地址与物理地址的映射关系，进一步的说记录了虚拟页号与物理页号的映射关系==）页表一般开机后就读入主存，并一直停留在主存中。
1. 页表
    下图展示的是一个页表。有效位也称为装入位，表示对应页面是否在主存中，若为1，表示已在主存，此时页表项存储该页的物理页号；若为0，则表示没有被调入主存，此时页表项为该页的磁盘地址。脏位也称修改位，用来表示页面是否被修改过，虚拟机制采用回写策略，利用脏位可判断被置换时是否需要写回磁盘。引用位也称使用位，一般用来配合置换算法策略进行设置，例如实现FIFO或LRU算法。
![Screenshot_2023-08-03-14-44-19-630_com.newskyer.draw.png](../_resources/Screenshot_2023-08-03-14-44-19-630_com.newskyer.dr.png)
CPU执行指令时，需要先将虚拟地址转换为主存物理地址。页表基址寄存器存放进程的页表首地址，然后根据虚拟地址高位部分的虚拟页号找到对应页表项，若装入位为1，则取出物理页号，与虚拟地址的低位页内地址拼接形成物理地址；若装入位为0，则说明缺页，需要操作系统进行缺页处理。地址变换如下所示：
![Screenshot_2023-08-03-14-53-31-954_com.newskyer.draw.png](../_resources/Screenshot_2023-08-03-14-53-31-954_com.newskyer.dr.png)
页式存储的优点在于页面的长度固定，页表简单，调入方便。缺点在于，由于程序不可能正好是页面的整数倍，最后一页的剩余部分将无法利用而造成浪费，并且页不是逻辑上独立的实体，所以处理，保护和共享都不及段式虚拟存储器方便。
2. 快表（$TLB$）
由上面的地址转换过程可知，访存时先访问一次主存查页表，再访问主存才能获得数据，如果缺页，还需要进一步的处理，所以普通页表方式至少需要两次访存才能获取主存中的数据。
依据程序的局部性原理，在一段时间内总是经常访问某些页时，若把这些页对应的页表项存放在高速缓冲器组成的快表（TLB）中，则可以提高效率，相应的把放在主存中的页表称为慢表（Page）。在地址转换时，首先查快表，若命中，则无需访问主存中的页表，这样就仅需访问一次主存就可读出数据。
快表通常采用全相联或组相联方式。每个TLB项有页表表项内容加上一个TLB标记字段组成，TLB标记用来表示该表项取自页表中哪个虚页号对应的页表项，因此TLB标记的内容在全相联方式下就是该页表项对应的虚页号；组相联方式下则是对应虚页号的高位部分（高多少位取决于分多少组），而虚页号的低位部分用于TLB组的组内索引。
> 应注意区别快表与Cache。快表中存放的是主存中页表信息副本，而Cache中存放的则是主存数据的副本，二者都是高速缓冲器，但功能不同

3. 具有TLB和Cache的多级存储系统
    下图是一个具有TLB和Cache的多级存储系统，其中Cache采用二路组相联方式。CPU给出一个32位的虚拟地址，TLB采用全相联方式，每一项都有一个比较器，查找时将虚页号与每个TLB标记字段同时进行比较，若有一项相等且对应有效位为1，则TLB命中，此时可直接通过TLB进行地址转换，若未命中，则TLB缺失，需要访问主存查找页表。图中所示的为两级页表方式，虚页号被分为页目录索引和页表索引两部分，由这两部分得到对应页表项，（多级页表会在OS中详细介绍）从而进行地址转换，并将相应表项调入TLB，若TLB已满，则还需使用置换策略。完成虚拟地址到物理地址的映射后，Cache根据映射方式将物理地址划分为多个字段，然后根据映射规则找到对应的Cache行或组，将对应Cache行中的标记与物理地址中的高位部分进行比较，若相等且有效位为1，则Cache命中，此时根据块内地址取出对应字送CPU。
![Screenshot_2023-08-03-15-27-38-588_com.newskyer.draw.png](../_resources/Screenshot_2023-08-03-15-27-38-588_com.newskyer.dr.png)
    查找时，也可以像Cache一样采用同时查找快表，慢表的策略。当TLB命中时，慢表查找停止。下图展示了带TLB虚拟存储器的CPU访存的流程：
![Screenshot_2023-08-03-15-30-06-313_com.newskyer.draw.png](../_resources/Screenshot_2023-08-03-15-30-06-313_com.newskyer.dr.png)
下表展示了TLB，page,Cache三种缺失的可能组合情况
![Screenshot_2023-08-03-15-31-04-911_com.newskyer.draw.png](../_resources/Screenshot_2023-08-03-15-31-04-911_com.newskyer.dr.png)
显然，第一种组合是最理想的情况，此时无需访问主存，第二和第三种情况都需要访问一次主存，而第四种情况需要访问两次主存，第五种情况发生“缺页异常”，需要发起中断访问磁盘，并且至少需要访问两次主存。Cache的缺失由硬件自动完成，缺页处理由操作系统（软件）完成，而TLB缺失既可以由硬件又可以由软件来处理。
### 3.6.3 段式虚拟存储器
不同于页式存储器的固定最小单位，段式存储器中的段是按程序的逻辑结构划分的，各个段的长度因程序而异。把虚拟地址分为两部分：段号和段内地址。虚拟地址到实地址之间的变换是由段表来实现的。段表是程序的逻辑段和在主存中存放位置的映射表。段表的每行记录与某个段对应的段号，装入位，段起点和段长等信息。由于段的长度可变，所以段表中需要给出各段的起始地址和段长。
CPU根据虚拟地址访存时，首先根据段号与段表基地址拼接成对应的段表行，然后根据该段表行的装入位判断是否已调入主存，已调入主存时，从段表读出该段在主存中的起始地址，与段内地址（偏移量）相加，得到对应的主存实地址。其地址变换过程如下所示：
<center>
<img src="../_resources/Screenshot_2023-08-03-16-00-41-548_com.newskyer.dr.png" alt="图片描述" width="400" height="300">
</center>

段式存储器的优点是，段的分界与程序的自然分界对应，因而具有逻辑独立性，使得其易于编译，管理，修改和保护，也便于多道程序的共享；缺点是因为段长度可变，容易在段间留下碎片，不好利用，造成空间浪费。
### 3.6.4 段页式虚拟存储器
段页式虚拟存储器把程序按逻辑结构分段，每段再划分为固定大小的页，主存空间也划分为大小相等的页，程序对主存的调入，调出仍以页为基本单位。在段页式虚拟存储器中，每个程序对应一个段表，每段对应一个页表，段的长度必须是页长的整数倍，段的起点必须是某一页的起点。
虚地址分为段号，段内页号，页内地址三部分。CPU根据虚地址访存时，首先根据段号得到段表地址；然后从段表中取出该段的页表起始地址，与虚地址段页号合成，得到页表地址；最后从页表中取出实页号，与页内地址拼接形成主存实地址。
段页式虚拟存储器的优点是兼具页式和段式虚拟存储器的优点，可以按段实现共享和保护，缺点是在地址变换过程中需要两次查表，系统开销大。
### 3.6.4 虚拟存储器与Cache的比较
1. 相同之处
- 最终目标都是为了提高系统性能，二者都有容量，速度，价格的梯度
- 都把数据划分为小信息块，并作为基本传递单位，虚存系统的信息块更大
- 都有地址映射，置换算法，更新策略等问题
- 都依据程序的局部性原理，将活跃的数据放在对应的高速部件中
2. 不同之处
- Cache主要解决系统速度，而虚拟存储器是为了扩充主存容量
- Cache全由硬件实现，为硬件存储器，对所有程序员透明；而虚拟存储器由OS和硬件共同实现，为逻辑存储器，对系统级程序员可见，对应用级程序员透明
- 对于不命中性能影响，Cache未命中而读取主存的代价要远大于缺页发起中断进行I/O的代价。因此缺页对系统性能的影响更大
- CPU与Cache和主存都建立了直接访问的通路，而辅存与CPU直接没有直接数据通路，因此Cache未命中是可直接访问主存，但缺页时必须先将外存数据读入主存后，CPU才能进行访问。

# 4.指令系统
## 4.1 指令系统
### 4.1.1 指令基本格式
1.零地址指令
<center>
    

|$OP$|
|-----|

</center>

只给出操作码，无显式地址，有下面的可能：
- 不需要操作数的指令，如空操作指令，停机指令，关中断指令等
- 零地址的运算类指令仅用在堆栈计算机中，通常参与运算的两个操作数隐含的从栈顶和次栈顶依次弹出，送到运算器进行运算，运算结果再压入堆栈。

2. 一地址指令
<center>
    
|$OP$|$A_1$|
|-----|-----|
</center>

- 只有目的操作数的单操作数指令，按$A_1$地址读取操作数，进行OP操作后，结果存回源地址，含义为：$OP(A_1) \rightarrow A_1$，如操作码含义是加1，减1，取反，求补等。整个过程至少需要3次访存（包含取指令，下同）
- 隐含约定目的地址的==双操作数==指令，按指令地址$A_1$可读取源操作数，指令可隐含约定另一个操作数由ACC累加器提供，运算结果返回ACC：含义：$(ACC)OP(A_1)\rightarrow ACC$。至少需要2次访存

3. 二地址指令
<center>
    
|$OP$|$A_1$|$A_2$|
|-----|-----|-----|
</center>

指令含义：$(A_1)OP(A_2)\rightarrow A_1$。对于常见的算术和逻辑运算指令，往往需要使用两个操作数，运算结果保存在目的操作数地址中。整个过程至少需要4次访存。

4. 三地址指令
<center>
    
|$OP$|$A_1$|$A_2$|$A_3(Result)$|
|-----|-----|-----|-----|

</center>

指令含义：$(A_1)OP(A_2)\rightarrow A_3$，与二地址的区别在于显式的给出了运算结果的存放地址，整个过程至少需要4次访存。

5. 四地址指令
<center>
    
|$OP$|$A_1$|$A_2$|$A_3(Result)$|$A_4(NextAdd)$|
|-----|-----|-----|-----|-----|
</center>

指令含义：$(A_1)OP(A_2)\rightarrow A_3$，$A_4$=下一条将要执行指令的地址。执行后PC不自动加1而是直接等于$A_4$。整个过程至少需要4次访存。
### ==4.1.2 定长操作码指令格式（定长指令字结构+可变长操作码）==
在下图中，指令字长为16位，其中4位为基本操作码字段OP，另有3个4位长的地址字段$A_1,A_2$和$A_3$。4位基本操作码若全用于三地址指令，则有16条，图中所示三地址指令为15条，1111留出扩展操作码，二地址指令为15条，1111 1111留出扩展操作码，一地址指令为15条，1111 1111 1111；留出扩展操作码，零地址为16条。
![Screenshot_2023-08-07-15-04-31-271_com.newskyer.draw.png](../_resources/Screenshot_2023-08-07-15-04-31-271_com.newskyer.dr.png)
一般在分配操作码时，对使用频率较高的指令分配较短的操作码，对使用频率较低的分配较长的操作码，从而尽可能减少指令译码和分析的时间。
> 假设地址长度为n，上层留出了m种状态给下层扩展，则下层可扩展的状态为$m \times 2^n$种

### 4.1.3 指令操作类型
1. 数据传送
传送指令通常有寄存器直接的传送($MOV$)，从内存单元读取到寄存器($LOAD$)，从寄存器写数据到内存($STORE$)等。
2. 算术和逻辑运算
比如加($ADD$)；减($SUB$)；比较($CMP$)；乘($MUL$)；除($DIV$)；加1($INC$)；减1($DEC$)；与($AND$)；或($OR$)；非($NOT$)；异或($XOR$)等
3. 移位操作
比如算术移位，逻辑移位，循环移位等
4. 转移操作
转移指令直接设置PC值，改变程序运行方向。比如无条件转移($JMP$)，条件转移($BRANCH$)，调用($CALL$)，返回($RET$)，自陷($TRAP$)等。
> 注意调用指令和转移指令的区别，调用指令需要保存下一条指令的地址（返回地址），子程序执行结束后返回主程序继续执行，而转移指令则不返回执行

5. I/O操作
用于CPU与外部设备交换数据或传送控制命令及状态信息

## 4.2 ==指令的寻址方式==
### 4.2.1 指令寻址和数据寻址
寻址方式分为指令寻址和数据寻址两大类，寻找下一条将要执行的指令地址称为指令寻址；寻找本条指令的数据地址称为数据寻址。
1. 指令寻址
指令寻址方式有两种：一种是顺序寻址方式，另一种是跳跃寻址方式。
- 顺序寻址：通过PC加1（1个指令字长），自动形成下一条指令地址。
- 跳跃寻址：即下条执行指令地址不由PC自动给出而是由本条指令给出下条指令地址的计算方式。
2. 数据寻址
数据寻址是指如何在指令中表示一个操作数的地址。
### 4.2.2 常见的数据寻址方式
1. 隐含寻址
这种类型的指令不显式的给出操作数的地址，而在指令中隐含操作数的地址，例如，在单地址的指令格式中就隐含了在地址字段中的第二操作数，而规定累加器ACC作为第二操作数地址。
隐含寻址的优点是有利于缩短指令字长，缺点是需增加存储操作数或隐含地址的硬件。
![Screenshot_2023-08-07-15-56-53-455_com.newskyer.draw.png](../_resources/Screenshot_2023-08-07-15-56-53-455_com.newskyer.dr.png)
2. 立即（数）寻址
顾名思义，这类指令的地址字段指的不是操作数的地址，而是操作数本身，也称立即数，采用==补码表示==。下图的#表示立即寻址特征，A为操作数本身。立即寻址的优点是指令执行过程不访存，执行时间最短，缺点是A的位数限制了A的表示范围。至少需要访存1次（包含取指令，下同）
![Screenshot_2023-08-07-15-59-12-638_com.newskyer.draw.png](../_resources/Screenshot_2023-08-07-15-59-12-638_com.newskyer.dr.png)
3. 直接寻址
指令字中的形式地址$A$是操作数的真实地址$EA$，即$EA=A$，如上所示。直接寻址的优点是简单，缺点是A的位数决定了该指令操作数的寻址范围，操作数的地址不易修改。整个过程至少需要2次访存。
4. 间接寻址
间接寻址是相对直接寻址而言的，其指令的地址字段给出的形式地址不是操作数的真正地址，而是操作数的有效地址所在的存储单元的地址（套娃），也就是操作数地址的地址，即$EA=(A)$。间接寻址可以次一次间址也可以是多次间址，一次间址最少需要3次访存。
![Screenshot_2023-08-07-16-05-09-739_com.newskyer.draw.png](../_resources/Screenshot_2023-08-07-16-05-09-739_com.newskyer.dr.png)
在上图中，主存单元为间址地址单元设置了一位tag，当tag为0时表示此单元中存放的是最终操作数的地址，当tag为1时表明间址仍未结束，仍需要继续访问该单元中存放的地址。间接寻址的优点是可以扩大寻址范围（有效地址EA的位数大于形式地址A的位数），便于编制程序（间接寻址可方便的完成子程序返回），缺点是需要多次访存，速度过慢。
5. 寄存器寻址
寄存器寻址是指在指令字中直接给出操作数所在的寄存器编号，即$EA=R_i$，其操作数在由$R_i$所指的寄存器内，如下所示。寄存器寻址的优点是指令在执行阶段不访问主存，只访问寄存器，执行速度快。缺点是计算机中的寄存器数量较少。整个过程至少需要1次访存。
![Screenshot_2023-08-07-16-19-05-399_com.newskyer.draw.png](../_resources/Screenshot_2023-08-07-16-19-05-399_com.newskyer.dr.png)
6. 寄存器间接寻址
寄存器间接寻址是指在寄存器$R_i$中给出的不是直接操作数，而是操作数所在的主存单元地址，即$EA=(R_i)$，如上所示。寄存器间接寻址比一般间接寻址相比速度更快(少一次访存操作)，整个过程至少需要2次访存。
7. 相对寻址
相对寻址是把PC的内容加上指令格式中的形式地址A而形成操作数的有效地址，即$EA=(PC)+A$，其中A是相对于当前PC的偏移量，可正可负，==补码表示==。
![Screenshot_2023-08-07-16-33-50-332_com.newskyer.draw.png](../_resources/Screenshot_2023-08-07-16-33-50-332_com.newskyer.dr.png)
相对寻址的优点是操作数的地址不是固定的，它随PC值的变化而变化，且与指令地址直接总是相差一个偏移量，便于程序浮动，相对寻址广泛应用与转移指令。
>注意：取出指令后，PC会自动加1指向下一条指令，所以相对寻址是相对于下一条指令的偏移

8. 基址寻址
基址寻址是指将CPU中基址寄存器（BR）的内容加上指令格式中的形式地址A而形成操作数的有效地址，即$EA=(BR)+A$。其中基址寄存器的内容由操作系统给出。
![Screenshot_2023-08-07-16-48-15-363_com.newskyer.draw.png](../_resources/Screenshot_2023-08-07-16-48-15-363_com.newskyer.dr.png)
基址寻址的优点是可扩大寻址范围；用户不必考虑自己的程序处于那个主存空间，有利于==多道程序设计==，并可用于编制浮动程序。
9. 变址寻址
变址寻址是指有效地址EA等于指令字中的形式地址A与变址寄存器IX（类型循环中的遍历指针i）的内容之和，即$EA=(IX)+A$，其中IX为变址寄存器（专用寄存器），也可用通用寄存器代替。
变址寄存器面向用户，程序执行过程中，变址寄存器的内容可由用户改变（作为偏移量），形式地址A不变（作为基地址）。
> 上面三种寻址方式均属于==偏移寻址==，其主要的区别在于起始地址的选择，相对寻址以PC中的地址作为起点，基址寻址一般以程序的起始存放位置为起点，变址寻址一般由程序员决定起点地址

10.堆栈寻址（后缀表达式）
堆栈是存储器（或专用寄存器组）中一块特定的，按后进先出（LIFO）原则管理的存储区，该存储区中读/写单元的地址时用一个特定的寄存器给出的，该寄存器称为堆栈指针($SP$)。堆栈可分为硬堆栈和软堆栈两种。
寄存器堆栈一般称为硬堆栈，其成本较高，不适合做大容量的堆栈；而从主存区划分一段区域来做堆栈是比较合算且最常用的做法，这种堆栈称为软堆栈。
在采用堆栈结构的计算机系统中，大部分指令表面上都表现为==无操作数指令==的形式，因为操作数地址都隐含使用了$SP$。

下面简单总结寻址方式，有效地址及访存次数（不包含取本条指令的访存）
![Screenshot_2023-08-07-17-09-14-786_com.newskyer.draw.png](../_resources/Screenshot_2023-08-07-17-09-14-786_com.newskyer.dr.png)
## 4.3 ==程序的机器级代码表示==
> 2022年408大纲新增考点，大题命题趋势

### 大纲原文
- 高级语言程序与机器级代码之间的对应
- 选择结构语句的机器级表示
- 循环结构语句的机器级表示
- 过程（函数）调用对应的机器级表示

### 4.3.1 常用汇编指令
在$x86$系统中常见有两种汇编格式，一种是$Windows$下的$Intel$格式，一种是$Linux$下的$AT\&T$格式，由于历年408中考察的通常是$Intel$格式下的汇编指令，所以重点掌握$Intel$格式的汇编指令（$emu8086$指令集）。此外，由于$x86$指令属于CSIC指令集，408中也出现过RSIC指令集的$MIPs$汇编指令，但题目中一般会给出其各汇编指令的含义，故只需判断是否属于$x86$指令集即可。
1. 寄存器
$x86$处理器中有8个32位的通用寄存器，分别为$EAX,EBX,ECX,EDX$，其中的高两位字节和低两位字节可以单独使用，比如$EAX$低两位称为$AX$，而$AX$的高低字节又可分别作为两个8位的寄存器：$AH$和$AL$。
2. 汇编指令格式
>早年408的参考书目袁春风教材中的指令格式为$AT\&T$格式，但历年真题出现（包括2023年）的以及新参考教材唐溯飞教材中指令格式为$Intel$格式，所以重点掌握$Intel$格式

这里重点区别$Intel$格式与$AT\&T$格式的区别：
- $AT\&T$格式的指令只能用小写，$Intel$格式对大小写不敏感
- $AT\&T$格式中第一个数为源操作数，第二个数为目的操作数，方向从左到右，$Intel$格式则相反
- $AT\&T$格式中，寄存器需要加前缀"$\%$"，立即数需要加前缀"$\$$"，$Intel$格式则不需要
- 内存寻址时，$AT\&T$格式用"$()$"，$Intel$格式用"$[]$"
- 在处理复杂寻址时，$AT\&T$格式的内存操作数`disp(base,index,scale)`分别表示偏移量，基址寄存器，变址寄存器和比例因子，如`8(%edx,%eax,2)`表示操作数为`M[R[edx]+R[eax]*2+8]`，其对应的$Intel$格式的操作数为`[edx+eax*2+8]`
- 在指定数据长度时，$AT\&T$格式指令操作码后面紧跟一个字符，表明操作数大小，“b”表示字节，“w”表示字，“l”表示双字.$Intel$格式也有类似语法，在操作码后面显式注明`byte ptr,word ptr,dword ptr`。==注意上面的操作数若未显式给出时，则默认为32bit。==

3. 常用指令
以$Intel$格式为例
- `<reg>`：表示任意寄存器，如其后带有数字，则指定其位数，如`<reg32>`表示32位寄存器（通用寄存器：`eax,ebx,ecx,edx,`变址寄存器组：`esi,edi`堆栈顶指针寄存器：`esp`堆栈底指针寄存器：`ebp`）；`<reg16>`表示16位寄存器（`ax,bx,cx,dx`）；`<reg8>`表示8位寄存器（`ah,al,bh,bl,ch,cl,dh,dl`）。
- `<mem>`：表示内存地址（如`[eax],[var+4],dword ptr[eax+ebx]`）
- `<con>`：表示8位，16位，32位常数。比如`<con8>`表示8位常数。
（1）数据传送指令
- `mov`指令。将第二个操作数复制到第一个操作数。注意不能直接从内存复制到内存，比如
```
mov eax,ebx #将ebx值复制到eax
mov byte ptr [var], 5 #将立即数5保存到var值执行的内存地址的一字节中
```
- `push`指令。将操作数压入内存的栈中，用于函数调用。`esp`为栈顶指针寄存器，压栈前`esp`先减4（栈顶为低地址，栈底为高地址），然后将操作数压入`esp`所指地址，例如（栈中元素固定为32位）：
```
push eax #将eax的值压栈
push [var] #将var所指内存地址的的4字节值压栈
```
- `pop`指令。与`push`指令相反，`pop`指令执行的是出栈操作，出栈前先将`esp`所指地址内容出栈，然后`esp`值加4
（2）算数和逻辑运算指令
- `add/sub`指令，相加相减指令，结果保存在第一个操作数中
- `inc/dec`指令，自增1，自减1指令，类似于C中的`i++,i--`
- `imul`指令，带符号整数乘法指令，结果保存在第一个操作数中
- `idiv`指令，带符号整数除法指令，==其只有一个操作数，即除数，被除数则为`edx:eax`中的内容（64位整数），操作结果商返回`eax`，余数返回`edx`==
- `and/or/xor`指令，逻辑与，逻辑或，逻辑异或操作，结果返回第一个操作数。
- `not`指令，对操作数的每一位进行取反
- `neg`指令，对操作数进行取负操作
- `shl.shr`指令，逻辑移位指令，`shl`为逻辑左移，`shr`为逻辑右移。
>注意：乘法和除法可以用分别用左移和右移来替代($*2^{移动位数}$)，其中带符号整数的乘/除法需要用==算数左/右==移来替代，无符号整数的乘/除用逻辑左/右移替代。

（3）==控制流指令==
- 无条件转移指令`jmp`。`jmp`指令控制PC直接转移到指定地址，不需要进行条件判断。
- 条件转移指令`jcondition`集合，前面需要使用`cmp`或其他判断指令进行条件判断，条件符合时转移，具体指令如下：
```
je <label> (jump when equal) a==b ZF==1?
jne <label> (jump when not equal) a!=b ZF==0?
jz <label> (jump when last result was zore) 
jg <label> (jump when greater than) a>b ZF==0 & SF==OF ?
jge <label> (jump when greater than or equal to) a>=b SF==OF ?
jl <label> (jump when less than) a<b SF!=OF ?
jle <label> (jump when less than or equal to) a<=b SF!=OF || ZF==1 ?
```
- `cmp/test`指令。`cmp`指令用于比较两个操作数的大小，`test`指令对两个操作数进行逐位与运算。其中`cmp`的底层原理是将两个操作数进行相减运算，根据运算结果设置CPU状态字中的各标志位，然后条件转移指令根据对应标志位判断条件是否满足。`cmp/test`指令一般与`jcondition`指令配合使用。
- `call/ret`指令。分别用于实现子程序（过程，函数等）的调用及返回。`call`指令首先将当前执行指令地址入栈，然后无条件转移到由标签指出的指令，与其他转移指令不同，`call`指令保存调用之前的地址信息（`call`指令结束后，返回调用前的地址继续执行）。`ret`指令实现子程序的返回，`ret`指令弹出栈中保存的指令地址，然后无条件转移到保存的指令地址（调用前的地址）执行。

> 在下面给出的选择，循环，过程调用的汇编示例中，为了方便，在条件转移时一般采用`<label>`表示转移地址，但在408的真题中，往往给出操作码地址（函数名+偏移量，函数名作用类似于`<label>`，其指向该函数的起始地址），然后可能会问此时采用了什么寻址方式，偏移量是多少。（事实上在$intel$格式汇编中，条件转移以及`call`指令的寻址方式都是相对寻址，即本条指令地址加“1”在加上偏移量即为转移后地址，偏移量可正可负），
### 4.3.2 选择语句的机器级表示
看这样一个C语言部分代码：
```c
int a=6,b=7,c=0;
if (a>b) c=a;
else c=b;
```
转换为汇编表示：
```
mov eax,7
mov eax,6
cmp eax,ebx
jle NEXT #不满足则跳转NEXT
mov ecx,eax
jmp END #无条件转移至末尾，否则会顺序执行NEXT
NEXT:
mov ecx,ebx
END:
```
### 4.3.3 循环语句的机器级表示
看这样一个求和程序段
```c
int result=0;
for(int i=1;i<=100;i++){
    result+=1;
}
//OR
int i=1,result=0;
while(i<=100){
    result+=1;
    i++;
}
```
```
//汇编：
mov eax,0
mov edx,1
cmp edx,100
jg L2
L1:
add eax,edx
inc edx
cmp edx,100
jle L1
L2:
```
除了用条件转移指令来实现循环外，也可以用loop指令来实现，如
```c
for(int i=500;i>0;i--){
...
...
}
```
```
//汇编：
mov ecx,500
Looptop:
...
...
loop Looptop #ecx--,若ecx!=0，跳转Looptop,loop指令只会对ecx寄存器进行自减操作
```
### 4.3.3 过程调用的机器级表示
看这样一个函数调用示例：
```c
int caller(){
    int temp1=125;
    int temp2=80;
    int sum=add(temp1,temp2);
    return sum;
}
int add(int x,int y){return x+y;}
```
```
//汇编：
caller:
push ebp
move ebp,esp
sub esp,24
mov [ebp-12],125
mov [ebp-8],80
mov eax,[ebp-8] #设置函数传递参数80，存放到[esp+4]
mov [esp+4],eax
mov eax,[ebp-12] #设置函数传递参数125，存放到[esp]
mov esp,eax
call add
mov [ebp-4],eax
mov eax,[ebp-4]
leave
ret

add:
push ebp
mov ebp,esp
mov eax,[ebp+12]
mov edx,[ebp+8]
add eax,edx
leave
ret
```
首先注意在内存区中，函数栈以高地址为栈底，低地址为栈顶。由栈底寄存器`ebp`和栈顶寄存器`esp`界定当前函数的栈帧范围。
在汇编中，过程调用由`call/ret`实现。
其中`call`指令的作用是把`IP`旧值压入栈顶保存，设置`IP`新值，无条件转移到被调用函数的第一条指令
`ret`指令的作用是从函数的栈帧顶部找到`IP`旧值，将其出栈并恢复到`IP`寄存器中
访问栈帧内部变量时可以通过`push/pop`指令实现
- 函数调用时，栈帧的切换会有一些固定操作，主要是对`ebp`和`esp`寄存器值的调整：
函数开头：此时在上一个调用的函数入口已经执行了`call`指令，`esp`执行`IP`旧值（返回地址）存放的上一函数栈顶，`push ebp`指令把上一函数的栈底地址出栈并保存到`esp`所指的栈顶，`mov ebp,esp`使得`ebp`指向与`esp`的同一栈顶位置。如下所示：
![Screenshot_2023-08-09-15-58-01-386_tv.danmaku.bili.png](../_resources/Screenshot_2023-08-09-15-58-01-386_tv.danmaku.bili.png)
上面的两步指令可以用`enter`指令替代
- 函数返回时：栈帧切换同样会有固定操作，`mov esp,ebp`指令让`esp`指向栈帧的底部，`pop ebp`指令将当前`esp`指向的栈顶内容（上一层函数的栈帧基地址）出栈保存到寄存器`ebp`中，然后`esp+=4`。如下所示： 
![Screenshot_2023-08-09-16-02-52-875_tv.danmaku.bili.png](../_resources/Screenshot_2023-08-09-16-02-52-875_tv.danmaku.bili.png)
同样的，上面两步指令可以用`leave`指令替代
- 函数参数的传递以及局部变量的访问可以通过`ebp`来实现，`ebp`永远指向的是当前函数栈的栈底部分，访问当前函数局部变量通过`[ebp-x]`访问，访问上一层函数传递的参数通过`[ebp+x]`访问：
![Screenshot_2023-08-09-16-21-09-640_tv.danmaku.bili.png](../_resources/Screenshot_2023-08-09-16-21-09-640_tv.danmaku.bili.png)
![Screenshot_2023-08-09-16-23-37-591_tv.danmaku.bili.png](../_resources/Screenshot_2023-08-09-16-23-37-591_tv.danmaku.bili.png)
![Screenshot_2023-08-09-16-24-43-129_tv.danmaku.bili.png](../_resources/Screenshot_2023-08-09-16-24-43-129_tv.danmaku.bili.png)
## 4.4 CISC和RISC的基本概念
CISC典型的有$x86$架构的计算机，RISC典型的有ARM，MIPS架构的计算机。二者主要的区别如下：
<center>

|:-----:|:-----:|:-----:|
| |$CISC$|$RISC$|
|指令系统|复杂，庞大|简单，精简|
|指令数目|一般大于200条|一般小于100条|
|指令字长|==不固定==|==固定==|
|可访存指令|不加限制|只有`Load/Store`指令|
|各种指令执行时间|相差较大|绝大多数在一个周期内完成|
|各种指令使用频率|相差很大|都比较常用|
|通用寄存器数量|较少|较多|
|目标代码|难以用优化编译生成高效的目标代码程序|采用优化的编译程序，生成代码较为高效|
|控制方式|绝大多数为微程序控制|绝大多数为组合逻辑控制|
|指令流水线|可以通过一定方式实现|必须实现|

</center>

# 5. 中央处理器
## 5.1 CPU的功能和基本结构
### 5.1.1 CPU的功能
中央处理器（CPU）由==运算器和控制器==组成。其中控制器负责协调并控制计算机各部件执行程序的指令序列，包括取指令，分析指令和执行指令。运算器负责对数据进行加工。
### 5.1.2 CPU的基本结构
1. 运算器
- 算术逻辑单元（ALU）。主要进行算术/逻辑运算
- 暂存寄存器。用于暂存从主存读来的寄存器，该数据不能直接放在通用寄存器中，否则会破坏原有内容，对所有程序员透明。一个应用的场景是，当CPU内部是单数据通路时，执行某个两个操作数的指令，此时无法同时从主存读入两个数据，会导致数据通路冲突，只能先读一个操作数放到暂存寄存器中，再读另一个操作数，最后将暂存寄存器中的操作数和数据通路中的操作数送到ALU中。
- 累计寄存器（ACC）。通用寄存器，用于暂时存放ALU运算的结果信息，此外，也可以作为加法器运算的一个输入端。
- 通用寄存器组。如AX,BX,CX,DX,SP等。用于存放操作数和各种地址信息等。SP是堆栈指针，用于指示堆栈顶的地址。
- 程序状态字寄存器（PSW）,保留由算术逻辑运算指令或测试指令的结果而建立的各种状态信息，如溢出标志(OF)，符号标志（SF），零标志（ZF），进/借位标志（CF）等。PSW中的这些位参与并决定微操作的形成。
- 移位器。对操作数或运算结果进行移位操作。
- 计数器。控制乘除运算的操作步数。
2. 控制器
> CU（Control Unit）控制单元，在图例中出现往往作为控制器内部的一个发出控制信号的部件，有时也把CU看做控制器总体。
- 程序计数器（PC）。用于指出下一条要执行的指令在主存中存放的地址。CPU根据PC中的地址去主存中取指令。PC寄存器通常具有自增功能。
- 指令寄存器（IR）。用于保存当前正在执行的这条指令内容。
- 指令译码器。仅对操作码字段进行译码，向控制器提供特定的操作信号
- 存储器地址寄存器（MAR）。用于存放要访问到主存单元的地址
- 存储器数据寄存器（MDR）。用于存放向主存写入的信息或从主存读出的信息。
- 时序系统。用于产生各种时序信号，由统一时钟（CLOCK）分频得到
- 微操作信号发生器。根据IR，PSW内容及时序信号，产生控制信号。
> 注意：CPU内部寄存器大致可分为两种，一种是汇编程序员可见的寄存器，可对此类寄存器编程。如通用寄存器组，程序状态字寄存器以及PC；另一种是汇编程序员不可见的寄存器，不可对这类寄存器编程，对所有用户透明，如MAR，MDR，IR等。

## 5.2 指令执行过程
> 从2013年命题组更换参考教材以来，第五章的大题仅在22年出现一次，并且降低了对硬件的要求，但仍需清楚的知道一条指令的执行过程，CPU中各部件的协同工作方式，以及指令周期的数据流。本节是解答第五章大题的关键

### 5.2.1 指令周期
CPU从主存中取出并执行一条指令的时间称为指令周期，不同指令的指令周期可能不同。指令周期常用若干机器周期来表示，一个机器周期又包含若干时钟周期（也称节拍或T周期，它是CPU的基本操作单位）。每个指令周期内的机器周期数可以不等，每个机器周期内的节拍数也可以不等。
大部分的指令都可以分为以下周期：
- 取指周期：从PC中所指的主存地址中取出要执行的指令
- 间址周期：通过指令中的间址方式去操作数的有效地址
- 执行周期：根据指令操作码对操作数进行操作
- 中断周期：处理中断请求
某些指令可能没有间址周期，比如一些零地址指令，不需要进行间址访问主存。对于无条件转移指令`JMP X`，在执行时不需要访问主存，只包含取指阶段和执行阶段。所以其指令周期仅包含取指周期和执行周期。

### 5.2.2 指令周期的数据流
- 取值周期（所有指令相同）
所谓取值阶段就是要把PC中所指的存放在主存中的指令取出来，然后放到IR中。即：
$PC\rightarrow MAR$
$M(MAR)\rightarrow MDR\rightarrow IR$
$PC+="1"$
==注意最后一条PC需要指向下一条指令==
1. 此"1"为当前指令的指令字长
2. 可以使用ALU，加法器，以及PC寄存器自增的功能实现PC+="1"
- 执行周期
    - 数据传送类（`mov,load,store`）
        - 寄存器－>寄存器
        - 寄存器－>主存
        - 主存－>寄存器
        - 立即数->寄存器
        - 立即数->主存
        涉及到主存时，应关注主存的读/写：
        $Write$：
            $Address \rightarrow MAR$
            $CU \ Give \ Read \ Sign$
            $M(MAR)\rightarrow MDR$
            $MDR\rightarrow EX$
        $Read$：
            $Address \rightarrow MAR$
            $Data\rightarrow MDR$
            $CU \ Give \ Write \ Sign$
            $MDR\rightarrow M(MAR)$
        同时需要注意总线占用问题，在一些单总线CPU中，需要合理的安排控制信号
        - 寄存器->暂存寄存器：通常是某条指令的子步骤，当单总线系统执行双操作数指令时，需要先将一个操作数存放到暂存寄存器中，另一个数据由数据通路传入ALU中。
    - 运算逻辑类指令（`add,sub,or,and,not`）
        - 加减指令可以用加法器，ALU实现
        - 自增自减可以用加法器，ALU，有自增自减功能的寄存器
        - 乘除指令可以用ALU，乘/除法器，整数乘二==（无逻左，带算左）除二（无逻右，带算右）==可以用ALU的移位实现，同样也可以由==带移位功能==的寄存器实现。
        - 移位运算可以用ALU，带移位功能的寄存器实现
        - 与，或，异或等可以用ALU，门电路实现
        - 非运算可以用ALU，门电路和一些带取反功能的寄存器实现。
        - 取补码，求负值可以用ALU以及一些带特殊功能的寄存器实现。
        - 符号扩展（带符号），0扩展（无符号）可以用带扩展功能的寄存器以及符号扩展器/0扩展器实现。
    - 转移类指令（`jmp,j×××`）－>可能会改变PC的值(2013真题T43，王道4.2.3大题8)
        - 条件转移类指令：
        一般会前置一条cmp指令（本质是减法A－B，生成标志位ZF,SF,OF,CF注意这些标志位是如何生成的）
        原理是根据标志位判断是否转移（指令周一般给出地址码）
        转移时需要注意：
            - 指令寻址方式
                - 相对寻址:PC+偏移量（==注意是以字为单位还是字节为单位==）注：若是根据题目指令格式可以看出为x86的Intel格式，那么转移类指令使用的都是相对寻址。
                - 直接寻址（少见）
            - 注意PC的值是以字节为单位还是以指令字为单位（CISC只能以字节为单位，RISC中都可以，上面的偏移量同理）
### 5.2.3 指令执行方案
- 单指令周期：对所有指令都选用相同的执行时间完成，指令之间串行执行，会导致较短时间可以完成的指令也要用更长的周期完成，降低整个系统的运行速度。
- 多指令周期：对不同类型的指令选用不同的执行步骤，称为多指令周期方案。指令之间串行执行，指令需要几个周期执行就分配几个周期。
- 流水线方案：指令直接可以并行执行的方案，称为流水线方案，这种方案通过在每个时钟周期启动一条指令，尽量让多条指令同时运行，但各自处在不同的执行步骤中。
## 5.3 数据通路的功能和基本结构
> 第五章408大题的命题重点，其解题的关键在于梳理清楚各类指令在取值，执行阶段的流程，各类指令需要哪些运算部件实现，以及在考察数据通路时，一般都会限制CPU内部为单总线（有考头），这个时候就需要注意，在一个指令周期内，内部总线上只能传输一个数据。以及有关暂存器的用途（基本年年考），重点结合历年408真题大题进行复习。

补充一下三态门和多路选择器：多路选择器就是较为常见的有多个input，根据内部电路片选信号选择一个output。而三态门是仅有一个input和一个output，通过内部电路控制是否output。在大题中若出现填某个运算部件，就看有没有给CU信号，是不是某个运算器或者寄存器后面接了一个部件，如果部件只有一个输入输出，那就是三态门，如果有多个输入，一个输出，那就是多路选择器。
## 5.4 控制器的功能和工作原理
> 这部分的内容在22年考纲修改中降低了要求，但微程序控制器仍然是考试的重点

### 5.4.1 控制器的功能
控制器是计算机系统的指挥中心，控制器的主要功能有：
- 从主存中取出一条指令，并指出下一条指令在主存中的位置
- 对指令进行移码或测试，产生相应的操作控制信号，启动规定操作
- 指挥并控制CPU，主存，输入和输出设备之间的数据流动方向
### 5.4.2 硬布线控制器
硬布线控制器的基本原理是根据指令的要求，当前的时序以及内外部的状态，按时间顺序发送一系列微操作控制信号。其由复杂的组合逻辑门电路和一些触发器构成，因此又称组合逻辑控制器。多用于RISC中。
CPU的控制方式：
- 同步控制方式。指系统有一个统一时钟，所有控制信号均来自这个统一的时钟信号。通常以最长的微操作序列和最烦琐的微操作作为标准。优点是控制电路简单，缺点是运行速度慢
- 异步控制方式。异步控制方式不存在基准时标信号，各部件按自身固有的速度工作，通过应答方式进行联络。优点是运行速度快，但控制电路复杂。
- 联合控制方式。是同步，异步控制方式的折中，其对各种不同的指令微操作大部分采用同步控制，小部分采用异步控制。
### 5.4.3 ==微程序控制器==
1. 微程序控制的基本概念
    微程序设计思想是把每条机器指令编写成一个微程序，每个微程序包含若干微指令，每条微指令对应一个或几个微操作命令。这些微程序可以存到一个控制存储器中（集成在CU中）。
- 微操作是微命令的执行过程，微命令是微操作都控制信号。二者都是微程序控制计算机中不可再分的最小单位。
- 微指令是若干微命令的集合。存放微指令的控制存储器的单元地址称为微地址。微周期是指执行一条微指令所需的时间，通常为一个时钟周期
- 主存储器与控制存储器。主存储器用于存放程序和数据，在CPU外部，用RAM实现；控制存储器（CM）用于存放微程序，在CPU内部，用ROM实现。
- 程序与微程序。一个程序由一段指令实现，一条指令的功能由一段微程序实现。程序由程序员编写，对用户可见。微程序用于描述机器指令，对程序员不可见。
注意区分下面的寄存器：
- 地址寄存器（$MAR$）。用于存放主存的读/写地址。
- 微地址寄存器（$CMAR \ or \ \mu PC$）。用于存放控制存储器的读/写地址
- 指令寄存器（$IR$）。用于存放从主存中读出的指令
- 微指令寄存器（$CMDR \ or \ \mu IR$）。用于存放从控制存储器中读出的微指令
2. ==微指令的编码方式==
微指令的编码方式又称微指令的控制方式，是指如何对微指令的控制字段进行编码，以形成控制信号。编码的目标是在保证速度的情况下，尽量缩短微指令字长。
- 直接编码（直接控制）方式
如下所示，直接编码无需进行译码，微指令的微命令字段中的每一位都代表一个微命令。设计微命令时，选用或不选用某个微命令，只需对应位设置成1或0即可。每个微命令对应并控制数据通路中的一个微操作。
![Screenshot_2023-08-11-15-30-20-473_com.newskyer.draw.png](../_resources/Screenshot_2023-08-11-15-30-20-473_com.newskyer.dr.png)
这种编码的优点在于简单，直观，执行速度快，操作并行性好；缺点是微指令字长过长，n个微命令就要求微指令的操作字段有n位，造成控制存储器容量极大。
- ==字段直接编码方式==
将微指令的微命令字段分为若干小字段，把互斥性微命令组合在同一字段中，相容性微命令组合在不同字段中，每个字段独立编码，每种编码代表一个微命令且各字段编码含义单独定义，与其他字段无关，如下所示：

<center>
<img src="../_resources/Screenshot_2023-08-11-15-34-16-271_com.newskyer.dr.png" alt="图片描述" width="400" height="300">
</center>

这种方式可以缩短微指令字长，但需要通过译码电路再发出微命令，速度比直接编码慢。
微命令字段分段的原则：
    (1) 互斥性微命令分在同一段内，相容性微命令分在不同段内
    (2) 每个小段中包含的信息位不能太多，否则将增加移码线路的复杂性和译码时间
    (3) *一般每个小段还需留出一个状态，表示本字段不发出任何微命令。因此，==当某字段长度为3时，最多只能表示7个互斥的微命令，通常用000表示不操作==
- 字段间接编码方式
一个字段的某些微命令需由另一个字段中的某些微命令来解释，由于不是靠字段直接译码发出的微命令，因此称为字段间接编码，又称隐式编码。这种方式可以进一步缩短微指令字长，但削弱了微指令的并行控制能力，通常作为字段直接编码方式的一种辅助手段。
3. 微指令的地址形成方式（类比机器指令的地址PC形成方式）
后继微地址的形成主要有以下两大基本类型：
- 直接由微指令的下地址字段指出。微指令格式中设置一个下地址字段，由微指令的下地址字段直接指出后继微指令的地址，这种方式又称断定方式
- 根据机器指令的操作码形成。机器指令取至指令寄存器后，微指令的地址由操作码经微地址形成部件形成。
4. 微指令格式
微指令格式与编码方式有关，通常分水平型微指令和垂直型微指令两种。
- 水平型微指令。从编码方式上看，直接编码，字段直接编码，字段间接编码和混合编码都属于水平型微指令。其基本指令格式如下所示，指令字中的一位对应一个控制信号。==一条水平型微指令定义并执行几种并行的基本操作==。通常一条水平型微指令很长，一个微程序由少量水平型微指令组成。其微程序短，执行速度快，但编写微程序较麻烦。
![Screenshot_2023-08-11-15-58-49-307_com.newskyer.draw.png](../_resources/Screenshot_2023-08-11-15-58-49-307_com.newskyer.dr.png)
- 垂直型微指令。垂直型微指令采用类似机器指令操作码的方式，在微指令中设置操作码字段，采用微操组码编译法，由微操作码规定微指令的功能，其格式如下所示。一条垂直型微指令只能定义并执行一种基本操作。其优点是微指令短，简单，规整，便于编写，缺点是微程序长，执行速度慢，工作效率低。
![Screenshot_2023-08-11-16-02-06-478_com.newskyer.draw.png](../_resources/Screenshot_2023-08-11-16-02-06-478_com.newskyer.dr.png)
- 混合型指令。在垂直型的基础上增加一些不太复杂的并行操作。微指令较短，扔便于编写；微程序也不长，执行速度比垂直型快。
- 水平型微指令和垂直型微指令的对比如下：
    - 水平型微指令并行操作能力强，效率高，灵活性强；垂直型微指令则次之
    - 水平型微指令执行一条指令的时间短；垂直型微指令执行的时间长
    - 水平型指令解释的微程序，具有微指令字较长但微程序短的特点；垂直型微指令则相反，微指令字较短而微程序长
    - 水平型微指令难以编写，而垂直型微指令与机器指令比较相似，便于编写
### 5.4.4 硬布线和微程序控制器的对比
![Screenshot_2023-08-11-16-07-13-029_com.newskyer.draw.png](../_resources/Screenshot_2023-08-11-16-07-13-029_com.newskyer.dr.png)

## 5.5 异常（同步）和中断（异步）机制
由CPU内部产生的意外事件被称为异常，也成为内中断。由CPU外部的设备向CPU发出的中断请求被称为中断，通常用于信息的输入输出，也称外中断。
### 5.5.1 异常和中断的分类
1. 异常的分类
- 故障（Fault）
  指在引起故障的指令启动后，执行结束前被检测到的异常事件。例如，指令译码时出现“非法操作码”；取数据时，发生“缺页”或“缺段”；执行整数除法时，发现除数为0等。对于“缺页”和“缺段”等可以挽回异常时，通常通过一定操作后，比如调页入主存，回到发生故障的指令继续执行，断点为当前发生故障的指令；对于不可挽回的异常，比如除数为0时，无法恢复故障，必须终止程序。
- 自陷（Trap）
  自陷也称陷阱或陷入，它是预先安排的一种“异常”事件。通过人为设置Trap，当执行到Trap时，CPU在执行完自陷指令后，自动根据不同Trap类型进行相应的处理，然后返回到自陷指令的下一条指令执行。
  故障异常和自陷异常都属于程序性异常（软件中断）
> 注意：当自陷指令是转移指令时，并不是返回到下一条指令执行，而是返回到转移目标指令执行。

- 终止（Abort）
  一般指在执行指令的过程中发生了使计算机无法继续执行的==硬件故障==，如控制器出错，存储器校验错等，那么程序无法继续执行，只能终止。此时，调出中断服务程序来重启系统。这种异常是随机发生的。终止异常和外中断都属于硬件中断。
2. 中断的分类
- 可屏蔽中断
  指通过可屏蔽中断请求线INTR向CPU发出的中断请求。CPU可以通过在中断控制器中设置相应的屏蔽字选择是否屏蔽该中断，被屏蔽的中断将不送CPU。
- 不可屏蔽中断
  指通过专门的不可屏蔽中断请求线NMI向CPU发出的中断请求，通常是非常紧急的硬件故障，如电源掉电等。这类中断请求信号不可被屏蔽，以让CPU快速处理这类紧急事件。

中断和异常本质上是一样的，都会暂停当前执行的指令，转而执行其他操作。但它们之间有两个重要的区别：
- 缺页和溢出等异常事件是由特定指令在执行过程中产生的，而中断不和任何指令相关联，换句话说，中断可能在任何指令执行期间发生。
- 异常的检测由CPU自身完成，不必通过外部的某个信号通知CPU。对于中断，CPU必须通过中断请求线获取中断源的信息，才能知道哪个设备发生了何种中断。
### 5.5.2 异常和中断响应过程
CPU执行指令时，如果发生了异常或中断请求，必须进行相应的处理。从CPU检测到异常或中断事件，到调出相应的处理程序，整个过程称为异常和中断的响应。CPU对异常和中断响应的过程可分为：关中断，保存断点和程序状态，识别异常和中断并转到相应的处理程序。
- 关中断。在保存断点和程序状态期间，不能被新的中断打断，即要求中断处理时原子操作，会用过IF触发器实现关中断。
- 保存断点和程序状态（PSW内容），保存现场，将PSW和程序的断点保存到栈中，保存到栈中可以支持异常或中断的嵌套。异常和中断处理后，存在栈中的PSW的内容会恢复到PSW中。
- 识别异常和中断并转到相应的处理程序。识别异常和中断有软件识别和硬件识别两种方式。异常和中断源的识别方式不同，异常大多采用软件识别方式，而中断可以采用软件识别或硬件识别方式。
    软件识别方式是指CPU设置一个异常状态寄存器，用于记录异常原因。操作系统使用一个统一的异常或中断查询程序，按优先级顺序查询异常状态寄存器，先查询到的先被处理，然后转到内核中的对应处理程序。
    硬件识别方式又称==向量中断==，异常或中断服务程序的==首地址称为中断向量==，所有中断向量存放在中断向量表中。每个异常或中断都被指定一个中断类型号。中断向量表中，类型号和中断向量一一对应。
> 中断响应过程将在第七章I/O系统重点介绍

## 5.6 指令流水线
### 5.6.1 指令流水线的基本概念
可从两方面提高处理机的并行性：
- 时间上的并行技术，将一个任务分解为几个不同的子阶段，每个阶段在不同的功能部件上并行执行，以便在同一时刻能够同时执行多个任务，进而提升系统性能
- 空间上的并行技术，在一个处理机内设置多个执行相同任务的功能部件，并让这些功能部件并行工作，这样的处理机称为超标量处理机
1. 指令流水的定义
   一条指令的执行过程可分解为若干阶段，每个阶段由相应的功能部件完成。如果将各阶段视为相应的流水段，则指令的执行过程就构成了一条指令流水线。
   按408真题划分一条指令的执行过程分为下面5个阶段：
- 取指(IF)：从指令存储器或Cache中取出指令
- 译码/读寄存器（ID）：操作控制器对指令进行译码，同时从寄存器堆中取操作数
- 执行/计算地址（EX）：执行运算操作或计算地址
- 访存（MEM）：对存储器进行读/写操作
- 写回（WB）：将指令执行的结果写回寄存器堆
> 不是所有的指令都有上面五个阶段，比如条件转移指令在写回PC时一般在MEM阶段完成，且不需要访存。注意写回阶段一般指的是写回通用寄存器组

为了利于实现指令流水线，指令集应具有如下特征：
- 指令长度应尽量一致，有利于简化取指令和指令译码操作。
- 指令格式应尽量规整，尽量保证源寄存器的位置相同，有利于在指令未知时就可取寄存器操作数。
- 采用`Load/Store`指令，其他指令都不能访存，可以把访存的执行步骤规整在同一周期中，有利于减少操作步骤。
- 数据和指令在存储器中“对齐”存放。有利于减少访存次数。

2. 流水线的表示方法
通过时空图可以直观的描述流水线的执行情况，如下所示：
![Screenshot_2023-08-12-15-37-18-223_com.newskyer.draw.png](../_resources/Screenshot_2023-08-12-15-37-18-223_com.newskyer.dr.png)
在上图中，5T时刻前，被称为装入时间，5T~9T称为排空时间。假设一个指令流水线中每条指令分为$m$个阶段，每个阶段执行都需要一个时钟周期$T$，指令流水线每隔周期$T$就有下一条指令装入，则$n$条指令完成指令流水线的时间为：
$$
t=(n-1+m)T
$$
例如，上图中的5条指令完成的时间为$(5-1+5)T=9T$。
### 5.6.2 流水线的基本实现及数据通路
> 这部分的内容较为复杂，且真题中考察频率较低，可战略性放弃
### 5.6.3 流水线的冒险与处理
> 这部分是历年考察的重点，通常以小题形式或者作为大题的某一问进行考察

1. 结构冒险（互斥）
    由于多条指令在同一时刻争用同一资源而形成的冲突，也称资源冲突，即由硬件资源竞争造成的冲突，有下面两种解决办法：
   - 前一指令访存时，使后一条相关指令（以及后序指令）暂停一个时钟周期
   - 单独设置数据存储器和指令寄存器，使取数和取指令操作各自在不同的存储器进行。（现代计算机都引用了多级Cache的机制，L1Cache通常采用数据Cache和指令Cache分离的方式，避免资源冲突的发生）
2. ==数据冒险==（同步）
    下一条指令会用到当前指令计算出的结果，此时这两条指令可能会发生数据冲突。当多条指令重叠处理时就会发生冲突，数据冒险可分为三类：
   - 写后读（Read After Write, RAW）相关：表示当前指令将数据写入寄存器后，下一条指令才能从该寄存器读取数据。否则，先读后写，读到的就是错误（旧）数据。
   - 读后写（Write After Read, WAR）相关：表示当前指令读出数据后，下一条指令才能写该寄存器。否则先写后读，读到的就是错误（新）的数据。
   - 写后写（Write After Write, WAW）相关，表示当前指令写入寄存器后，下一条指令才能写该寄存器，否则，下一条指令在当前指令之前写，将使寄存器的值不是最新值。
解决的办法有下面几种：
   - 把遇到数据相关的指令及其后续指令都暂停一至几个时钟周期，直到数据相关问题消失后继续执行，可分为硬件阻塞和软件插入“NOP”指令两种方法。
   - 设置相关专用通路，即不等前一条指令把计算结果写回寄存器组，下一条指令页不再读寄存器组，而直接把前一条指令的ALU计算结果作为自己的输入数据开始计算。这称为==数据旁路技术==
   - 通过编译器对数据相关的指令编译优化的方法，调整指令顺序来解决数据相关。
3. 控制冒险
    指令通常是顺序执行的，但是遇到转移类指令改变执行顺序时，会改变PC的值，从而引起控制冒险，有以下解决办法：
   - 对转移指令进行分支预测，尽早生成转移目标地址。分支预测分为简单（静态）预测和动态预测。静态预测总是预测条件不满足，即继续执行分支指令的后续指令，动态预测根据程序执行的历史情况，进行动态预测调整，预测准确率较高。
   - 预取转移成功和不成功两个控制流方向上的目标指令
   - 加快和提前形成条件码
   - 提高转移方向的猜准率
> 历年真题中多次提到的“按序发射，按序完成”指的是，下一条指令的IF必须和上一条指令的ID并行，以免上一条指令发生冲突而导致下一条指令先执行完
### 5.6.4 流水线的性能指标
1. 流水线的吞吐率
    流水线的吞吐率是指单位时间内流水线所完成的任务数量，或输出结果的数量。流水线吞吐率（$TP$）的最基本公式为：
$$
TP=\frac{n}{T_k}
$$
![Screenshot_2023-08-12-16-09-25-724_tv.danmaku.bilibilihd.png](../_resources/Screenshot_2023-08-12-16-09-25-724_tv.danmaku.bili.png)
其中，$n$为任务数，$T_k$是处理完$n$个任务所用的总时间。设$k$为流水段的段数，$\Delta t$为时钟周期。在输入流水线中的任务连续的理想情况下，一条$k$段流水线能在$k+n-1$个时钟周期内完成$n$个任务。进一步得出吞吐率为：
$$
TP=\frac{n}{(k+n-1)\Delta t}
$$
连续输入任务数$n \rightarrow \infty$时，得最大吞吐率为$TP_{max}=1/ \Delta t$
2. 流水线的加速比
完成相同数量指令，不使用流水线与使用流水线所用的时间之比。
流水线加速比(S)的基本公式为：
$$
S=\frac{T_0}{T_k}
$$
其中，$T_0$表示不使用流水线的总时间；$T_k$表示使用流水线的总时间。一条$k$段流水线完成$n$个任务所需时间为$T_k=(k+n-1)\Delta t$。顺序执行$n$个任务时，所需的总时间为$T_0=kn\Delta t$。将$T_0$和$T_k$代入上式，进一步得出加速比为：
$$
S=\frac{T_0}{T_k}=\frac{kn\Delta t}{(k+n-1)\Delta t}=\frac{kn}{k+n-1}
$$
连续输入的任务数$n \rightarrow \infty$时，得最大加速比为$S_{max}=k$
### 5.6.5 高级流水线技术
有两种增加指令级并行的策略，一种是多发射技术，它通过采用多个内部功能部件，使流水线功能段能同时处理多条指令，处理机一次可以发射多条指令
进入流水线执行；另一种是超流水线技术，通过增加流水线级数来使更多的指令同时在流水线中重叠执行。
1. 超标量流水线技术（动态多发射技术，空分复用）
    每个时钟周期内可并发多条独立指令；需要配置多个功能部件；不能调整指令的执行顺序。乱序发射（执行）时则可以动态调整指令执行顺序。通过编译优化技术，把可并行执行的指令搭配起来。
![Screenshot_2023-08-12-16-40-25-022_com.newskyer.draw.png](../_resources/Screenshot_2023-08-12-16-40-25-022_com.newskyer.dr.png)
2. 超流水技术（时分复用）
    在一个时钟周期内再细分段；在一个时钟周期内，一个功能部件可能被使用多次；不能调整指令执行顺序，执行顺序由编译器决定。
![Screenshot_2023-08-12-16-44-09-897_com.newskyer.draw.png](../_resources/Screenshot_2023-08-12-16-44-09-897_com.newskyer.dr.png)
3. 超长指令字
    由编译器挖掘指令间潜在的并行性，将多条能并行的指令合成一条；具有多个操作码字段的超长指令字（可达几百位）；采用多个处理部件。

## 5.7 多处理器的基本概念
> 22年新增考点，只要求掌握基本概念，只会考小题。可重点在考前记一记

### 5.7.1 SISD;SIMD;MIMD和向量处理机的基本概念
- SISD（单指令流单数据流）。特性：各指令序列只能并发，不能并行，每条指令处理一两个数据，其不是数据级并行技术。硬件组成：一个处理器+一个主存储器。若采用指令流水线，需设置多个功能部件，采用多模块交叉存储器。
- SIMD（单指令流多数据流）。特性：各指令序列只能并发，不能并行，但每条指令可以同时处理多个具有相同特征的数据，是一种数据级并行技术。硬件组成：一个指令控制部件（CU）+多个处理单元/执行单元（如ALU）+多个局部存储器+一个主存储器。每个执行单元有各自的寄存器组；局部存储器；地址寄存器。不同执行单元执行同一条指令，处理相同特征的不同数据。
- MISD（多指令流单数据流）。多条指令并行执行，处理同一个数据，==现实中不存在这样的计算机==
- MIMD（多指令流多数据流）。特性：各指令序列并行执行，分别处理多个不同的数据。是一种线程级并行，甚至是线程级以上并行技术。进一步可分为：
    - 多处理器系统（个人PC）。特性：各处理器之间，可以通过`LOAD/STORE`指令，访问同一个主存储器，可通过主存相互传送数据。硬件组成：一台计算机内，包含多个处理器+一个主存储器，多个处理器共享单一的物理地址空间。
    - 多计算机系统（分布式计算机系统）。特性：各计算机之间，不能通过`LOAD/STORE`指令直接访问对方的存储器，只能通过“消息传递”相互传送数据。硬件组成：多台计算机组成，因此拥有多个处理器+多个主存储器。每台计算机拥有各自的私有存储器，物理地址空间相互独立。
- 向量处理机（SIMD思想的进阶应用）：特性；一条指令的处理对象是“向量”。擅长对向量型数据并行计算，浮点数运算，常被用于超级计算机中，处理科研中巨大的运算量。硬件组成：多个处理单元，多组“向量寄存器”；主存储器采用“多个端口同时读取”的交叉多模块存储器；主存储器大小限定了机器的运算规模。
### 5.7.2 共享内存多处理器/多核处理器（MIMD）
1. 共享内存多处理器（多处理器系统）：多个处理器共享一个主存储器，多个处理器共享单一物理地址空间，都可以通过`LOAD/STORE`指令访问共享的主存空间。
2. 多核处理器：一个CPU芯片中包含多个处理器，即多个核（core），因此通常也称片级多处理器，即一块芯片上集成了多个处理器。所有核心共享一个最低级的Cache缓存，并共享主存储器。
### 5.7.3 硬件多线程
<center>


| |细粒度多线程|粗粒度多线程|同时多线程(SMT)|
|:-----:|:-----:|:-----:|:-----:|
|指令发射|轮流发射各线程的指令（每个时钟周期发射一个线程）|连续几个时钟周期，都发生同一线程的指令序列，流水线阻塞时，切换另一个线程|一个时钟周期内，同时发射多个线程的指令|
|线程切换频率|每个时钟周期切换一次线程|只有流水线阻塞时才切换一次线程|NULL|
|线程切换代价|低|高，需要重载流水线|NULL|
|并行性|指令级并行，线程间不并行|指令级并行，线程间不并行|指令级，线程级并行|

</center>

# 6.总线
## 6.1 概述
### 6.1.1 系统总线的结构
1. 单总线结构
> 408大题尝尝设置为单总线结构的计算机，其在传输数据时需要注意一个时钟周期内只能传输一个数据

单总线结构如下所示，注意单总线并不是只有一个信号线，系统总线按传送信息的不同可细分为地址总线，数据总线和控制总线。其优点是结构简单，成本低，易于接入新的设备。缺点是带宽低，负载重，多个部件只能争用唯一的总线，且不支持并行传送数据。
![Screenshot_2023-08-16-15-13-22-481_com.newskyer.draw.png](../_resources/Screenshot_2023-08-16-15-13-22-481_com.newskyer.dr.png)

2. 双总线结构
双总线结构有两条总线：一条是主存总线，用于CPU，主存和通道直接传送数据，另一条是I/O总线，用于多个外部设备与通道直接传输数据，如下所示，其优点在于将低速的I/O设备从单总线上分离出来，实现了存储器总线和I/O总线分离。缺点在于需要增加通道等硬件设备。
> 注意双总线结构支持突发（猝发）传送，即寻址阶段CPU发送连续数据单元的首地址，传输阶段传送多个连续单元的数据，每个时钟周期传送一个字长的信息，但直到传送完毕都不释放总线

![Screenshot_2023-08-16-15-21-41-773_com.newskyer.draw.png](../_resources/Screenshot_2023-08-16-15-21-41-773_com.newskyer.dr.png)
3. 三总线结构
三总线结构是计算机结构各部件直接采用三条独立的总线来构成信息通路，其三条总线分别为主存总线，I/O总线和DMA（直接内存访问）总线，如上所示。主存总线用于CPU和内存之间传送地址，数据和控制信号。I/O总线用于在CPU和各类外设直接通信。DMA总线用于内存和高速外设直接直接传送数据。其优点在于提高了I/O设备的性能，使其更快响应命令，提高系统吞吐量。缺点在于系统工作效率低。
> DMA数据传送还会在第七章I/O中详细介绍

### 6.1.2 总线性能指标
> 大部分的性能指标可与CPU性能指标类比记忆
- 总线传输周期。指一次总线操作所需的时间。总线传输周期通常由若干总线时钟周期构成。
- 总线时钟周期。与总线时钟频率互为倒数。
- 总线工作频率。总线上各种操作都频率，为总线周期的倒数。实际上指1秒内传送几次数据。
- 总线时钟频率。与总线时钟周期互为倒数。
- 总线宽度。又称总线位宽，它是总线上能够传输的数据位数，通常指数据总线的根数。
- ==总线带宽==。可理解为总线的最大传输效率，即单位时间内总线上最多可以传输数据的==位数==，通常用每秒传送信息的字节数来衡量，单位可用字节/秒(B/s)表示。总线带宽=总线工作频率×（总线宽度/8）（单位B/s）。
- 总线复用。指一种信号线在不同时间传输不同信息，比如DRAM可以采用地址复用技术，行列地址分时传送，地址线减少一半。
- 信号线数。地址总线，数据总线和控制总线3种总线数的总和称为信号线数。

## 6.2 总线事务和定时
### 6.2.1 总线事务
从请求总线到完成总线使用的操作序列称为总线事务，它是在一个总线周期中发生的一系列活动。常见的总线事务分为下面阶段：
- 请求阶段。主设备（CPU或DMA）发出总线传输请求，并且获得总线控制权。
- 仲裁阶段。总线仲裁机构决定将下一个传输周期的总线使用权授予某个申请者。
- 寻址阶段。主设备通过总线给出要访问的从设备地址及有关命令，启动从模块。
- 传输阶段。主设备与从设备进行数据交换，可单向或双向进行数据传送。
- 释放阶段。主设备的有关信息均从系统总线上撤除，让出总线使用权。

==突发（猝发）==传送方式能够进行连续成组数据的发生，其寻址阶段发送的是连续数据单元的首地址，在传输阶段传送多个连续单元的数据，每个时钟周期可以传送一个字长的信息，但是不释放总线，直到一组数据全部传送完毕后，再释放总线。
### 6.2.2 同步定时方式
同步定时方式是指系统采用一个统一的时钟信号来协调发送和接收双方的传送定时关系。时钟产生相等的时间间隔，每个间隔构成一个总线周期。在一个总线周期中，发送方和接收方可以进行一次数据传送。其优点在于传送速度快，具有较高的传输效率；总线控制逻辑简单。缺点在于主从设备属于强制性同步，不能及时进行数据通信的有效性校验，可靠性较差。同步定时方式适用于总线长度较短及总线所接部件的存取时间比较接近的系统。
> 有些同步定时方式为了缓解：当一个时钟周期内CPU发出访存信号后，内存还在准备数据时，该时钟周期就已经结束的情况。会在时钟周期中插入WAIT信号时间，确保一个时钟周期内CPU能够读取到数据

### 6.2.3 异步定时方式
异步定时方式没有统一的时钟和固定的时间间隔，完全依靠传送双方相互制约的“握手”信号实现定时控制。通常把交换信息的两个部件设备分为主设备和从设备，主设备提出交换信息的“请求”信号，经接口传送到设备；从设备接到主设备的请求后，通过接口向主设备发出“回答”信号。其优点在于总线周期长度可变，能保证两个工作速度相差很大的部件或设备之间可靠的进行信息交换，自动适用时间的配合。缺点在于比同步定时方式更加复杂，速度也更慢。
根据“请求”和“回答”信号是否互锁，异步定时方式又分为以下三种类型：
- 不互锁方式。主设备发出“请求”信号后，不必等待接受从设备的“回答”信号，过一段时间后自动撤销“请求”信号。而从设备接到“请求”信号后，发出“回答”信号，并经过一段时间自动撤销。双方不存在互锁关系，如下（a）所示。
- 半互锁方式。主设备发出“请求”信号后，必须等待接受从设备的“回答”信号后，才能撤销“请求”信号，有互锁关系。但从设备在接到“请求”信号后，发出“回答”信号，但不必等待获知主设备“请求”信号已撤销，而是隔一段时间自动撤销“回答”信号，不存在互锁关系，如下（b）所示。
- 全互锁方式。主设备发出“请求”信号后，必须等待接受从设备的“回答”信号后，才能撤销“请求”信号，有互锁关系。且从设备在接到“请求”信号后，发出“回答”信号后，必须等待获知主设备“请求”信号已撤销后才撤销“回答”信号，双方存在互锁关系，如下（c）所示。
> 不互锁方式到半互锁方式再到全互锁方式，其速度逐渐变慢，可靠性越高。

![Screenshot_2023-08-16-16-04-21-792_com.newskyer.draw.png](../_resources/Screenshot_2023-08-16-16-04-21-792_com.newskyer.dr.png)

# 7 输入/输出系统
## 7.1 I/O接口
### 7.1.1 I/O接口的功能
I/O接口的主要功能如下：
- 进行地址译码和设备选择
- 实现主机和外设的通信联络控制
- 实现数据缓冲
- 信号格式转换
- 传送控制命令和状态信息
### 7.1.2 I/O接口的基本结构
![Screenshot_2023-08-17-16-41-11-400_com.newskyer.draw.png](../_resources/Screenshot_2023-08-17-16-41-11-400_com.newskyer.dr.png)
> 对数据缓冲寄存器，状态/控制寄存器的访问操作是通过相应的指令来完成的，通常称这类指令为I/O指令，I/O指令只能在操作系统内核的底层I/O软件中使用，它们是一种特权指令

### 7.1.3 I/O接口的类型
- 按数据传送方式可分为并行接口（一字节或一个字的所以位同时传送）和串行接口（一位一位的传送），接口需要完成数据格式的转换
- 按主机访问I/O设备的控制方式可分为程序查询接口，中断接口和DMA接口等
- 按功能选择的灵活性可分为可编程接口和不可编程接口
### 7.1.4 I/O端口及其编址
I/O端口是指接口电路中==可被CPU直接访问到寄存器==，主要有数据端口，状态端口和控制端口，若干端口加上相应的控制逻辑电路组成接口。通常，CPU能对数据端口执行读写操作，但对状态端口只能执行读操作，对控制端口只能进行写操作。
I/O端口编址方式分为存储器统一编址和独立编址两种：
- 统一编址，又称存储器映射方式，是把I/O端口当做存储器的单元进行统一的地址分配，这种方式CPU不需要设置专门的I/O指令，用统一的访存指令就可以访问I/O端口。其缺点在于端口占用存储器地址，使内存容量变小，而且利用存储器编址的I/O设备进行数据输入输出操作速度较慢。这种编址方式在RISC中常用。
- 独立编址，又称I/O映射方式，I/O端口的地址空间与主存地址空间相互独立，无法从地址码的形式区分，需要设置专门的I/O指令进行访问I/O端口，但其优点在于输入/输出指令与访存指令有明显区别，便于程序理解。
## 7.2 I/O方式
### 7.2.1 程序查询方式（独占查询）
信息交换的控制完全由CPU执行程序实现，程序查询方式接口中设置一个数据缓冲寄存器（数据端口）和一个设备状态寄存器（状态端口）。主机进行I/O操作时，先发出询问信号，读取设备的状态并根据设备状态决定下一步操作是继续等待还是进行数据传送。大致流程如下：
- CPU执行初始化程序，并设置传送参数
- 向I/O接口发出命令字，启动I/O设备
- 从外设接口读取其状态信息。
- CPU==不断查询==I/O设备状态，直到外设准备就绪
- 传送一次数据
- 修改地址和计数器参数
- 判断传送是否结束，若未结束转第3步，直到计数器为0。
在这种控制方式下，CPU一旦启动I/O，就必须停止现行程序运行，并在现行程序中插入一段程序。程序查询方式的主要特点是CPU会一直等待I/O设备，CPU与I/O串行工作，这种方式的接口设计简单，设备量少，但CPU在信息传送过程中要花费很多时间来查询和等待，且一段时间内只能和一台外设交换信息，效率较低。
>补充一种对上述查询方式的改进：定时查询。在保证数据不会丢失的情况下，CPU发出启动I/O设备指令后，不在原地等待I/O设备准备数据，而是每隔一段时间CPU查询一次I/O设备状态，在查询间隔CPU可以转而执行其他程序。（注意这种方式与程序中断方式不同）

### 7.2.2 程序中断方式
1. 程序中断的基本概念
程序中断是指在计算机执行程序的过程中，出现某些急需处理的异常情况或特殊请求，CPU暂时中止现行程序，而转去对这些异常情况或特殊情况进行处理，处理完毕后再返回到现行程序的断点处，继续执行原程序。早期的中断技术是为了处理数据传送。
中断技术有下面的功能：
- 实现CPU与I/O设备的并行工作
- 处理硬件故障和软件错误
- 实现人机交互，用户干预机器需要用到中断系统
- 实现多道程序，分时操作，多道程序的切换需要借助中断系统
- 实时处理需要借助中断系统来快速响应
- 实现应用程序和操作系统（管态程序）的切换，称为“软中断”
- 多处理器系统中各处理器之间的信息交流和任务切换
程序中断方式如下所示：
![Screenshot_2023-08-18-16-49-17-486_com.newskyer.draw.png](../_resources/Screenshot_2023-08-18-16-49-17-486_com.newskyer.dr.png)

2. 程序中断的工作流程
- 中断请求
    中断源是请求CPU中断的设备和事件，一台计算机允许有多个中断源。每个中断源向CPU发出中断请求的时间是随机。为记录中断事件并区分不同的中断源，中断系统需对每个中断源设置中断请求标记触发器，当其状态为“1”时，表示中断源有请求。这些触发器可组成中断请求标志寄存器，该寄存器可集中在CPU中，也可分散在各个中断源中。
> 通过INTR线发出的是可屏蔽中断， 通过NMI线发出的是不可屏蔽中断。

- 中断优先响应级判优
    中断响应优先级是指CPU响应中断请求的先后顺序。由于许多中断源提出中断请求的时间都是随机的，因此当多个中断源同时提出中断请求时，需通过中断判优逻辑来确定响应哪个中断源的请求，中断响应的判优通常是通过硬件排队器实现的。
    一般来说，$不可屏蔽中断 > 内部异常 > 可屏蔽中断$，内部异常中：$硬件故障> 软件中断$，==DMA中断请求优先于I/O设备传送的中断请求==，在I/O传送类指令中，高速设备优先于低速设备，输入设备优先于输出设备，实时设备优先于普通设备。
- CPU响应中断的条件
    CPU在满足一定条件下响应中断源发出的中断请求，并经过一些特定的操作，转去执行中断服务程序。CPU响应中断需要满足下面的条件：
    - 中断源有中断请求
    - CPU允许中断及开中断（异常和不可屏蔽中断不受此限制）
    - 一条指令执行完毕（异常不受此限制，一条指令指的是当前上处理机执行的指令），且没有更紧迫的任务
> I/O设备的就绪时间是随机的，而CPU在统一的指令执行周期的中断周期向接口发出中断查询信号，以获取I/O中断请求，即CPU响应I/O中断的时间是在每条指令执行的结束时刻

- 中断响应过程
    CPU响应中断后，经过某些操作，转去执行中断程序。这些操作是由硬件直接实现的，我们将它称为==中断隐指令==。中断隐指令并不是指令系统中的一条真正的指令，而是一种虚拟的说法，本质上是==硬件的一系列操作==。其完成的步骤如下；
    - 关中断。CPU响应中断后，首先==保护程序断点和现场信息==，在保护断点和现场的过程中，CPU不能响应更高级中断源的中断请求。保存断点和现场保存是原子操作。
    - 保存断点。为保证在中断服务程序执行完成后能正确的返回到原来的程序，必须将原程序的断点保存在栈或特定寄存器中。
    注意中断和异常的差别：异常指令通常本条指令没有执行成功，在异常处理好需要返回当前指令的断点处重新执行该指令，而中断的断点是下一条指令的地址。
    - 引出中断服务程序。识别中断源，将对应的服务程序入口地址送入程序计数器PC。一般有两种方法可以识别中断源：硬件向量法和软件查询法。
- 中断向量
    中断识别分为向量中断和非向量中断两种，非向量中断即软件查询法。
    每个中断都有一个唯一的类型号，每个中断类型号都对应一个中断服务程序，每个中断服务程序都有一个入口地址，CPU必须找到这个入口地址，即==中断向量(中断程序的主存起始地址)==。把系统中的全部中断向量集合中存放到存储器的某个区域内，这个存放的中断向量主存区域就叫==中断向量表==。==（注意中断向量表中存放的并不是中断服务程序，而是每个中断向量）==
    CPU响应中断后，通过识别中断源获得中断类型号，然后根据计算出对应中断向量的地址，再根据该地址从中断向量表中取出中断服务程序的入口地址也即中断向量，并送入程序计数器PC，以转而执行中断服务程序。这种方法被称为中断向量法，采用中断向量法的中断被称为向量中断。
- 中断处理程过程
    中断处理流程如下：
    - 关中断
    - 保存断点
    - 中断服务程序寻址
    - 保存现场和屏蔽字
    - 开中断。允许更高级中断请求被响应，实现中断嵌套
    - 执行中断服务程序
    - 关中断
    - 恢复现场和屏蔽字
    - 开中断，中断返回
    其中，前三步为中断隐指令（硬件自动完成），后面的步骤由中断服务程序完成。
>恢复现场是指在中断返回前，必须将寄存器堆内容恢复到中断处理前的状态，这部分工作由中断服务程序完成。中断返回由中断服务程序的最后一条中断返回指令完成

3. 多重中断和中断屏蔽技术
    若CPU在执行中断服务程序的过程中，又出现了新的更高优先级的中断请求，而CPU对新的中断请求不予响应，则这种中断称为单重中断，如下（a）所示。若CPU暂停现行的中断服务程序，转去处理新的中断请求，则这种中断称为多重中断，又称中断嵌套，如下（b）所示。
![Screenshot_2023-08-19-13-55-27-102_com.newskyer.draw.png](../_resources/Screenshot_2023-08-19-13-55-27-102_com.newskyer.dr.png)
    CPU要具备多重中断的功能，必须满足下列条件：
    - 在中断服务程序中提前设置开中断指令
    - 优先级更高的中断源有权中断优先级别低的中断源
    中断处理优先级是指多重中断的实际优先处理顺序，可以利用中断屏蔽技术动态调整，从而灵活调整中断服务程序的优先级，使中断处理更加灵活。每个中断源都有一个屏蔽触发器，1表示屏蔽该中断源的请求，0表示可以正常申请，所以屏蔽触发器组合在一起便构成一个屏蔽字寄存器，屏蔽字寄存器堆内容称为屏蔽字。屏蔽字中“1”越多，优先级越高，每个屏蔽字至少有1个“1”，即至少可以屏蔽来自自身的中断，下面举例说明：
   假设某计算机中有4个中断源$A,B,C,D$，其硬件排队优先次序为$A>B>C>D$，先要求将中断处理次序改为$D>A>C>B$。要求给出每个中断源对应的屏蔽字。
    根据中断处理次序，D具有最高优先级，可以屏蔽其他所有中断，且不能中断自身，因此D对应屏蔽字为1111，以此类推，得到4个中断源屏蔽字如下:
![Screenshot_2023-08-19-14-05-18-502_com.newskyer.draw.png](../_resources/Screenshot_2023-08-19-14-05-18-502_com.newskyer.dr.png)
### 7.2.3 DMA方式（块设备）
DMA方式是一种完全由硬件进行成组信息传送的控制方式，它具有程序中断方式的优点，即在数据准备阶段，CPU与外设并行工作。DMA方式在外设与内存之间直接开辟了一条“直接数据通路”。信息传送不需要通过CPU，降低了CPU在传送数据时的开销，因此称为直接存储器存取方式。由于数据不经过CPU，也就不需要保护，恢复CPU现场等烦琐操作。
1.DMA方式的特点
    主存和DMA接口之间有一条直接数据通路。由于DMA方式传送数据不需要经过CPU，因此不必中断现行程序。I/O与主机并行工作，程序和传送并行工作。
    DMA方式具有下列特点：
   - 它使主存与CPU的固定关系脱钩，主存既可被CPU访问，又可被外设访问。
   - 在数据块传送时，主存地址的确定，传送数据的计数等都由硬件电路直接实现。
   - 主存中要开辟专用缓冲区，及时供给和接收外设的数据
   - DMA的传送数据极快，CPU和外设并行工作，提高了系统效率
   - DMA在传送开始前要通过程序进行预处理，结束后要通过中断方式进行后处理

2.DMA控制器的组成
    在DMA方式中，对数据传送过程进行控制的硬件称为DMA控制器（DMA接口）。当I/O设备需要进行数据传送时，通过DMA控制器向CPU提出DMA传送请求，CPU响应之后将让出系统总线，由DMA控制器接管总线进行数据传送。其主要功能如下：
   - 接受外设发出的DMA请求，并向CPU发出总线请求
   - CPU响应并发出总线响应信号，DMA接管总线控制权，进入DMA操作周期
   - 确定传送数据的主存单元地址及长度，并自动修改主存地址计数和传送长度计数
   - 规定数据在主存和外设间的传送方向，发出读写等控制信号，执行数据传送操作
   - 向CPU报告DMA操作结束
   下图给出了一个简单的DMA控制器：
![Screenshot_2023-08-19-14-24-49-161_com.newskyer.draw.png](../_resources/Screenshot_2023-08-19-14-24-49-161_com.newskyer.dr.png)

其中：
- 主存地址计数器：存放要交换数据的主存地址
- 传送长度计数器：记录传送数据的长度，计数溢出时，数据即传送完毕，自动发中断请求信号
- 数据缓冲寄存器：暂存每次传送的数据
- DMA请求触发器：每当I/O设备准备好数据后，给出一个控制信号，使DMA请求触发器置位
- “控制/状态”逻辑：由控制和时序电路及状态标志组成，用于指定传送方向，修改传送参数，并对DMA请求信号，CPU响应信号进行协调同步
- 中断机构：当一个数据块传送完毕后触发中断机构，向CPU提出中断请求
    在DMA传送过程中，DMA控制器将接管CPU的地址总线，数据总线和控制总线，CPU的主存控制信号被禁止使用。而当DMA传送结束后，将恢复CPU的一切权利并开始执行其他操作。因此，DMA控制器必须具备控制系统总线的能力。

3.DMA的传送方式
    主存和I/O设备之间交换信息时，不通过CPU。但当I/O设备和CPU同时访存时，可能发生冲突，为了有效使用主存，DMA控制器和CPU通常采用下面3种方式使用主存：
   - 停止CPU访存。即当I/O设备有DMA请求时，由DMA控制器向CPU发生一个停止信号，使CPU脱离总线，停止访问主存，直到DMA传送一块数据结束。数据传送结束后，DMA控制器通知CPU可使用主存，并将总线控制权交还CPU。
   - 周期挪用（或周期窃取）。当I/O设备有DMA请求时，会发生三种情况：(1)此时CPU不在访存，因此I/O的访存请求与CPU未发生冲突，DMA可直接接管总线进行访存；(2)CPU正在访存，此时必须待当前存储周期结束后，CPU再将总线占用权让出；(3)I/O和CPU同时发出访存请求，出现访存冲突，此时CPU要暂时放弃总线占用权。I/O访存的优先级高于CPU访存，因为I/O不立即访存有可能丢失数据，此时I/O设备挪用一个或几个存储周期，传送完一个数据后立刻释放总线，这是一种单字传送方式。
   - DMA和CPU交替访存。这种方式适用于CPU的工作周期比主存存取周期长的情况。例如，若CPU的工作周期是$1.2\mu s$，主存的存取周期小于$0.6 \mu s$，则可将一个CPU周期分为$C_1,C_2$两个周期，其中$C_1$专供DMA访存，$C_2$专供CPU访存。总线使用权通过$C_1$和$C_2$分时控制。

4.DMA的传送过程
    DMA的数据传送过程分为预处理，数据传送和后处理三个阶段：
   - 预处理。由CPU完成一些必要的准备工作。首先，CPU执行几条I/O指令，用以测试I/O设备状态，初始化DMA控制器中的有关寄存器，设置传送方向，启动该设备等。然后，CPU继续执行原来的程序，直到I/O设备准备好发送的数据或接受的数据时，I/O设备向DMA控制器发送DMA请求，再由DMA向CPU发生总线请求（有时将这两个过程统称为DMA请求），用以传送数据。
   - 数据传送。DMA的数据传输可以以单字（或）字位基本单位，也可以以数据块为基本单位。需要注意数据传送阶段完全由DMA（硬件）控制
   - 后处理。DMA控制器向CPU发生中断请求，CPU执行中断服务程序做DMA结束处理，包括校验送入主存数据是否正确，测试传送过程中是否出错以及决定是否继续使用DMA传送其他数据等。传送流程大致如下所示：
![Screenshot_2023-08-19-15-01-33-436_com.newskyer.draw.png](../_resources/Screenshot_2023-08-19-15-01-33-436_com.newskyer.dr.png)

5.DMA方式和中断方式的区别
    DMA方式和中断方式的重要区别如下：
   - 中断方式是程序的切换，需要保护和恢复现场；而DMA方式不中断现行程序，无需保护现场，除了预处理和后处理，其他时候不占用任何CPU资源。
   - 对中断请求的响应只能发生在每条指令执行结束时（执行周期后）；而DMA请求的响应可以发生在任意一个机器周期结束时（取值，间址，执行周期均可，只要总线空闲即可响应DMA请求）。
   - 中断传送过程需要CPU的干预；而DMA传送过程不需要CPU的干预，因此数据传输率非常高，适合于高速外设的成组数据传送。
   - DMA请求的优先级高于中断请求。
   - 中断方式具有处理异常事件的能力，而DMA方式仅局限于大批数据的传送。
   - 从数据传送来看，中断方式靠程序传送，DMA方式靠硬件传送。