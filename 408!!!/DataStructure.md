# 1.绪论
>这部分考点主要涉及到时间，空间复杂度的计算，几乎每年的出题都是1小题（2分），代码题第三问（3分）
## 1.1 从往年的命题趋势上看，一般需要进行一些简单的计算，==推导出循环或者递归内部的任意一条语句频度(i)与条件边界值(n)的关系，再反解出i关于n的高阶无穷大形式即可==，除22年出了一个双层循环嵌套等比求和的较难的题目外，其他题目中规中矩正常计算即可
## 1.2大题，一般选择较为熟悉的算法模板，不求找出最优解，在能解决问题的条件上尽可能保持时间空间复杂度低，使用熟悉的方法，比如暴力，套排序模板（快排）时间空间复杂度都比较好分析
# 2.线性表
>算法大题命题的重点
## 2.1 基本概念
>主要掌握线性表的定义以及一些基本的线性表操作

1.定义:相同数据类型的n个数据元素的有限序列，除了第一个元素外，每个元素有且仅有一个直接前驱，除了最后一个元素外，每个元素有且仅有一个直接后继
2.基本操作
```cpp
InitList(&L): //初始化表
Length(L): //求表长
LocateElem(L,e): //按值查找操作
GetElem(L,i): //按位查找操作
ListInsert(&L,i,e): //插入操作
ListDelete(&L,i,&e): //删除操作
PrintList(L): //输出操作
Empty(L): //判空操作
DestroyList(&L): //销毁操作
```
## 2.2线性表的实现：两种线性表的存储方式
### 2.2.1顺序存储：==逻辑相邻，物理相邻，支持随机访问==，但插入删除需要移动大量元素
结构体定义
```cpp
#define MaxSize 50 //最大长度
typedef struct {
    ElemType data[MaxSize];//静态分配
    ElemType *data;//动态分配
    int length;
}SqList;
L.data=new ElemType[InitSize];//动态分配时申请内存空间
```
### 2.2.2 链式存储（小题爱考）：==逻辑相邻，物理离散分布==
1.单链表
```cpp
typedef struct LNode{ //结构体定义
    ElemType data; //数据域
    struct LNode *next; //指针域
}LNode,*LinkList;
```    
- 通常用一个头指针标识一个单链表（带头指针和不带头指针，即第一个指针指向的是空元素还是第一个实体元素，一般选择带头指针便于统一与其他表的一致便于操作）
- 建立单链表包括两种方式：头插法和尾插法，前者在插入时每次将新元素指针插入最前端，后者则插入最末段。
- 查找分为按序查找和按值查找，由于链表不支持随机访问，所以上述两种查找方式均需遍历整个链表即时间复杂度为O(n)
- 对链表的插入以及删除操作，考试时画示意图即可，代码不必死记硬背，需要注意的是与顺序表不同，由于链表在物理上离散存储，仅通过指针链接上下元素，在删除及插入时不需要移动后续的元素，修改相邻节点指针即可
2.双链表
```cpp
  typedef struct DNode{ //结构体定义
    ElemType data; //数据域
    struct DNode *prior,*next; //前驱和后继指针
}DNode,*DLinkList;
```
- 插入操作
  假如在双链表p所指节点后插入节点*s，插入片段代码如下
  ```c
  s->next=p->next; //1
  p->next->prior=s; //2
  s->priot=p; //3
  p->next=s; //4
  ```
        上述语句顺序不唯一，但需要注意的是1,2两步必须在4之前，否则p的后继节点将失去索引，导致插入失败
- 删除操作，假设删除双链表p的后继节点q
  ```c
  p->next=q->next;
  q->next->prior=p;
  free(q);
  ```
  上述的插入删除只是给出样例，实际考试中情形不可能原翻不动，解决问题的关键在于画出节点示意图，推断出每一步都代码逻辑顺序即可，不必死记硬背，特别注意==对指向后驱节点的指针操作往往要放到后面完成==，防止后驱指针改变后无法找到原来的后驱节点

3.循环链表
分为循环单链表和循环双链表，本质上与单链表和双链表无异，只不过==最后一个指针不指向NULL而是指向头节点==，从而整个链表构成一个环路，做题时仍然画出有关示意图推理即可

4.静态链表
借助==数组==来描述链式存储，与上述链表不同的是，静态链表指针指向的是==存储的数组下标(相对地址)==，静态链表需要预先申请一块的连续内存空间，以next=-1结束，插入删除与动态链表相同不需要移动元素，不支持随机查找，静态链表的指针就是数组的下标。
## 2.3 顺序表和链表的比较
1. 存取（读写方式）
    顺序表可以顺序存取也可以随机存储，而链表只能从表头顺序读取元素，故顺序表访问一个随机元素平均时间复杂度为$O(1)$,链表则为$O(n)$   
2. 逻辑结构和物理结构
    顺序表逻辑物理上均连续，链表逻辑上连续，物理上离散
3. 查找，插入和删除操作
    对于按值查找，顺序表无序时，两者的时间复杂度均为$O(n)$,顺序表有序时，可采用二分查找，此时时间复杂度为$O(log_2n)$。
    对于按序查找，顺序表支持随机访问，时间复杂度仅为$O(1)$，但链表的平均复杂度为$O(n)$。
    顺序表的插入，删除操作平均需要移动半个表长的元素，而链表仅需修改相关结点的指针即可。
    由于链表的每个结点都带有指针域，故而存储密度不够大。
4. 空间分配
    顺序存储在静态存储分配情况下，存储空间在整个程序运行期间都是固定值不能修改，灵活性较低。而链式存储的结点空间只在需要时申请分配，只要内存有空间就可分配，操作灵活，高效。
# 3.栈，队列和数组
>小题考察的重点，几乎每年都会在这部分根据栈，队列以及矩阵存储的性质计算出1~2个小题
## 3.1 栈
### 3.1.1 栈的定义以及基本操作
栈是只允许在一端==进行插入或删除操作（操作受限）==的线性表，性质概括为==先进后出（First In Last Out,FILO）==,或者后进先出
数学性质：n个不同元素进栈，出栈元素不同排列的个数为(卡特兰数)
>注：n个节点的二叉树的不同形式个数也是卡特兰数
$$
C_n = \frac{{1}}{{n+1}} C^n_{2n} \quad \text{{for }} n \geq 0 
$$
$$
OR \quad C_n = \frac{{1}}{{n+1}} \binom{{2n}}{{n}} = \frac{{(2n)!}}{{(n+1)!n!}} \quad \text{{for }} n \geq 0
$$
基本操作
```cpp
InitStack(&S): //初始化空栈S
StackEmpty(S): //判空
Push(&S,&x): //进栈
Pop(&S,&x): //出栈
GetTop(S,&x): //读栈顶元素
DestroyStack(&S): //销毁栈
```
### 3.1.2 栈的顺序存储结构
1. 顺序栈的定义
```cpp
#define MaxSize 50
typedef struct { //顺序栈结构体定义
    ElemType data[MaxSize]; //栈中元素
    int top; //栈顶指针
}SqStack;
```
基本运算的代码实现不做过多赘述，代码题可直接调用基本函数
但需要注意到的是，一般来说栈顶指针初始指向NULL，此时入栈==指针先++再入栈==，出栈时，==先出栈指针再－－==，若初始指针指向栈底元素，则出入栈时指针±与出入栈操作需调换顺序
2. 共享栈
两个顺序栈共享同一个一维数组空间，两个栈底分别设置在数组两端，进栈向数组中间方向进栈，当```top1-top0==1```时，判断双栈满

![Screenshot_2023-06-30-17-27-45-280_com.newskyer.draw.png](../_resources/Screenshot_2023-06-30-17-27-45-280_com.newskyer.dr.png)
3. 链式存储结构
又称为链栈，便于多个栈共享存储空间提高效率，不存在栈上溢情况。规定所有操作在单链表的表头进行，链栈不带头节点，Lhead指向栈顶元素，入栈和出栈的操作都在链栈底表头进行
```cpp
typedef struct LinkNode{ //链式栈结构体定义，基本与单链表无异
    ElemType data; //数据域
    struct LinkNode *next; //指针域
}*LiStack;
```

## 3.2 队列
### 3.2.1队列的基本概念及基本操作
队列是只允许==在一段进行插入(队尾)，另一段进行删除(队头)（操作受限）==的线性表，性质概括为==先进先出（Frist In Frist Out,FIFO）==
基本操作
```cpp
InitQueue(&Q): //初始化队列
QueueEmpty(Q): //判队列空
EnQueue(&Q,x): //入队
DeQueue(&Q,&x): //出对
GetHead(Q,&x): //读取队头元素
```
### 3.2.2队列的顺序存储结构
1.队列的顺序存储
```cpp
#define MaxSize 50;
typedef struct{
    ElemType data[MaxSize];
    int front,rear;
}SqQueue;
```
初始时```Q.front==Q.rear==0```,但经过若干次入队出队操作后，若使用条件`Q.rear==MaxSize`判断队满，可能出现front指针指向rear相邻元素，此时入队出现上溢，但data数组中仍然存在可以存放元素的位置，故造成了假溢出
2.循环队列
引出循环队列，将队列变成逻辑上的闭环，称之为循环队列，遍历指针可以通过对M取余实现：
```cpp
Q.front=Q.rear=0; //初始时
Q.front=(Q.front+1)%MaxSize; //队首指针＋＋，出队
Q.rear=(Q.rear＋1)%MaxSize; //队尾指针＋＋，入队
length=(Q.rear+Maxsize-Q.front)%MaxSize; //队列长度
```
上面的循环队列仍然存在问题：易知当对空队满时均有```Q.front==Q.rear```,无法区分这两种状态，故存在下面三种解决方法：
- ==牺牲一个单元来区分队满和队空==（最常见的做法），此时有：
队满条件：```(Q.rear+1)%MaxSize==Q.front```
队空条件：```Q.front==Q.rear```
某时刻队列中元素个数：```(Q.rear+MaxSize-Q.front)%MaxSize```

- 结构体定义中增加变量表示元素个数，则此时队空即```Q.size==0```,队满为```Q.size==MaxSize```
- 结构体定义中增加变量tag,tag=0表示因删除导致了```Q.front==Q.rear```,则为队空;tag=1表示因插入导致了```Q.front==Q.rear```，则为队满
### 3.2.2队列的链式存储结构
又称为链队列，实际上就是一个同时带有队头指针和队尾指针的单链表，头指针指向队头节点，尾指针指向队尾节点（与顺序存储不同，顺序存储在入队时，先赋值队尾指针再＋＋,队尾指针指向的是一个此时刻不在队列内的位置，也即队尾指针可能越界，但链队的队尾指针一直指向队尾节点）
一般为了使得插入和删除操作得到统一，一般采用带头结点的单链表
```cpp
typedef struct LinkNode{  //链式队列节点
    ElemType data;
    struct LinkNode *next;
}LinkNode;
typedef struct{     
    LinkNode *front,*rear;  //队列的队头和队尾指针
}LinkQueue;
```
基本操作与顺序存储一致，插入删除时遵循单链表的操作即可
### 3.2.2双端队列
>小题的高频考点，解决这类问题的关键在于根据题目的描述画出有关队列示意图，模拟过程求解

- 双端队列是指允许两端可以进行入队和出队操作的队列，其元素的逻辑结构仍是线性结构，将队列的两端成为前端和后端，两端都可以入队和出队
- 输出受限的双端队列:允许在一端进行插入和删除，但在另一端只允许插入的双端队列
- 输入受限的双端队列:允许在一端进行插入和删除，但在另一端只允许删除的双端队列
## 3.3栈和队列的应用
> 重难点在于栈在表达式求值中的应用，可能会在小题中考察中缀表达式转后缀（前缀）表达式时某一时刻中栈的情况，也即需要掌握机算的过程
### 3.3.1 栈在括号匹配中的作用
简述一下算法思想，其实很简单，就是检测一串序列中括号的嵌套是否合法，可以先设置一个空栈，当扫描到左括号时，将此括号压入栈中，扫描到右括号时，弹出栈顶对应（比如[],{}）的左括号，最后程序退出时，若栈空则序列合法，否则匹配失败。
### 3.3.2栈在表达式求值中的应用
三个主要问题
- 手算中缀表达式与后缀（前缀）表达式的互相转换
  前缀和后缀表达式的区别就在于运算符写在操作数前面还是后面，手算时，先考虑高优先级（如括号内的运算），相同优先级时从左边开始写起（前缀表达式则相反从右边开始起算）
- 给出后缀表达值，机算求值的过程
   顺序扫描后缀表达式，如为操作数，则将其压入栈中，若该项是操作符```<OP>```，则连续一次从栈中出栈==两个操作数Y(后出栈),X(先出栈),形成运算符```X<OP>Y```==,并将结果压回占中，扫描结束后，栈顶存放的结果就是最后结果。（注意这里如果题目说明了有关操作数和OP的关系，则以题目为主）
- 机算中缀表达式转后缀（前缀）表达式的过程
  从左至右依次扫描中缀表达式，遵循以下原则：
  1. 如遇操作数，直接加入到后缀表达式中
  2. 如遇界限符，遇到'('时直接入栈，遇到')'则依次弹出栈中的运算符加入后缀表达式直到弹出上一个'('为止，注意'(',')'不加入后缀表达式，但占用栈空间
  3. 如遇到运算符，依次弹出栈内优先级高于或等于的所有运算符，并加入后缀表达式，若弹出碰见'('或栈空则停止，之后将本操作符压入栈中，如此时栈内无高于或等于当前操作数的运算符时，则直接将本操作符压入栈中。
### 3.3.3 栈在递归中的应用
408中对递归的复杂算法不会过度考察，知道递归调用时，系统为每一层的返回点，局部变量，传入实参等都开辟了递归工作栈来'保存现场'，在从表层到深层递归时，递归函数是依次入栈的。
### 3.3.4 队列在层次遍历中的应用
对树的层次遍历可使用队列，下面给出二叉树层次遍历的过程：
1. 根节点入队
2. 若队空（所有节点都已处理完毕），则结束遍历，否则重复3操作
3. 队列中第一结点出队，并访问，若该结点有左孩子则将左孩子入队，有右孩子则将右孩子入队，返回2
### 3.3.5 队列在计算机系统中的应用
可从两个方面来简述队列在计算机系统中的应用
- 设置某些数据缓冲区，解决主机与外部设备之间的速度不匹配问题
- 进程队列，解决多进程引起的系统资源竞争问题
## 3.4 数组和特殊矩阵
> 重点在于一些特殊矩阵的数组存储，以小题为主，记住每种特殊矩阵的结构特性，公式可不必死记硬背，理解现推即可
### 3.4.1 一般数组的存储结构
1. 以一维数组```A[0...n-1]```为例，其存储结构对应关系如下：
$$
LOC(a_i)=LOC(a_0)+i \times L \quad  (0 \leq i < n)
$$
其中,L是每个数组元素占存储单元的大小
2. 对于多维数组(一般认为是二维数组)而言,有两种映射方法：按行优先和按列优先。以二维数组为例，按行优先的意思是说先行后列，先存储行号较小的元素，行号相等先存储列号较小的元素。假设二维数组的行下标和列下标的范围分别为$[0,h_1]$与$[0,h_2]$，则存储结构关系式为：
$$
LOC(a_{i,j})=LOC(a_{0,0})+[i \times (h_2+1) + j] \times L \\
$$
> 其中$h_2+1$表示行长

当以列优先方式存储时，则存储结构关系式为：
$$
LOC(a_{i,j})=LOC(a_{0,0})+[j \times (h_1+1) + i] \times L \\
$$
>其中$h_1+1$表示列长
>注：上述公式仅仅给出参考，不需死记硬背，理解即可，但需要注意数组下标是从0开始还是从1开始，以及数组中的行长和列长
### 3.4.2 特殊数组的压缩存储
压缩存储的意思是说为多个值相同的元素只分配一个存储空间，对0元素不分配空间，节省存储空间
特殊矩阵是指许多相同矩阵元素或0元素，并且这些相同矩阵元素或0元素的分布具有一定规律，便于建立逻辑与物理位置间的映射，下面是一些常见的特殊矩阵存储压缩方式
1. 对称矩阵
   即在一个n阶矩阵A中任意一个元素$a_{i,j}$都有$a_{i,j}=a_{i,j} (1 \leq i, j \leq n)$,则称其为对称矩阵。对于n阶对称阵，上三角区(i<j)的元素和下三角区(i>j)的对应元素相同，所以将n阶对称阵存放在一维数组$B[n(n+1)/2]$中，下面讨论只存放下三角(包含主对角)元素：
   在数组B中，位于元素$a_{i,j}(i \geq j)$前面元素个数为
   第1行：1个元素$(a_{1,1})$
   第2行：2个元素$(a_{2,1},a_{2,2})$
   ...
   第i-1行：i-1个元素$(a_{i-1,1},a_{i-1,2},...,a_{i-1,i-1})$
   第i行：i个元素$(a_{i,1},a_{i,2},...,a_{i,i})$
   因此，元素$a_{i,j}$在数组B中的下标$k=1+2+...(i-1)+j-1=i(i-1)/2+j-1$(数组下标从0开始)，所以，元素下标之间的对应关系如下:
$$
k = \begin{cases}
    \frac{i(i-1)}{2} + j-1, &  i \geq j (下三角和主对角元素)\\
    \frac{j(j-1)}{2} + i-1, &  i < j (上三角区元素a_{i,j}=a_{j,i},ij互换即可)
\end{cases}
$$
>注：这里$a_{i,j}$中的i,j均表示第几个元素，二维数组中```A[n][n]```和```A[0...n-1][0...n-1]```的写法是等价的。如果数组写成```A[1...n][1...n]```，则说明指定了下标从1开始存储元素，二维数组元素写为```a[i][j]```,这里的数组下标i,j通常是从0开始的,而表示矩阵元素的$a_{i,j}$或$a_{(i,j)}$，这里的i,j是从1开始的

2. 三角矩阵
   分为上，下三角矩阵。以下三角矩阵为例，其上三角区的所有元素为同一常量。其存储思想与对称矩阵相似，先存储下三角及主对角元素，在最后存储上三角区常量，故可将n阶下三角矩阵压缩到$B[n(n+1)/2+1]$中。元素下标之间的映射关系如下：
$$
k = \begin{cases}
    \frac{i(i-1)}{2} + j-1, &  i \geq j (下三角和主对角元素)\\
    \frac{n(n+1)}{2} , &  i < j (上三角区元素)
\end{cases}
$$ 
   对于上三角矩阵，在数组B中，位于元素$a_{i,j}(i \geq j)$前面元素个数为
   第1行：n个元素
   第2行：n-1个元素
   ...
   第i-1行：n-i+2 or n-((i-1)-1)个元素
   第i行：j-i+1个元素
   因此，元素$a_{i,j}$在数组B中的下标$k=n+(n-1)+...+(n-i+2)+(j－i+1)-1=\frac{(i-1)(2n-i+2)}{2}+(j-i)$(数组下标从0开始)，所以，元素下标之间的对应关系如下:
$$
k = \begin{cases}
    \frac{(i-1)(2n-i+2)}{2} + (j-i), &  i \leq j (上三角和主对角元素)\\
    \frac{n(n+1)}{2} , &  i > j (下三角区元素)
\end{cases}   
$$
>注：以上关系对应均假设数组下标从0开始，若题设有具体要求，则应具体分析

3. 三对角矩阵
对角矩阵也称带状矩阵，行如下图所示的矩阵成为三对角矩阵，在三对角矩阵中，所有非0元素都集中在以主对角元线为中心的3条对角线的区域，其他元素均为0，将三对角元素按行优先方式存放在一维数组B中，且$a_{1,1}$存放在$B[0]$中，则3条对角线上的元素$a_{i,j}$在一维数组B中的下标为$k=2i+j-3$,(可以这么理解，前$i-1$行中共有$3(i-1)-1$个元素，而第$i$行中有$j-i+2$个元素，所以总共有$2i+j-2$个元素，由于下标从0开始再－1)
$$
\begin{bmatrix}
a_{1,1} & a_{1,2} & 0 & \cdots & \cdots & \cdots & 0 \\
a_{2,1} & a_{2,2} & a_{2,3} & 0 & \cdots & \cdots & 0 \\
0 & a_{3,2} & a_{3,3} & a_{3,4} & 0 & \cdots & 0 \\
\vdots & \ddots & \ddots & \ddots & \ddots & \ddots & \vdots \\
0 & \cdots & 0 & a_{n-2,n-3} & a_{n-2,n-2} & a_{n-2,n-1} & 0 \\
0 & \cdots & \cdots & 0 & a_{n-1,n-2} & a_{n-1,n-1} & a_{n-1,n} \\
0 & \cdots & \cdots & \cdots & 0 & a_{n,n-1} & a_{n,n} \\
\end{bmatrix}
$$
反之，若已知三对角线矩阵中某一元素$a_{i,j}$在数组B中的下标k，反求i,j，则关键在于求出i，可以这样考虑，前$i-1$行中共有$3(i-1)-1$个元素，而前$i$行中共有$3i-1$个元素，则有不等式$3(i-1)-1<K+1 \leq 3i-1$,解得$i \geq (k+2)/3 ,即 i=\lceil (k+2)/3 \rceil$ ，解出i后根据上面的$k=2i+j-3$可知$j=k-2i+3$。(注意这里的k表示的是下标，如果题设给出的是第k个元素，则在不等式中把k+1替换成k即可)
>注：再次强调上面所给公式不需死记硬背，题目随便换个条件公式就不可用了，需要理解并记住公式推导的过程，在做小题时，若选项给出通项，可以代入几个特殊点去快速选出答案，不必一步步详细推导

### 3.4.3 稀疏矩阵
矩阵中非零元素的个数t相对矩阵中元素的个数s来说非常少，即可以简单理解为一个矩阵中大部分的元素都是0，则成为稀疏矩阵，比如一个矩阵阶为100，但该矩阵中只有少于100个非零元素。
存储时将非零元素及其对应的行和列构成一个==三元组(行标，下标，值)==,除三元组外可能还需要存储稀疏矩阵的==总行数和总列数(23 408真题)==,然后按规律存储这些信息，但稀疏矩阵经压缩存储后便失去了随机存取的特性。另外，稀疏矩阵的三元组除了可以用数组存储外，还可以用十字链表发存储，但该方法过于复杂，考察概率较低，知道有这个方法就行

# 4 串的模式匹配
> 重点掌握KMP以及改进的KMP算法，不太可能考大题，考也是考应用题，主要理解算法原理
## 4.1 简单的模式匹配算法
子串的定位操作通常成为串的模式匹配，它求的是子串（通常称模式串）在主串的位置，这里给出一种暴力匹配算法
```cpp
int Index(SString S,SString T){
    int i=1,j=1;
    while(i<=S.length && j<=T.length){
        if(S.ch[i]==T.ch[i]){
            ++i;++j; //继续比较后续字符
        }
        else{
            i=i-j+2;j=1; //指针回退重新开始匹配
        }
    }
    if(j>T.length) return i-T.length;
    else return 0;
}
```
简单模式匹配算法的最坏时间复杂度为$O(mn)$，其中n和m分别为主串和模式串的长度。
## 4.2 串的模式匹配算法-KMP算法
KMP算法的关键之处在于求出next数组，求出next数组后，在匹配子串失败时，主串指针不需要回退，只需模式串向右移动即可，下面给出求解next数组的手算过程：
假设有模式串`T='abaabc'`,求出next数组：
首先next数组的长度一般等于模式串长度+1(这是为了下标从1开始，也可以只使用n个空间，下标从0开始),对前两个元素`next[1]=0,next[2]=1`，即从第三个开始求，在不匹配的位置前，划一条线，依次使模式串右移，i,j指针不动，当分界线前可以完全匹配时停止，此时j指向的模式串位置即为该下标值，否则置为1。

![Screenshot_2023-07-04-15-25-28-712_com.newskyer.draw.png](../_resources/Screenshot_2023-07-04-15-25-28-712_com.newskyer.dr.png)
根据上述的过程可知最后的next数组应为：

<center>

|j|0|1|2|3|4|5|6|
|--|--|--|--|--|--|--|--|
|next\[i\]|-1|0|1|1|2|2|3|

</center>

>注意next数组中的值由于下标算法不同，可能结果会同时±1

在求出了next数组之后，KMP匹配的思想大致与简单模式匹配算法一致，不同之处在于当匹配过程失败时，指针i保持不变，而指针j回退到next\[j]的位置并重新比较，并且当指针j为0时，指针i和j同时加1。即若主串的第i个位置和模式串的第一个字符都不相同，则应从子串的i+1个位置开始匹配。代码如下
```cpp
int Index_KMP(SString S,SString T,int next[]){
    int i=1,j=1;
    while(i<=S.length && j<=T.length){
        if(j==0 || S.ch[i]==T.ch[i]){
            ++i;++j; //继续比较后续字符
        }
        else{
            j=next[j]; //模式串向右移动
        }
    }
    if(j>T.length) return i-T.length; //匹配成功
    else return 0;
}
```
尽管普通模式匹配的时间复杂度为$O(mn)$，KMP算法的时间复杂度为$O(m+n)$，但在一般情况下，普通模式匹配的实际执行时间近似为$O(m+n)$，因此至今仍被采用。KMP算法仅在主串与子串有很多“部分匹配”时才显得比普通算法快得多，其主要的优点是主串不需要回溯。
## 4.2 KMP算法的进一步优化
前面定义的next数组在某些情况下仍存在缺陷，对于上面的例子，模式串`T='abaabc'`，求得的next数组为：

<center>

|j|0|1|2|3|4|5|6|
|--|--|--|--|--|--|--|--|
|next\[i\]|-1|0|1|1|2|2|3|

</center>

考虑这样一个情况：假设模式串从主串起点处开始匹配，当匹配到第3个位置时，发现字符匹配失败，则按照KMP的思想，此时应该更新j指针为next\[3]
即1，模式串从第一个位置：a开始匹配，但是由于模式串的第三个位置就是a，可知此时i指针指向的一定不是a,所以更新j后必然匹配失败，此时j指针再次更新为0，在这个过程中，j指针的第一次更新其实是冗余的，因为我们已经知道了这次匹配肯定会失败，所以优化思路从此而来，即更新next数组为nextval，把出现上述情况的next数组指针更新，减少冗余计算，下面给出手算的思路：
`nextval[1]=0`,从nextval\[2]开始，若此时模式串的该位置字符与数组值所指位置字符一致，则应更新值为nextval中数组值索引的值；若不一致，则保持原next中的值。对于上面的例子，更新后的nextval值应为：

<center>

|j|0|1|2|3|4|5|6|
|--|--|--|--|--|--|--|--|
|next\[i\]|-1|0|1|1|2|2|3|
|nextval\[i\]|-1|0|1|0|2|1|3|

</center>

代码示意如下：
```cpp
nextval[j]=0;
for (int j=2;j<T.length;j++){
    if (T.ch[j]==T.ch[next[j]){
    nextval[j]=nextval[next[j]];
    else nextval[j]=next[j];
    }
}
```
对于匹配过程与KMP相同，只需要把next数组换成更新后的nextval数组即可。
# 5. 树与二叉树
## 5.1 树的基本概念
### 5.1.1 树的定义
树是n个结点的有限集，是一种递归的数据结构。其具有以下两个特点：
1. 树的==根节点没有前驱，除根节点外的所有结点有且仅有一个前驱==。
2. 树中==所有结点都可以有零个或多个后继==。
树适合表示具有层次结构的数据。树中的某个结点（根结点除外）最多和上一层的一个结点（即其父结点）有直接关系，根结点没有直接上层结点，因此在$n$个结点的树中有$n-1$条边。而树中每个结点与其下一层的零个或多个结点（即其子女结点）都有直接关系。
### 5.1.2 基本术语
1. 树中一个结点的孩子个数称为该结点的==度==，树中结点的==最大度数称为树的度==
2. 度大于0度结点称为分支结点（又称非终端结点）；度为0点的结点称为叶子结点（又称终端结点）。
3. 结点的深度，高度和层次
   结点的层次从树根开始定义，根节点为第1层，其子结点为第2层，以此类推。
   结点的深度是从根结点开始自顶向下逐层累加的。
   结点的高度是从根结点开始自底向上逐层累加的。
   树的高度（或深度）是==树中结点的最大层数==
5. 有序树和无序树：树中结点的各子树从左到右是有次序的，不能互换，则称该树为有序树，否则称为无序树。（树中各结点是否具有唯一标识符）
6. 路径和路径长度：树中两个结点之间的路径是由这两个结点之间所经过的结点序列构成的，而路径长度是路径上所经过的边的个数。（树中的有向，树中的路径均是从上向下的，同一双亲的两个孩子之间不存在路径）
7. 森林。森林是$m(m \geq 0)$棵互不相交的树的集合。森林即把树的根节点删去就成了森林，反之给m棵独立的树添加一个根结点，这m棵树作为其子树，则森林就变成了树
### 5.1.3 树的性质
树具有如下最基本的性质：
1. 树中的结点数等于所有结点的度数之和加1（每个结点有多少度，则有多少个孩子结点，加上根节点即为总结点数）。
2. 度为m或m叉树的第$i$层上至多有$m^{i-1} (i \geq 0)$个结点。
> 注意区分度为m的树以及m叉树，度为m的树是树中存在一个最大度数的结点，该结点的度为m，m叉树是指所有结点的度不超过m。度为m的树一定是非空树，至少有m+1个结点，而m叉树可以是空树。

3.高度为$h$的$m$叉树至多有$\frac{m^h-1}{m-1}$个结点（看做首项为1，公比为m，共有h项的等比数列求和）,至少有$h$个结点。高度为$h$的度为$m$的树至少有$h+m-1$个结点（一定存在一个度为m的结点）
4.具有$n$个结点的$m$叉树的最小高度为$\lceil log_m(n(m-1))+1 \rceil$
>不必死记硬背，这样理解，最小高度即树尽可能宽，所有结点的度都为m，则由3可知，n应大于前h-1层的最大总结点数，小于等于前h层的最大总结点数，故存在不等式$\frac{m^{h-1}-1}{m-1} < n \leq \frac{m^h-1}{m-1}$，解出h即可。

## 5.2 二叉树的概念
### 5.2.1 二叉树的定义及其主要性质
二叉树的定义不在赘述，注意二叉树是有序树以及与度为2点的树的区别

==几个特殊的二叉树==
1. 满二叉树
   一颗高度为$h$，且含有$2^h-1$个结点的二叉树称为满二叉树，即树中每层都含有最多的结点，其叶子结点均在最下一层，且除叶子结点之外的度数均为2。
   对满二叉树按层序编号：从根结点（根节点编号为1）起，自上而下，自左向右。对于编号为$i$的结点，若有父结点，则其父结点为$\lfloor i/2 \rfloor$,若有左孩子，则左孩子为$2i$；若有右孩子，则右孩子为$2i+1$。
   
![Screenshot_2023-07-05-16-32-21-994_com.newskyer.draw.png](../_resources/Screenshot_2023-07-05-16-32-21-994_com.newskyer.dr.png)

1. ==完全二叉树==
   高度为$h$,有$n$个结点的二叉树，当且仅当其每个结点都与高度为h的满二叉树中的编号$1...n$的结点一一对应时，称为完全二叉树（可以看做从满二叉树删除结点而来，但是删除时需满足自右向左，自下而上按倒序删除结点）。其特点如下：
- 若$i \leq \lfloor n/2 \rfloor$，则结点$i$为分支结点，否则为叶子结点。
- 叶子结点只可能在层次最大的两层上出现。对于最大层次中的叶结点，都依次排列在该层最左边的位置上。
- 若有度为1点结点，则==只可能有1个==，且该结点==只会有左孩子而无右孩子==。
- 按层序编号后，一旦出现某结点（编号为$i$）为叶子结点或者只有左孩子，则编号大于$i$的结点均为叶子结点。
- 若$n$为奇数，则每个分支结点都有左孩子和右孩子；若$n$为偶数，则编号最大的分支结点（编号为$n/2$）只有左孩子，无右孩子，其余分支结点均有左右孩子
2. 二叉排序树
    左子树上所有结点的关键字均小于根结点的关键字；右子树上所有结点的关键字均大于根结点的关键字；左右子树又各是一颗二叉排序树。
3. 平衡二叉/树
    树上任意一个结点的左子树和右子树的深度之差不超过1

==二叉树的性质==
1. 非空二叉树上的叶结点数等于度为2点结点数加1，即$n_0=n_2+1$
>证明：设度为0，1和2点结点个数分别为$n_0$,$n_1$和$n_2$则结点总数为$n=n_0+n_1+n_2$。又因为二叉树中只存在度为1和2的非根结点，其中度为1的结点会产生一个子结点，度为2点结点会产生两个子结点，加上一个根节点，故结点总数也可以表示为$n=n_1+2n_2+1$，所以有$n_0=n_2+1$。拓展到任意一棵树，若结点数量为$n$，则边的数量为$n-1$

2.非空二叉树上第$k$层上至多有$2^{k-1} (k \geq 1)$个结点。
3.高度为h的二叉树至多有$2^h-1 (h \geq 1)$个结点 
4.对完全二叉树按从上到下，从左到右的顺序依次编号$1,2,...,n$，则有以下关系：
- 当$i>1$时，结点$i$的父节点编号为$\lfloor i/2 \rfloor$，即当$i$为偶数时，其双亲的编号为$i/2$，它是父节点的左孩子；当当$i$为奇数时，其双亲的编号为$(i-1)/2$，它是父节点的右孩子。
- 当$2i \leq n$时，结点$i$的左孩子编号为$2i$，否则无左孩子。
- 当$2i+1 \leq n$时，结点$i$的右孩子编号为$2i+1$，否则无右孩子。
- 结点$i$所在层次（深度）为$\lfloor log_2i \rfloor + 1$。
5.具有$n$个$(n > 0)$结点的完全二叉树高度为$\lceil log_2{n+1} \rceil$或$\lfloor log_2n \rfloor + 1$。
>同样不需要死记硬背，这样理解，设完全二叉树的高度为$h$，则由完全二叉树的定义，$n$应大于前$h-1$层结点数，小于等于前$h$层结点个数，所以有以下不等式：$2^{h-1}－1 < n \leq 2^h-1$，根据不等式解出h即可。

6.对于完全二叉树，可以由结点数$n$推出度为0,1和2点结点个数$n_0$，$n_1$和$n_2$:
    完全二叉树最多只有一个度为1的结点，即
    $n_1=0 or 1$,
    又$n_0=n_2+1$->$n_0+n_2=2n_1+1$，即$n_0+n_2$一定是奇数
    所以 若完全二叉树有$2k$（偶数）个结点，则必有$n_1=1,n_0=k,n_2=k-1$
    同样的，若完全二叉树有$2k－1$（奇数）个结点，则必有$n_0=1,n_0=k,n_2=k-1$
### 5.2.2 二叉树的存储结构
1. 顺序存储
    顺序存储的意思是说，二叉树按自上而下，自左至右，从根结点开始编号（根结点为1），然后编号存在数组中，比如完全二叉树上编号为$i$的结点，存放在一维数组下标为$i-1$的单元中，从这种存储规则来看，完全二叉树和满二叉树采用顺序存储比较合适，树中结点序号可以唯一的反应结点之间的逻辑关系，这样既能提高存储密度又能利用数组下标确定结点在二叉树中的位置，以及结点之间的关系。
    但对于一般的二叉树而言，为了满足上面的存储规则，只能添加一些并不存在的空结点，让其每个结点与完全二叉树上的结点相对照。然而，在最坏情况下，一个高度为$h$且只有$h$个结点的单支树却要占据$2^h-1$个存储单元，存储密度较低。
2. 链式存储
    由于顺序存储对一般二叉树的存储密度较低，因此一般二叉树采用链式存储结构，用链表结点来存储二叉树中的每个结点，结构体定义如下：
```cpp
typedef struct BiTNode{
    ElemType data; //数据域
    struct BiTNode *lchild,*rchild; //左，右孩子指针
}BiTNode,*BiTree;
```
容易验证，在含有$n$个结点的二叉链表中，含有$n+1$个空链域。
> 重要结论，经常在选择题中进行考察，如实在忘记对应关系了，可以画两棵简单的树现推，知道和n有关系就行。

## 5.3 二叉树的遍历和线索二叉树
### 5.3.1 二叉树的遍历
由二叉树的递归定义可知，遍历一棵二叉树便要决定对根节点N，左子树L和右子树R的访问顺序。按照先遍历左子树再遍历右子树的原则，常见的遍历次序有先序（NLR），中序（LNR）和后序（LRN）三种遍历算法，其中“序”指的是根结点在何时被访问。
1. 先序遍历
   先序遍历（PreOrder）遍历过程如下：
- 访问根节点；
- 先序遍历左子树;
- 先序遍历右子树;
   可以简单概括为==根左右==
   代码如下（可能会考算法题，要求掌握）：
```cpp
void PreOrder(BiTree T){ //树采用链式存储，递归遍历
    if(T!==NULL){
        visit(T); //访问根节点
        PreOrder(T->lchild); //递归遍历左子树
        PreOrder(T->rchild); //递归遍历右子树
    }        
}
```
2. 中序遍历
   中序遍历（InOrder）遍历过程如下：
- 中序遍历左子树;
- 访问根节点；
- 中序遍历右子树;
- 可以简单概括为==左根右==
   代码如下（可能会考算法题，要求掌握）：
```cpp
void InOrder(BiTree T){ //树采用链式存储，递归遍历
    if(T!==NULL){
        InOrder(T->lchild); //递归遍历左子树
        visit(T); //访问根节点
        InOrder(T->rchild); //递归遍历右子树
    }        
}
```
3. 后序遍历
   后序遍历（PostOrder）遍历过程如下：
- 中序遍历左子树;
- 中序遍历右子树;
- 访问根节点；
- 可以简单概括为==左右根==
   代码如下（可能会考算法题，要求掌握）：
```cpp
void PostOrder(BiTree T){ //树采用链式存储，递归遍历
    if(T!==NULL){
        PostOrder(T->lchild); //递归遍历左子树
        PostOrder(T->rchild); //递归遍历右子树
        visit(T); //访问根节点
    }        
}
```
三种遍历算法中，递归遍历时左，右子树的顺序都是固定的，只是访问根节点的顺序不同。不管采用哪种遍历方法，每个结点都被访问一次且仅访问一次，故时间复杂度均为$O(n)$。在递归遍历中，递归工作栈的栈长正好为树的深度，最坏情况下，有n个结点的二叉树深度为n的单支树，此时递归算法的空间复杂度为$O(n)$
4. 递归算法和非递归算法的转换
>不太可能考察代码，比较复杂，下面给出中序遍历的访问过程供参考

- 沿着根的左孩子，依次入栈，直到左孩子为空
- 栈顶元素出栈并访问：若其右孩子为空，则继续执行本步；若其右孩子不空，将右子树转而执行上一步
5. 层次遍历
  按自上而下，从左到右的顺序，依次按层遍历各个结点。要进行层次遍历，需要借助一个队列。下面给出算法过程：
  首先将根节点入队，然后出队，访问出队结点，若该结点有左子树，则将左子树根节点入队；若该结点有右子树，则将右子树根节点入队。完成入队后出队，访问结点...如此反复，直到队列为空。代码如下：
```cpp
void LevelOrder(BiTree T){
    InitQueue(Q); 
    BiTree p;
    EnQueue(Q,T); //根节点入队
    while(!IsEmpty(Q)){ //判队列非空
        DeQueue(Q,p); //队头结点出队
        visit(p); //访问出队结点
        if(p->lchild!=NULL)
            EnQueue(Q,p->lchild); //左结点不为空，则左子树根节点入队
        if(p->rchild!=NULL)
            EnQueue(Q.p->rchild); //右结点不为空，则右子树根节点入队
    }
}
```

6.由遍历序列构造二叉树
关于二叉树的前中后以及层次遍历是小题的高频考点，有下面的结论：
由二叉树的==先序==序列和==中序==序列可以唯一地确定一棵二叉树
由二叉树的==后序==序列和==中序==序列可以唯一地确定一棵二叉树
由二叉树的==层序==序列和==中序==序列可以唯一地确定一棵二叉树
由二叉树的先序序列和后序序列无法唯一地确定一棵二叉树
简而言之，要确定一个唯一地二叉树，需要中序序列和另一种遍历序列，若无中序序列，得到的二叉树不唯一。
### 5.3.2 线索二叉树
1.线索二叉树的基本概念
线索二叉树是说传统的二叉链表仅能体现一种父子关系，不能直接得到结点在遍历中的前驱或后继。前面提到，在含有$n$个结点的二叉树中，有$n+1$个空指针，这是因为每个叶子结点都有两个空指针，每个度为1点结点都有一个空指针，空指针总数为$2n_0+n_1$，又$n_0=n_2+1$，所以空指针总数为$n_0+n_1+n_2+1=n+1$。存在较多的空指针域，故能否利用这些空指针来存放指向其前驱和后继的指针？引入线索二叉树正是为了加快查找结点前驱和后继的速度。
对于线索二叉树有这样的规定：若结点无左子树，另`lchild`指向其前驱结点；若无右子树，另`rchild`指向其后继结点，之外还需增加两个标志域以区别指针指向的是左右孩子还是前驱后继。结点结构如下：
<center>

|lchild|ltag|data|rtag|rchild|
|-|-|-|-|-|

</center>

其中标志域的含义如下：
$$
ltag=\begin{cases}
    0, \quad lchild域指向该结点左孩子\\
    1, \quad lchild域指向该结点前驱
\end{cases} \\
rtag=\begin{cases}
    0, \quad rchild域指向该结点右孩子\\
    1, \quad rchild域指向该结点后继
\end{cases} \\
$$
>由于三种遍历序列的不同，导致不同遍历方式每个结点的前驱后继可能不一样，所以存在三种线索二叉树，即先序，中序，后序线索二叉树
线索二叉树的结构体定义与二叉链表类似，加了两个int型的ltag,rtag变量，其他无异

2.线索二叉树的构造
二叉树的线索化是将二叉链表中的空指针改为对应遍历序列指向前驱或后继的线索，而前驱或后继的信息只有在遍历时才可以得到，所以线索化的本质就是遍历一次二叉树。
3.线索二叉树的遍历
<center>

|&nbsp;|中序二叉树|先序二叉树|后序二叉树|
|-|-|-|-|
|找前驱|✓|✗|✓|
|找后驱|✓|✓|✗(除非使用三叉链表或者从头开始用Pre指针遍历)|

</center>

>王道这里介绍的比较详细，但考察具体算法的实现过程的可能性较小，这部分的考题主要还是以小题为主，重点理解线索二叉树概念，以及能够根据遍历序列手动画出对应的线索二叉树，还需注意tag的含义。
## 5.4 树，森林
### 5.4.1 树的存储结构
1.双亲表示法
这种存储方式采用一组连续空间来存储每个结点，同时在每个结点中增加一个伪指针，指示其双亲结点在数组中的位置，如下图所示

![Screenshot_2023-07-06-15-36-31-107_com.newskyer.draw.png](../_resources/Screenshot_2023-07-06-15-36-31-107_com.newskyer.dr.png)
双亲表示法的存储结构定义如下：
```cpp
#define MAX_TREE_SIZE 100
typedef struct{ //结点定义
    ElemType data; //数据元素
    int parent; //双亲位置域
}PTNode;
typedef struct {
    PTNode nodes[MAX_TREE_SIZE];
    int n; 
}PTree;
```
这样的存储结构利用了每个结点（根结点除外）只有唯一双亲的性质，可以很快地得到每个结点的双亲结点，但求结点的孩子时则需遍历整个结构
> 注意区别树的顺序存储结构和二叉树的顺序存储结构，在树的顺序存储中，数组下标仅代表结点的编号，结点的关系有元素内部定义的`parent`变量指明，而在二叉树的顺序存储中，数字下标既代表了结点的编号，又指明了各结点之间的关系。二叉树可以用树的存储结构存储，但树不能用二叉树的存储结构存储。

2.孩子表示法
孩子表示法是将每个结点的孩子结点都用单链表链接起来形成一个顺序结构，此时$n$个结点就有$n$个孩子链表（叶结点的孩子链表为空）
> 其实这种存储方式是把树看做图，用图的邻接表法来存储树，线性表中每个结点后面都链接一串孩子结点

3.孩子兄弟表示法
孩子兄弟表示法又称二叉树表示法，即以二叉链表作为树的存储结构。孩子兄弟表示法的每个结点包括三部分：结点值，指向结点第一个孩子结点的指针，以及指向结点下一个兄弟结点的指针。
>其实可以理解为先把树逻辑上转化为二叉树，再用二叉链表存储

存储结构定义如下：
```cpp
typedef struct CSNode{
    ElemType data; //数据域
    struct CSNode *firstchild,*nextsibing; //第一个孩子和右兄弟指针
}CSNode,*CSTree;
```
这种存储方式较为灵活，其最大的优点是可以方便的实现树转换为二叉树的操作，易于查找结点的孩子等，但缺点是从当前结点查找其双亲结点比较麻烦，解决办法是可以再添加一个`parent`指针，指向其父结点。
### 5.4.2 树，森林与二叉树的转换
容易以小题的形式考察，需要掌握树与二叉树以及森林与二叉树互相转换的画法。牢记一点：最终转换的二叉树中，对任意结点而言，其左孩子一定是原树或森林中本结点的孩子结点，而右孩子一定是原树或森林（树转化为二叉树根结点一定没有右子树）中本结点的兄弟结点（或者说同级节点）。
### 5.4.3 树和森林遍历
1.树的遍历是指用某种方式访问树中的每个结点，且仅访问一次。主要有两种方式：
- 先根遍历。先访问根节点，再依次遍历根节点的每棵子树，遍历子树时仍然遵循先根后子树的规则，其遍历序列与这棵树对应的二叉树的==先序序列==相同
- 后根遍历。先依次遍历根节点的每棵子树，再访问根结点，遍历子树时仍然遵循先子树后根的规则，其遍历序列与这棵树对应的二叉树的==中序序列==相同
- 另树也有层序遍历，与二叉树的层次遍历思想基本相同，即按层序依次访问各结点
2. 森林的遍历
  1）先序遍历森林
  - 访问森林中第一棵树的根结点。
  - 先序遍历第一棵树中根结点的子树森林
  - 先序遍历除去第一棵树之后剩余的树构成的森林
  2）中序遍历森林
  - 中序遍历森林中第一棵树的根结点的子树森林
  - 访问第一棵树的根结点
  - 中序遍历除去第一棵树之后剩余的树构成的森林
==树和森林的遍历与二叉树遍历的对应关系如下:==
<center>
    
|树|森林|二叉树|
|-|-|-|
|先根遍历|先序遍历|先序遍历|
|后根遍历|中(后)序遍历|中序遍历|

</center>

## 5.5 树与二叉树的应用
### 5.5.1 哈夫曼树和哈夫曼编码
这部分的考点由于比较熟悉，在考题中往往以小题出现，由于一个序列构造出的哈夫曼树不唯一，但所有的哈夫曼树带权路径长度一致且是最短的，这类问题只需构造出哈夫曼树再进行计算即可。构造过程不在赘述，下面给出带权路径以及平均带权路径的计算方法:
$$
WPL = \sum_{i=1}^{n} w_i \cdot l_i \\
$$
$$
AWPL = WPL / \sum_{i=1}^{n} w_i
$$
其中，$w_i$表示第$i$个叶子结点所带权值，$l_i$是该叶子结点到根结点的路径长度。
注意以下小题中常考的知识点：
1. 定长编码是对所有字符采用==相同==位数的二进制进行编码，其生成的二叉树为==完全二叉树，字符均处于最后一层的叶子结点==。
2. ==若没有一个编码是另一个编码的前缀，则称这样的编码为前缀编码==。哈夫曼编码一定是前缀码。
3. 哈夫曼树中一定不存在度为1的结点，所以只要给定哈夫曼树的总结点数$n$，由于$n=n_0+n_2$，又$n_0=n_2+1$，故由$n=2n_0-1$可得字符数$n_0=\frac{n+1}{2}$，同理可得哈夫曼树中非叶子结点$n_1=\frac{n-1}{2}$
### 5.5.2 ==并查集==
> 2022大纲新增考点，2023仍未考察，故今年考察概率极大
> 大纲原文是：并查集及其应用
> 不太可能直接考察大题的应用题，大概率还是考选择题，重点掌握并查集的概念和性质，以及有哪些应用。

1.并查集的基本概念
并查集是一种简单的集合表示，它支持以下3种基本操作：
    1)`Initial(S):`将集合S中的每个元素都初始化为只有一个单元素的子集合。
    2)`Union(S,Root1,Root2):`把集合S中的子集合Root2并入子集合Root1。要求Root1和Root2==互不相交(无交集)==，否则不执行合并。
    3)`Find(S,x):`查找集合S中单元素x所在的子集合，并返回该子集合的根结点。
    通常用树（森林）的双亲表示作为并查集的存储结构，每个子集以一棵树表示。所有表示子集合的树，构成表示全集合的森林，存放在双亲表示数组内。通常用数组元素的下标代表元素名，用根结点的下标代表子集合名，根结点的双亲结点为负数。
    例如，若设有一个全集合为$S=\{0,1,2,3,4,5,6,7,8,9\}$，初始化时每个元素自成一个单元素子集合，每个子集合的数组值为-1，如下：
<center>
   

|0|1|2|3|4|5|6|7|8|9|
|-|-|-|-|-|-|-|-|-|-|
|-1|-1|-1|-1|-1|-1|-1|-1|-1|-1|

</center>

假设经过一段时间的计算，这些子集合合并为3个更大的子集合$S_1=\{0,6,7,8\},S_2=\{1,4,9\},S_3=\{2,3,5\}$，此时并查集的树形表示和存储结构表示如下：

![Screenshot_2023-07-08-16-27-28-107_com.newskyer.draw.png](../_resources/Screenshot_2023-07-08-16-27-28-107_com.newskyer.dr.png)

<center>
    
|0|1|2|3|4|5|6|7|8|9|
|-|-|-|-|-|-|-|-|-|-|
|-4|-3|-3|2|1|2|0|0|0|1|

</center>

假设现在对上述状态集合中的$S_1$和$S_2$集合进行`Union`操作（将$S_2$合并到$S_1$中），只需要将$S_2$集合的根结点的双亲指针指向$S_1$集合的根结点，因此$S_1 \cup S_2$后可能有下面的状态:

<center>
    
![Screenshot_2023-07-08-16-34-37-958_com.newskyer.draw.png](../_resources/Screenshot_2023-07-08-16-34-37-958_com.newskyer.dr.png)

    
|0|1|2|3|4|5|6|7|8|9|
|-|-|-|-|-|-|-|-|-|-|
|-7|0|-3|2|1|2|0|0|0|1|

</center>

> 注意上面的Union操作以及后序的Find操作均是一般的实现方式，咸鱼讲了一些Union以及Find的优化思路
> 1.Union的优化其实是说由于Find操作的时间复杂度与构建出来的树的高度称正比，所以在构建树时我们希望树尽可能'矮'，那么在进行Union操作时，我们希望总是高度小的树归并到大的树中去，数的结点总数由根结点的绝对值表示，使用这种方法构造出来的树高为$O(log_2n)$量级，也就是说此时Find操作的时间复杂度由原来的$O(n)$(最坏)降低到了$O(log_2n)$。
> 2.Find的优化(压缩路径)是说我在每一次进行查找x之后会产生一个从x到根结点的路径，对于当前的树而言，假设是已经由优化后的Union操作构建的，那么其高度也仍是$O(log_2n)$量级，那么在每一次都查找之后，我都把沿着x到根结点的路径上的每一个结点及其子树都挂载到根结点上，那么经过大量的Find操作之后，理想状况下这个子集中的所有元素都会被挂载到根结点下，也就是说此时再对这个子集中的元素进行Find操作时，时间复杂度为$O(1)$常量级。
> 3.上述的优化思路属于扩展内容，考察概率不大，但由于其原理并不复杂，稍作了解防一手老头不讲武德。

下面给出一些并查集主要运算的基本实现（不必背，了解算法背后原理即可）
```cpp
#define SIZE 100
int UFSets[SIZE]; //集合元素数组（双亲指针数组）
void Initial(int S[]){ //初始化操作
    for(int i=0;i<SIZE;i++){
        s[i]=-1; //每个元素自成单个元素集合
    }
}
int Find(int S[],int x){ 
    while(S[x]>=0) //循环寻找x的根结点
        x=S[x];
    return x; //根结点的数组值＜0
}
bool Union(int S[],int Root1,int Root2){
    if(Root1==Root2) return false; //如有交集，合并失败
    else{
        S[Root2]=Root1; //将根Root2点根结点连接到Root1下
        return true;
    }
}
```
2.并查集的应用
并查集的应用主要有以下方面(重点关注:知道有这些应用就行):
- **克鲁斯卡尔(Kruskal)算法实现最小生成树**
- **判断无向图中是否有环路**
- **判断无向图中是否有连通，甚至可以计算连通分量**

# 6.图
## 6.1 图的基本概念
1. 定义
    图G由顶点集$V$和边集$E$组合，记为$G=(V,E)$，其中$V(G)$表示图$G$中顶点的有限非空集；$E(G)$表示图$G$中顶点直接的边集合。若$V=\{v_1,v_2,...,v_n\}$，则用$\lvert V \rvert$表示图$G$中顶点的个数，$E=\{(u,v) \vert u \in V,v \in V\}$，用$\lvert E \rvert$表示图$G$中边的条数。
2. 有向图
    若$E$是有向边（也称弧）的有限集合时，则图$G$为有向图。弧是顶点的有序对，记为$<v,w>$，其中$v,w$是顶点，$v$称为弧尾，$w$称为弧头，$<v,w>$称为从$v$到$w$的弧，也称$v$邻接到$w$。
3. 无向图
    若$E$是无向边（简称边）的有限集合时，则图$G$为无向图。边是顶点的无序对，记为$(v,w)$或$(w,v)$，可以说$w$和$v$互为邻接点，边$(v,w)$依附于$w$和$v$，或称边$(v,w)$和$v,w$相关联。
4. 简单图，多重图
    一个图$G$如果满足：①不存在重复边；②不存在顶点到自身的边。那么称图$G$为简单图，数据结构中仅讨论简单图。
5. 完全图（也称简单完全图）
    对于无向图，$\lvert E \rvert$的取值范围为$0$到$n(n-1)/2 (C_n^2)$，有$n(n-1)/2$条边的无向图称为完全图，在完全图中任意两个顶点之间都存在边。对于有向图，$\lvert E \rvert$的取值范围为$0$到$n(n-1) (2C_n^2)$，有$n(n-1)$条弧的有向图称为有向完全图，在有向完全图中任意两个顶点之间都存在方向相反的两条弧。
6. 子图
    从原来图的顶点和边集合中取出一部分构成子图。若取出的顶点和原来图中的顶点一致，则称其为生成子图。
>并非所有子集都能构成子图，因为这样的子图很可能不是图，比如取出的某些边关联的顶点并不在子集中

7. 连通，连通图和连通分量
    在无向图中，若从顶点$v$到$w$有路径存在，则称$v$和$w$是连通的。若图$G$中任意两个顶点都是连通的，则称图$G$为连通图。无向图中的==极大连通子图==称为==连通分量==。
    假设一个图有$n$个顶点，如果边数小于$n-1$，那么此图必然是非连通图（$n$个顶点构成连通图最少需要$n-1$条边才能互相连通）。
    如果图是非连通图，那么最多可以有$C_{n-1}^2$条边（非连通情况下边最多的情况：由$n-1$个顶点构成一个完全图，此时再加入一个顶点必然变成连通图）。  
8. 强连通图，强连通分量
    在有向图中，如果一对顶点$v$和$w$，从$v$到$w$和从$w$到$v$之间都有路径，则称这两个顶点是强连通的。若图$G$中任意两个顶点都是强连通的，则称图$G$为强连通图。有向图中的==极大强连通子图==称为有向图的==强连通分量==。
    一个有向图有$n$个顶点，如果是强连通图，那么最少需要$n$条边，构成一个环路。
>注意在无向图中讨论连通性，在有向图中讨论强连通性。

9. 生成树，生成森林
    连通图的生成树是包含图中==全部顶点==的一个==极小连通子图==。若图中顶点树为$n$，则它的生成树含有$n-1$（构成连通图的最少数量的边）。包含图中全部顶点的极小连通子图，只有生成树满足这一极小条件，对生成树而言，若砍去它的一条边，则会变成非连通图，若加上一条边则会形成一个环路。在非连通图中，连通分量的生成树构成了非连通图的生成森林。
> 注意区分极大连通子图和极小连通子图。极大连通子图是无向图的连通分量，要求改连通子图包含其所有的边；而极小连通子图是既要保持图连通，又要使得边数最少的子图。

10.顶点的度，入度和出度
    在无向图中，顶点$v$的度是指依附与顶点$v$的边的条数。记为$TD(v)$。对于具有$n$个顶点，$e$条边的无向图，
$$
    \sum_{i=1}^{n} TD(v_i)=2e
$$
即无向图的全部顶点的度之和等于边数的2倍，因为每条边和两个顶点相关联。
    在有向图中，顶底$v$的度分为入度和出度，入度是以顶点$v$为==终点==的有向边的数目，记为$ID(v)$；而出度是以顶点$v$为==起点==的有向边的数目，记为$OD(v)$。顶点$v$的度等于其入度与出度之和，即$TD(v)=ID(v)+OD(v)$。对于具有$n$个顶点，$e$条边的有向图，
$$
    \sum_{i=1}^{n} ID(v_i)=\sum_{i=1}^{n} OD(v_i)=e
$$  
即有向图的全部顶点的入度之和与出度之和相等，并且等于边数，这是因为每条有向边都有一个起点和终点。

11.边的权和网
    在一个图中，每条边都可以标上具有某种意义的数值，改数值称为该边的权值。这种边上带有权值的图称为带权图，也称网
12. 稠密图，稀疏图
    边数很少的图称为稀疏图，反之称为稠密图。一般当图$G$满足$\lvert E \rvert < \lvert V \rvert log \lvert V \rvert$时，可将其视为稀疏图。
13. 路径，路径长度和回路
    顶点$v_p$到顶点$v_q$之间的一条路家是指顶点序列${v_p,v_{i_1},v_{i_2},...,v_{i_m},v_q}$。路径上边的数目称为路径长度。第一个顶点和最后一个顶点相同的路径称为回路或环。若一个图有$n$个顶点，并且有大于$n-1$条边，则此图一定有环。
14. 简单路径，简单回路
    在路径序列中，顶点不重复出现的路径称为简单路径。除第一个顶点和最后一个顶点外，其余顶点不重复出现的回路称为简单回路。
15. 距离
    从顶点$u$出发到顶点$v$的最短路径若存在，则此路径的长度称为从$u$到$v$的距离。若从$u$到$v$根本不存在路径，则记该距离为无穷($\infty$) 。
16. 有向树
    一个顶点的入度为0，其余顶点的入度均为1的有向图，称为有向树。
## 6.2 图的存储及基本操作
### 6.2.1 邻接矩阵法
邻接矩阵是用一个一维数组存储图中顶点的信息，一个二维数组存储图中边的信息。存储顶点之间邻接关系的二维数组称为邻接矩阵。
结点数为$n$为图$G=(V,E)$的邻接矩阵$A$是$n \times n$的。将$G$的顶点编号为$v_1,v_2,...,v_n$。若$(v_i,v_j) \in E$，则$A[i][j]=1$，否则$A[i][j]=0$。
$$
A[i][j]=\begin{cases}
    1, &  if & (v_i,v_j)or<v_i,v_j> \in E(G) \\
    0, &  if & (v_i,v_j)or<v_i,v_j> \notin E(G)
    \end{cases}
$$
对于带权图而言，若顶点$v_i$和$v_j$之间有边相连，则邻接矩阵中对应项存放着该边对应的权值，若顶点$v_i$和$v_j$不相连，则通常用$\infty$来表示这两个顶点之间不存在边。
$$
A[i][j]=\begin{cases}
    w_{ij}, &  if & (v_i,v_j)or<v_i,v_j> \in E(G) \\
    0or\infty, &  if & (v_i,v_j)or<v_i,v_j> \notin E(G)
    \end{cases}
$$
图的邻接矩阵存储结构定义如下：
```cpp
#define MaxVertexNum 100 //顶点数目最大值
typedef char VertexType; //顶点的数据类型
typedef int EdgeType; //带权图中边上权值的数据类型
typedef struct{
    VertexType Vex[MaxVertexNum]; //顶点表
    EdgeType Edge[MaxVertexNum][MaxVertexNum]; //邻接矩阵，边表
    int vexnum,arcnum; //图当前的顶点数和弧树
}MGraph;
```
> 注意：
> 1.在简单的一般情形下，可以直接用二维数组作为图的邻接矩阵（顶点信息可以忽略）
> 2.当邻接矩阵的元素仅表示相应的边是否存在时，EdgeType可采用bool类型
> 3.无向图的邻接矩阵是对称矩阵，对规模较大的邻接矩阵可采用压缩存储
> 4.邻接矩阵表示法的空间复杂度为$O(n^2)$(即使采用了压缩存储)，其中$n$为图的顶点数。

图的邻接矩阵表示法具有以下特点：
1.无向图的邻接矩阵一定是一个==对称矩阵(且表示法唯一)==。因此，在实际存储邻接矩阵时只需存储上（或下）三角矩阵的元素。
2.对于无向图，邻接矩阵的第$i$行（或第$i$列）非零元素（或非$\infty$元素）的个数正好是顶点$i$的度$TD(v_i)$
3.对于有向图，邻接矩阵的第$i$行非零元素（或非$\infty$元素）的个数正好是顶点$i$的出度$OD(v_i)$；第$i$列非零元素（或非$\infty$元素）的个数正好是顶点$i$的入度$ID(v_i)$；
4.用邻接矩阵存储图，很容易确定图中任意两个顶点之间是否有边相连。但是要确定图中有多少条边，则必须按行，列对每个元素进行遍历，时间复杂度较高
5.==稠密图==适合用邻接矩阵的存储表示
6.设图$G$的邻接矩阵为$A$，$A^n$的元素$A^n[i][j]$等于由顶点$i$到$j$的长度为$n$的路径的数目。(该结论了解即可)
### 6.2.2 邻接表法
当一个图为稀疏图时，使用邻接矩阵法存储显然会浪费大量的存储空间，而图的邻接表法结合了顺序存储和链式存储，适合存储==稀疏图==
邻接表是对图$G$中的每个顶点$v_i$建立一个单链表，第$i$个单链表中的结点表示依附于顶点$v_i$的边（对于有向图则是以顶点$v_i$为尾的弧），这个单链表就称为顶点$v_i$的边表（对于有向图而言则称为出边表）。边表的头指针和顶点的数据信息采用顺序存储（称为顶点表），所以在邻接表中存在两种结点：顶点表结点和边表结点。
无向图和有向图的邻接表实例分别如下所示：

![Screenshot_2023-07-10-15-17-14-459_com.newskyer.draw.png](../_resources/Screenshot_2023-07-10-15-17-14-459_com.newskyer.dr.png)
图的邻接表的存储结构定义如下：
```cpp
#define MaxVertexNum 100 //顶点数目最大值
typedef struct ArcNode{ //边表结点
    int adjvex; //该弧所指向的顶点的位置
    struct ArcNode *next; //指向下一条弧的指针
    //InfoType info;   //网的边权值
}ArcNode;
typedef struct VNode{ //顶点表结点
    VertexType data; //顶点信息
    ArcNode *first; //指向第一条依附该结点的弧的指针
}VNode,AdjList[MaxVertexNum];
typedef struct{ 
    AdjList vertices; //邻接表
    int vexnum,arcnum; //图的顶点数和弧数
}ALGraph; //ALGraph是以邻接表存储的图类型
```
图的邻接表存储方法有以下==特点==：
1. 若$G$为无向图，则所需的存储空间为$O(\lvert V \rvert+2\lvert E \rvert)$；若$G$为有向图，则所需存储空间为$O(\lvert V \rvert+\lvert E \rvert)$。（前者倍数2是因为在无向图中，每条边在邻接表中出现了两次）
2. 对于==稀疏图==，采用邻接表表示能极大的节省存储空间。
3. 在邻接表中，给定一顶点，能很容易找出它的所有邻边，因为只需要读取该顶点的邻接表。在邻接矩阵中，相同的操作则需要扫描一行，花费时间为$O(n)$。但是，若要确定给定两个顶点之间是否存在边，则在邻接矩阵中可以立刻查到，而在邻接表中则需要在相应结点的边表中查找另一个结点，效率较低。
4. 在有向图的邻接表表示中，求一个给定顶点的==出度==只需要计算其邻接表中的结点个数；但求其顶点的==入度==时则需要遍历全部的邻接表。所以也可以采用逆邻接表存储加速求解入度。
5. ==图的邻接表表示并不唯一==，因为在每个顶点对应的单链表中，各边结点的链接次序可以是任意的，其取决于建立邻接表的算法及边的输入顺序。
### 6.2.3 十字链表
十字链表是==有向图==的一种链式存储结构。弧结点的结构如下所示：
<center>

|tailvex|headvex|hlink|tlink|(info)|
|-|-|-|-|-|

</center>

弧结点中有5个域，tailvex和headvex两个域分别指明了弧尾和弧头这两个顶点的编号；hlink域指向==弧头==相同的下一个弧结点；tlink域指向==弧尾==
相同的下一个弧结点；info域存放该弧的相关信息。顶点结点之间是==顺序存储==的。

![Screenshot_2023-07-10-15-51-26-378_com.newskyer.draw.png](../_resources/Screenshot_2023-07-10-15-51-26-378_com.newskyer.dr.png)
在十字链表中，可以很容易以某结点为头或尾的弧。图的十字链表表示也是==不唯一==的，但一个十字链表表示确定一个图。
### 6.2.4 邻接多重表
邻接多重表示==无向图==的另一种链式存储结构。
与十字链表相似，在邻接多重表中，每条边用一个结点表示，起结构如下所示：
<center>

|ivex|ilink|jvex|jlink|(info)|
|-|-|-|-|-|

</center>

其中，ivex和jvex这两个域分别指明该边依附的两个顶点的编号；ilink域指向下一条依附于顶点ivex的边；jlink域指向下一条依附于顶点jvex的边，info同样存放该边的相关信息。

![Screenshot_2023-07-10-16-00-32-396_com.newskyer.draw.png](../_resources/Screenshot_2023-07-10-16-00-32-396_com.newskyer.dr.png)

在邻接多重表中，所有依附于同一顶点的边串联在同一链表中，由于每条边依附于两个顶点，因此每个边结点同时链接在两个链表中。对于无向图而言，其邻接多重表和邻接表的差别仅在于，同一条边在邻接表中用两个边结点表示，而在邻接多重表中只有一个边结点。邻接多重表表示法也==不唯一==

>上述图的存储方式重点掌握图的邻接矩阵和邻接表，对于十字链表和邻接多重表而言，考察概率较小。

## 6.3 图的遍历
### 6.3.1 广度优先搜索(Breadth-First-Search,BFS)
广度优先搜索类似于树的==层序==遍历算法。基本思想与算法名称一致，其是一种分层查找的过程，先考虑广度，每向前走一步就访问可以访问到的所有结点。
>BFS，DFS代码考察的概率极低，重点掌握其算法思想，会根据给定图写出对应遍历序列。

1.BFS的算法性能分析
    不论是邻接表还是邻接矩阵的存储方式，BFS算法都需要借助一个辅助队列Q，n个顶点均需入队一次，在最坏的情况下，其空间复杂度为$O(\lvert V \rvert)$。
    采用==邻接表==存储时，每个顶点均需搜索一次（或入队一次），故时间复杂度为$O(\lvert V \rvert)$，在搜索任意一个顶点的邻接点时，每条边至少访问一次，故时间复杂度为$O(\lvert E \rvert)$，算法总的时间复杂度为$O(\lvert V \rvert+\lvert E \rvert)$。采用==邻接矩阵==存储时，查找每个顶点的邻接点所需时间为$O(\lvert V \rvert)$，所以算法的总时间复杂度为$O(\lvert V \rvert ^2)$
2.BFS求解单源最短路径问题
    使用BFS可以求解==非带权==图的单源最短路径问题。
> 事实上408历年的真题中求解单源最短路径时均考察迪杰斯特拉算法，连弗洛伊德算法都未曾考过，所以这里只需要知道BFS是可以求解该问题的即可，算法过程不必细究。

3.广度优先生成树
    在广度遍历的过程中，我们可以得到一棵遍历树，其称为==广度优先生成树==，需要注意到是，由于邻接矩阵存储表示法唯一，其广度优先生成树也是唯一的。但由于邻接矩阵表示不唯一，所以其广度优先生成树并不唯一。
> 若图是非连通图，生成的为广度优先森林
### 6.3.2 深度优先搜索(Depth-First-Search,BFS)
深度优先搜索类似于树的先序遍历。如其名称中所含意思一样，其遵循的原则是尽可能'深'的搜索一个图。由于深度优先是一种递归算法，形式上较为简单，故给出代码供参考。
```cpp
bool visited[MAX_VERTEX_NUM] //访问标记数组
void DFSTraverse(Graph G){
    for(int v=0;v<G.venum;v++)
        visited[v]=false; //初始化已访问标记数组
    for(int v=0;v<G.venum;v++) //从v=0开始遍历
        if(!visited[v])
            DFS(G,v);
}
void DFS(Graph G,int v){ //从顶点v出发，深度优先遍历图G
    visit(v); //访问顶点v
    visited[v]=true; //设置已访问标记
    for(int w=FirstNeighbor(G,v);w>=0;w=NextNeighbor(G,v,w)) //由图的基本操作进行遍历相邻顶点
        if(!visted[w]) //w为v的尚未访问的邻接顶点
            DFS(G,w);
}
```
>注意：图的邻接矩阵表示法是唯一的，但对于邻接表来说，若边的输入次序不同，生成的邻接表也不同。因此，对于同样一个图，基于邻接矩阵的遍历所得到的DFS序列和BFS序列是唯一的。基于邻接表的遍历所得到的DFS和BFS序列则是不唯一的。

1.DFS的算法性能分析
    DFS算法是一个递归算法，需要借助一个==递归工作栈==，其空间复杂度为$O(\lvert V \rvert)$。
    遍历图的过程实际上就是对每个顶点查找其邻接点的过程，所以其时间复杂度与BFS一致：当使用邻接矩阵表示时为：$O(\lvert V \rvert ^2)$。当使用邻接表表示时为：$O(\lvert V \rvert+\lvert E \rvert)$。
2.深度优先的生成树和生成森林
    与广度优先搜索一样，深度优先搜索也会产生一颗深度优先的生成树。但是需要注意的是，只有对连通图进行DFS时才能产生深度优先生成树，否则产生的将是深度优先生成森林，与BFS类似，基于邻接表存储的深度优先生成树是不唯一的。
### 6.3.3 图的遍历与图的连通性
==图的遍历算法可以用来判断图的连通性==
    对于无向图而言，若无向图是连通的，则从任意一个结点出发，仅需一次遍历就能够访问当前图中的所有结点；所无向图是非连通的，则从某一个结点出发，一次遍历只能访问到该顶点所在的连通分量中的所有结点，而对于图中其他连通分量的顶点，则需要多次遍历才能访问。
    对于有向图而言，若从初始点到图中每个顶点都有路径，则能够访问到图中的所有顶点，否则不能访问到所以顶点。
## 6.4 图的应用
> 本节是历年考察的重点，一般以小题出现，直接考察大题的概率不大，需要会手动模拟给定图的给个算法的执行过程，此外，这部分可能结合计网进行考察，即需要掌握对给定模型建立相应的图去解决问题的方法。

### 6.4.1 最小生成树
一个连通图的生成树包含图的所有顶点，并且只含有尽可能少的边，对于生成树而言，若砍去一条边，则会使生成树变成非连通图，若给它增加一条边，则会形成图中的一条回路。
对于一个带权连通无向图而言，生成树不同，每棵树的权也可能不同，最小生成树是指在所有生成树中，权值总和最小的生成树。最小生成树有下面性质;
- 最小生成树是不唯一的
- 最小生成树的边的权值之和总是唯一的
- 最小生成树的边数为顶点树减1

1.$Prim$算法
    $Prim$(普里姆)算法的执行非常类似于$Dijkstra$算法
    $Prim$算法的大致流程为：初始时从图中任取一个顶点加入树$T$，此时树中只有一个顶点，之后选择一个与当前$T$中顶点集合距离最近的顶点，并将该顶点和相应的边加入到$T$，每次操作后$T$中的定点数和边数都+1。依次类推，直到图中所有的顶点都并入$T$，得到的$T$就是最小生成树，此时$T$中必然有$n-1$条边。

![Screenshot_2023-07-10-17-33-32-417_com.newskyer.draw.png](../_resources/Screenshot_2023-07-10-17-33-32-417_com.newskyer.dr.png)

$Prim$算法的时间复杂度为$O(\lvert V \rvert ^2)$，不依赖于$\lvert E \rvert$，因此它适用于求解==边稠密==的图的最小生成树。
2.$Kruskal$算法
    $Kruskal$（克鲁斯卡尔）算法是一种按权值的递增次序选择合适的边来构造最小生成树的方法。
    $Kruskal$算法的大致流程为：初始时只有$n$个顶点而无边的非连通图$T$，每个顶点自成一个连通分量，然后按照边的权值由小到大的顺序，不断选取当前未被选取过且权值最小的边，若该边依附的顶点落在$T$中不同的连通分量上，则将此边加入$T$，否则舍弃此边而选择下一条权值最小的边，直到$T$中所有顶点都处于一个连通分量中。
    
![Screenshot_2023-07-10-17-32-48-230_com.newskyer.draw.png](../_resources/Screenshot_2023-07-10-17-32-48-230_com.newskyer.dr.png)

通常在$Kruskal$算法中，通常采用堆来存放边的集合，因此每次选择最小权值的边只需$O(log_2\lvert E \rvert)$的时间。此外，由于生成树$T$中的所有边可以视为一个等价类，因此每次添加新的边的过程类似于求解等价类的过程，由此可以采用==并查集==的数据结构来描述$T$，从而构造$T$的时间复杂度为$O(\lvert E \rvert log_2\lvert E \rvert)$。因此，$Kruskal$算法适合与==边稀疏而顶点较多==（$\lvert E \rvert$小，$\lvert V \rvert$大）的图。
### 6.4.2 最短路径
带权有向图$G$的最短路径问题一般可分为两类：一是单源最短路径，即求图中某一顶点到其他各顶点的最短路径，可通过经典的$Dijkstra$（迪杰斯特拉）算法求解；二是求每对顶点间的最短路径，可通过$Floyd$（弗洛伊德）算法求解。
1.$Dijkstra$算法求单源最短路径问题
    $Dijkstra$算法设置一个集合$S$记录已求得的最短单源路径的顶点，初始时把源点$v_0$放入$S$，集合$S$每并入一个新顶点$v_i$，都要修改源点$v_0$到集合$V-S$中顶点当前的最短路径长度(不可达用$\infty$表示)，假设图中共有$n$个结点，则共需要$n-1$次并入，每次找到一个顶点的最短距离。

![Screenshot_2023-07-11-14-19-42-914_com.newskyer.draw.png](../_resources/Screenshot_2023-07-11-14-19-42-914_com.newskyer.dr.png)

使用邻接矩阵表示时，$Dijkstra$算法的时间复杂度是$O(\lvert V \rvert ^2)$。使用带权的邻接表表示时，时间复杂度仍然为$O(\lvert V \rvert ^2)$。
    有时可能只需要找到源点到特定某顶点的最短路径,但这个问题和求解源点到其他所有顶点的最短路径一样复杂，时间复杂度仍为$O(\lvert V \rvert ^2)$。
    需要注意的是，边上带有==负权值==时，$Dijkstra$算法并不适用。
2.$Floyd$算法求各顶点之间的最短路径问题
    $Floyd$算法的基本思想是：递推产生一个$n$阶方阵序列$A^{(-1)},A^{(0)},...,A^{(k)},...,A^{(n-1)}$，其中$A^{(k)}[i][j]$表示从顶点$v_i$到顶点$v_j$的路径长度，$k$表示假如我从第$k$个顶点走，矩阵中各个顶点之间的最短路径是否会发生变化。初始时，对于任意两个顶点$v_i$和顶$v_j$，如果它们直接存在边，则以此边上的权值作为它们直接的最短路径长度；若它们直接不存在有向边，则以$\infty$表示。以后逐步尝试在原路径中加入顶点$k(k=0,1,...,n-1)$作为中间顶点。若增加中间顶点后，得到的路径比原来的路径长度减少了，则以此新路径代替原路径。其关键代码用C语言描述如下：
```cpp
    // Floyd 算法主循环
    for (k = 0; k < numVertices; k++) {
        for (i = 0; i < numVertices; i++) {
            for (j = 0; j < numVertices; j++) {
                // 如果经过顶点 k 的路径比直接路径更短，则更新距离
                if (dist[i][k] + dist[k][j] < dist[i][j]) {
                    dist[i][j] = dist[i][k] + dist[k][j];
                }
            }
        }
```
$Floyd$算法的时间复杂度为$O(\lvert V \rvert ^3)$。但由于代码紧凑，且并不包含其他复杂的数据结构，因此隐含的常数系数是很小的。
    $Floyd$算法允许图中有带负权值的边，但不允许包含==带负权值的边组成的回路==。$Floyd$算法同样适用于带权无向图，因为带权无向图可视为权值相同往返二重边的有向图。
    也可以采用单源最短路径算法来解决每队顶点之间的最短路径问题。轮流将每个顶点作为源点，并且在所有边权值非负时，运行一次$Dijkstra$算法，其时间复杂度为$O(\lvert V \rvert ^2) \cdot \lvert V \rvert = O(\lvert V \rvert ^3)$
>历年408的真题中都只考查过$Dijkstra$算法的应用，$Floyd$算法虽一直在考纲要求内，但从未考察，需提防今年可能会出题
### 6.4.3 有向无环图描述表达式
==有向无环图==：若一个有向图中不存在环路，则称为有向无环图。简称$DAG$图
有向无环图可以描述含有公共子式的表达式的有效工具，例如：
$$
((a+b)*(b*(c+d))+(c+d)*e)*((c+d)*e)
$$
这个表达式可以采用一棵二叉树来表示，如下，但容易发现有一些相同的子表达式，比如$(c+d)$和$(c+d)*e$，而在二叉树中，它们也重复出现，若利用有向无环图，可以将相同子式去除，只保留一个，所有后置运算指向这一个即可。如下所示：

![Screenshot_2023-07-11-15-02-50-090_com.newskyer.draw.png](../_resources/Screenshot_2023-07-11-15-02-50-090_com.newskyer.dr.png)
>做题时，先画出一般二叉树表示，再删去重复子式，指针重新索引，直到图中不存在重复子式为止。
### 6.4.4 拓扑排序
$AOV$网：若用$DAG$图表示一个工程，其顶点表示活动，用有向边$<V_i,V_j>$表示活动$V_i$必须先于活动$V_j$进行的这样一种关系，则将这种有向图称为顶点表示活动的网络，记为$AOV$网。
拓扑排序是对有向无环图的顶点的一种排序，它使得若存在一条从顶点A到顶点B的路径，则在排序中顶点B出现在顶点A的后面。每个$AOV$网都有一个活多个拓扑排序序列。
对一个$AOV$进行拓扑排序有以下步骤：
1. 从$AOV$网中选择一个没有前驱的结点并输出
2. 从网中删除该顶点和所有以它为起点的有向边
3. 重复1,2直到当前的$AOV$网为空或当前网中不存在无前驱的顶点为止。后一种情况说明该有向图中必然存在环。
    由于输出每个顶点的同时还要删除以它为起点的边，故采用邻接表存储时拓扑排序的时间复杂度为$O(\lvert V \rvert+\lvert E \rvert)$，采用邻接矩阵存储时拓扑排序的时间复杂度为$O(\lvert V \rvert^2)$。此外，==深度优先遍历==也可以实现拓扑排序。
   对于一个$AOV$网，如果采用下列步骤进行排序，则称之为==逆拓扑排序==：
   1. 从$AOV$网选择一个没有后继（出度为0）的顶点并输出
   2. 从网中删除该顶点和所有以它为终点的有向边
   3. 重复1，2知道当前的$AOV$网为空
>拓扑排序的题一般以小题为主，注意到对于给定的一个图，拓扑排序序列一般不唯一。在做选择题时，注意到拓扑排序的定义，即假如存在A顶点指向B顶点的一条边，则拓扑排序中B一定在A后面，在选择题中可根据这点排除选项快速选出答案。
>注意，如果一个有向无环图存在拓扑排序序列，那么该有序无环图一定可以用上/下三角矩阵存储，这里容易和矩阵的压缩存储结合出题

### 6.4.5 关键路径
在带权有向图中，以==顶点代表事件==，以==有向边代表活动==。以边上的权值表示完成该活动的开销，称之为用边表示活动的网络，简称$AOE$网，$AOE$网和$AOV$网都是有向无环图，不同之处在于它们的边和顶点所代表的含义是不同的，$AOE$网中的边有权值；而$AOV$网中的边无权值，仅代表顶点之间的前后关系。
    在$AOE$网中，从源点到汇点的所有路径中，具有==最大==路径长度的路径称为==关键路径==，而把关键路径上的活动称为关键活动。
    完成整个工程的最短时间就是关键路径的长度，即关键路径上各活动花费开销的总和。
有关参量的定义：
1. 事件（顶点）$v_k$的最早发生时间$ve(k)$  （$MAX$前推）
    它是指从源点$v_1$到顶点$v_k$的最长路径长度。事件$v_k$的最早发生时间决定了所有从$v_k$开始的活动能够最早开始的时间。
2. 事件（顶点）$v_k$的最迟发生时间$ve(k)$  （$MIN$回推）
    它是指在不推迟整个工程完成的前提下，即保证它的后继事件$ve(j)$在其最迟发生时间$vl(j)$能够发生时，该事件最迟必须发生的时间。
3. 活动（有向边）$a_i$的最早开始时间$e(i)$
    它是指该活动弧的==起点==所表示第事件的最早发生时间。若有边$<v_k,v_j>$表示活动$a_i$，则有$e(i)=ve(k)$
4. 活动（有向边）$a_i$的最晚开始时间$l(i)$
    它是指该活动弧的==终点==所表示第事件的最迟发生时间与该活动所需时间之差。若有边$<v_k,v_j>$表示活动$a_i$，则有$l(i)=vl(j)-Weight(v_k,v_j)$
5. 一个活动$a_i$的最晚开始时间$l(i)$和其最早开始时间$e(i)$的差额$d(i)=l(i)-e(i)$
    它是指活动完成的时间余量，即在不增加完成整个工程所需总时间的情况下，活动$a_i$可以拖延的最大时间。若一个活动的时间余量为0，则说明该活动必然处于关键路径之上。
   
关于关键路径，需要注意以下几点：
- 关键路径上的所有活动都是关键活动，它是决定整个工程的关键因素，因此可以通过加快关键活动来缩短整个工程的工期。但也不能任意缩短关键活动，因为一旦缩短到一定程度，该关键活动可能会变为非关键活动
- $AOE$网中的关键路径并不唯一，且对于有几条关键路径的网，只提高一条关键路径上的某个关键活动并不能缩短整个工程的工期，只有加快那些包括在所有关键路径上的关键活动才能缩短工期。
>对于关键路径的考题一般以小题形式出现，求关键路径，或者求某个活动的时间余量
>1.求关键路径，对于关键路径定义是指有时间余量为0的活动组成的由源点到终点的路径，但在做题时，可以直接$MAX$前推，即找到源点到终点的最大长度的路径，即为关键路径。注意可能求出来的关键路径不止一条
>2.求活动的时间余量，需要先$MAX$前推出最终活动完成的最大长度，再根$MIN$回推出每个顶点的最迟开始时间，活动（边）的时间余量即为该弧的终点回推值-活动自身的时间－活动起点前推的值。

# 7.查找
## 7.1 查找的基本概念
注意==平均查找长度==的计算：在查找过程中，一次查找的长度是指需要比较的关键字==次数==，而平均查找长度则是所有查找过程中进行关键字的比较次数的==平均值==，其数学定义为：
$$
ASL = \sum_{i=1}^{n} P_i \cdot C_i
$$
其中，$n$是查找表的长度；$P_i$是第$i$个数据元素被查找的概率，一般认为每个数据元素都查找概率相等，即$P_i=1/n$；$C_i$是找到第$i$个数据元素需要进行的比较次数。平均查找长度是衡量各查找算法效率的最主要的指标。

## 7.2 顺序查找和折半查找
### 7.2.1 顺序查找（$O(n)$）
1.一般线性表的顺序查找
    作为一最直观的查找方法，其基本思想是从线性表的一端开始，逐个检查关键字是否匹配。若查找到某个元素的关键字满足给定条件，则查找成功，返回该元素在线性表中的位置；若已经查找到表的另一端，但还没有查找到符合条件的元素，则返回查找失败的信息。
    对于有$n$个元素的表，给定值`key`与表中第$i$个元素相等，即定位第$i$个元素时，需进行$i$(从前往后找)次关键字的比较,查找成功时顺序查找的平均查找长度为：
$$
ASL_{成功} = \sum_{i=1}^{n} P_i \cdot (i) = \frac{n+1}{2}
$$
查找不成功时，与表中各关键字的对比次数显然是$n+1$次，即$ASL_{不成功}=n+1$
    通常，查找表中记录的查找概率并不相等。若可以事先预知每个记录的查找概率，则应先对记录的查找概率进行排序，使表中记录按查找概率重新排列。
    综上所述，顺序查找的缺点是当$n$较大时，平均查找长度较大，效率低；优点是对数据元素的存储没有要求，顺序存储或链式存储均可。对表中记录的有序性也没有要求，无论记录是否按关键字有序，均可应用。同时还需注意，==对线性的链表只能进行顺序查找==。
2.有序表的顺序查找（顺序查找的优化）
    若在查找之前就已经知道表是关键字有序的，则查找失败时可以不需要继续遍历可直接返回查找失败信息。从而降低顺序查找失败的平均查找长度。
    假设表$L$是按关键字从小到大排序的，查找的顺序是从前往后，待查找元素都关键字为`key`，当查找到第$i$个元素时，如果发现第$i$个元素对应的关键字小于`key`，但第$i+1$个元素对应的关键字大于`key`，这时就可以返回查找失败的信息。可以用如下的判定树来描述有序线性表的查找过程。（不难发现，这样的判定树是最坏情况下的判定树，即n个结点的树高来到了最大，也就意味着平均失败查找长度的量级并没有降低）。
    
![Screenshot_2023-07-13-14-39-29-448_com.newskyer.draw.png](../_resources/Screenshot_2023-07-13-14-39-29-448_com.newskyer.dr.png)
查找不成功的平均查找长度在相等查找概率的情形下为：
$$
ASL_{不成功} = \sum_{j=1}^{n} q_j \cdot (l_j-1) = \frac{1+2+...+n+n}{n+1} = \frac{n}{2} + \frac{n}{n+1}
$$
其中，$q_j$是到达第$j$个失败结点的概率，在相等查找概率的情形下，它为$1/(n+1)$；$l_i$是第$j$个失败结点所在的层数。
>注意，有序线性表的顺序查找和后序的折半查找的思想是不同的，且有序线性表的顺序查找中的线性表可以是链式存储结构。

### 7.2.1 折半查找
折半查找又称二分查找，它==仅适用于有序的顺序表(顺序存储结构)==
    折半查找的基本思想：首先将给定值`key`与表中中间位置的元素比较，若相等，则查找成功，返回该元素的存储位置；若不等，则所需查找的元素只能在中间元素以外的前半部分或后半部分，例如给定表为升序排列时，若给定`key`大于中间元素，则所查找的元素只可能在后半部分，反之，只可能在前半部分。然后在缩小的范围内继续进行同样的查找，如此重复，直到找到为止，或确定表中没有所需要查找的元素，则查找失败，返回失败信息。有关算法如下：
```cpp
int Binary_Search(SSTable L,ElemType key){ //默认顺序表关键字按升序排序
    int low=0,high=L.TabeLen-1,mid;
    while(low<=high){
        mid=(low+high)/2; //取中间位置
        if(L.elem[mid]==mid)
            return mid; //查找成功则返回所在位置
        else if(L.elem[mid]>key)
            high=mid-1; //从前半部分继续查找
        else
            low=mid+1; //从后半部分继续查找
    }
    return -1; //查找失败，返回－1
}
```
折半查找的过程可以用下图所示的==二叉判定树==来描述。树中每个圆形结点表示一个记录，结点中的值为该记录的关键字值；树中最下面的叶子结点都是方形的，其表示查找不成功的情况，从判定树可以看出，查找成功时的查找长度为根结点到目的结点的路径上的结点数，而查找不成功的查找长度为从根结点到对应失败结点的父结点的路径上的结点数；每个结点值均大于其左子结点的值，且均小于右子结点的值。若有序序列共有$n$个元素，则对应的判定树有$n$个圆形的非叶子结点和$n+1$($n_0=n_2+1$)个方形的叶子结点。显然，==二叉判定树是一棵平衡二叉树==。

![Screenshot_2023-07-13-15-07-22-448_com.newskyer.draw.png](../_resources/Screenshot_2023-07-13-15-07-22-448_com.newskyer.dr.png)

 由上述分析可知，用折半查找查找到给定值的比较次数最多不会超过树的高度。在等概率查找时，查找成功的平均查找长度为：
$$
ASL = \frac{1}{n} \sum_{i=1}^{n} l_i = \frac{1}{n}(1 \times 1+ 2 \times 2+...+h \times 2^{h-1}) = \frac{n+1}{n}log_2(n+1)-1 \approx log_2(n+1)-1 \quad (when \quad n-> \infty)
$$
其中，$h$是树的高度，并且元素个数为$n$时树高$h=\lceil log_2(n+1) \rceil$。所以折半查找的时间复杂度为$O(log_2n)$，平均情况下比顺序查找效率更高。
    在上面的判定树中，在等概率的情况下，查找成功的$ASL=(1 \times 1+2 \times 2+3 \times 4 +4 \times 4)/11=3$，查找不成功的$ASL=(3 \times 4+4 \times 8)/12=3$。
==二叉查找判定树的构造==
来看这样两种情况，假如当前`low`与`high`指针之间有奇数个元素，那么在分割子树时，左右子树的个数应该相同；若之间有偶数个元素，假设$mid= \lfloor (low+high)/2 \rfloor$，则分割子树后，右半部分会比左半部分多一个元素。所以在上述分割规则下的二叉查找判定树中，对于任意一个结点，右子树结点数-左子树结点数=0或1。
> 不难看出，由于这一特性，二叉查找判定树一定是一棵平衡二叉树，且是较普通定义的平衡二叉树更为严格的平衡二叉树，在上述规则下，它限制了只能是右子树比左子树多1个结点或者相等。
>因为折半查找需要对顺序表进行随机访问，所以该查找方法仅适用于顺序存储结构，不适合于链式存储结构，且要求元素按关键字有序排列。

### 7.2.3 分块查找
分块查找又称索引顺序查找，它吸取了顺序查找和折半查找各自的优点，既有动态结构，又适于快速查找。
    分块查找的基本思想：将查找表分为若干子块。块内的元素可以无序，但块间的元素是有序的，即第一个块中的最大关键字小于第二个块中的所有记录的关键字，依次类推。再建立一个索引表，索引表中的每个元素含有各块的最大关键字和各块中第一个元素的地址，索引表按关键字有序排列。
    分块查找的过程分为两步：第一步是在索引表中确定带查记录所在的块，可以顺序查找或折半查找索引表；第二步是在块内顺序查找。
    分块查找的平均查找长度为索引查找和块内查找的平均长度之和。将长度为$n$的查找表均匀地分为$b$块，每块有$s$个记录，在等概率情况下，若在块内和索引表中均采用顺序查找，则平均查找长度为:
$$
ASL =L_I+L_S= \frac{b+1}{2} + \frac{s+1}{2}= \frac{s^2+2s+n}{2s}
$$
此时，若$s= \sqrt n$，则平均查找长度取最小值$\sqrt n+1$
>上面的描述中要求了索引表按关键字有序排列，目的是为了可以在第一步在索引表中确定记录所在块时可以使用二分查找加快查找效率，但实际在工程应用上，比如对于OS中的文件物理结构（文件的分配方式）中的索引分配方式，对索引表中不仅会进行查找操作，也常常会进行增加，删除操作，这时如果要在每次增加或删除后仍然保持索引表有序，花费的代价相较二分查找块的效率提升较大，所以这时往往不对索引表的有序进行限制，查找时使用顺序查找。

## 7.3 树型查找
### 7.3.1 二叉排序树（$BST$）
构造一棵二叉排序树的目的并不是为了排序，二是为了提高查找，插入和删除关键字的速度，二叉排序树这种非线性结构也有利于插入和删除的实现。
1.二叉排序树的定义
- 若左子树非空，则左子树上所有结点的值均小于根结点的值
- 若右子树非空，则右子树上所有结点的值均大于根结点的值
- 左，右子树分别也是一棵二叉排序树
根据二叉排序树的定义，左子树结点值＜根结点值＜右子树结点值，因此对二叉树进行==中序==遍历，可以得到一个递增的有序序列。
2.二叉排序树的查找
    二叉排序树的查找是从根结点开始，沿某个分支逐层向下比较的过程。若二叉排序树非空，先将给定值与根结点的关键字比较，若相等则查找成功；若不等，如果小于根结点的关键字，则在根结点的左子树上查找，否则在根结点的右子树上查找。下面给出一个递归查找的算法：
```cpp
BSTNode *searchBST(BiTreee* root, int target) {
    if (root == NULL || root->data == target) {
        return root;
    }
    if (target < root->data) {
        return searchBST(root->left, target);
    } else {
        return searchBST(root->right, target);
    }
}
```
3.二叉排序树的插入
    二叉排序树作为一种动态树表，其特点是树的结构通常不是一次生成的，而是在查找过程中，当树中不存在关键字值等于给定值的结点时再进行插入的。
    插入结点的过程如下：若原二叉排序树为空，则直接插入；否则，若关键字k小于根结点值，则插入到左子树，若关键字k大于根结点值，则插入到右子树。插入的结点一定是一个新添加的叶子结点，且是查找失败时查找路径上访问的==最后一个结点的左孩子或右孩子==。
4.二叉排序树的构造
    从一棵空树出发，依次输入元素，将它们插入二叉排序树中适合的位置。（即先查找，在查找失败路径上的最后一个根结点处选择插入位置）
5.==二叉排序树的删除==
    在二叉排序树中删除一个结点时，不能把以该结点为根的子树上的结点都删除，必须先把被删除结点从树上摘下，将因删除结点而断开的树重新链接起来，同时确保二叉排序树的性质。删除操作的实现过程有以下3种情形：
- 若被删除结点z是叶结点，则直接删除，不会破坏二叉排序树的性质。
- 若结点z只有一棵左子树或右子树，则让z的子树成为z父结点的子树，代替z的位置
- 若结点z有左，右两棵子树，则令z的==直接后继（或直接前驱）==（这里的前驱后继是整个有序序列的前驱后继）替代z，然后从二叉排序树中删除这个直接后继（或直接前驱），这样就转化为了前面两种情况。下图显示了在3种情形下分别删除结点45,78,78的过程：

![Screenshot_2023-07-13-16-37-35-878_com.newskyer.draw.png](../_resources/Screenshot_2023-07-13-16-37-35-878_com.newskyer.dr.png)

6.二叉排序树的查找效率分析
    二叉排序树的查找效率主要取决于树的高度，若二叉排序树的左，右子树高度之差的绝对值不超过1（平衡二叉树），则它的平均查找长度为$O(log_2n)$。若二叉排序树是一个只有右（左）孩子的单支树（类似于有序表的顺序查找判定树），则其平均查找长度为$O(n)$。
    在最坏的情形下，即构造的二叉排序树的输入序列是有序的（此时即为有序表的顺序查找判定树），则会形成一个倾斜的单支树，此时二叉排序树的性能最差，树的高度也增加为元素个数$n$。
    从查找过程上看，二叉排序树与二分查找相似，就平均性能而言，二叉排序上的查找和二分查找差不多。但二分查找的判定树唯一，而二叉排序树的查找不唯一，==相同的关键字其插入的顺序不同可能生成不同的二叉排序树==。
    就维护表的有序性而言，二叉排序树无序移动结点，只需要修改指针即可完成插入和删除操作，平均时间复杂度为$O(log_2n)$。二分查找的对象是有序顺序表，进行插入删除操作时，需要移动元素保持顺序表的有序性，时间复杂度为$O(n)$。因此当有序表是静态查找表时，宜采用顺序表作为其存储结构，采用二分查找进行查找操作；若有序表是动态查找表，则应选择二叉排序树作为其逻辑结构。

### 7.3.2 平衡二叉树（$AVL$树）
1.平衡二叉树的定义
    在二叉排序树的基础上，为了避免树的高度增长过快，降低二叉排序树的性能，规定在插入和删除结点时，要保证==任意结点的左，右子树高度差的绝对值不超过1==，这样的二叉树称为平衡二叉树($Balanced Binary Tree$)，或称$AVL$树。定义结点左子树与右子树的高度差为该结点的==平衡因子==，则该二叉树的结点的平衡因子的值只可能是-1,0或1。
    因此，平衡二叉树可定义为：或者是一棵空树，或者是具有下列性质的二叉树：它的左子树和右子树都是平衡二叉树，且左子树和右子树的高度之差的绝对值不超过1。
2.==平衡二叉树的插入==
    平衡二叉树保证平衡的基本思想如下：每当在二叉排序树中插入（或删除）一个结点时，首先检查其插入路径上的结点是否因为此次操作而导致了不平衡。若导致了不平衡，则先找到插入路径上离插入结点最近的平衡因子的绝对值大于1的结点A，再对以A为根的子树（以结点A为根结点的子树称之为最小不平衡子树），在保持二叉排序树特性的情况下，调整各结点位置，使之重新达到平衡。
>每次调整的对象都是最小不平衡子树，下图展示了一个结点插入时结点位置发生调整使之重新恢复平衡的过程，图中虚线框代表最小不平衡子树。

![Screenshot_2023-07-14-13-58-35-356_com.newskyer.draw.png](../_resources/Screenshot_2023-07-14-13-58-35-356_com.newskyer.dr.png)
    平衡二叉树的插入过程前半部分与二叉排序树相同， 都是先遍历找到合适的插入位置，但在新结点插入以后，若造成查找路径上的某个结点不再平衡，则需要做出相应的调整，可根据插入结点相对最小平衡子树根结点A的位置分为以下4种情形：
- $LL$平衡旋转（==右单旋转==）。由于在结点A的==左孩子($L$)的左子树($L$)上==插入了新结点，A的平衡因子由1增至2，导致以A为根的子树失去平衡，需要==一次向右的旋转操作==。将A的左孩子B向右上旋转代替A成为根结点，将A结点向右下旋转称为B的右子树的根结点，而B的原右子树则作为A结点的左子树。

![Screenshot_2023-07-14-14-06-17-827_com.newskyer.draw.png](../_resources/Screenshot_2023-07-14-14-06-17-827_com.newskyer.dr.png)

- $RR$平衡旋转（==左单旋转==）。由于在结点A的==右孩子($R$)的右子树($R$)上==插入了新结点，A的平衡因子由－1减至－2，导致以A为根结点的子树失去平衡，需要==一次向左的旋转操作==。将A的右孩子B向左上旋转代替A成为根结点，将A结点向左下旋转称为B的左子树的根结点，而B的原左子树则作为A结点的右子树。

![Screenshot_2023-07-14-14-10-49-784_com.newskyer.draw.png](../_resources/Screenshot_2023-07-14-14-10-49-784_com.newskyer.dr.png)

- $LR$平衡旋转（==先左后右双旋转==）。由于在结点A的==左孩子($L$)的右子树($R$)上==插入了新结点，A的平衡因子由1增至2，导致以A为根结点的子树失去平衡，需要==先左旋转后右旋转两次操作==。先将A的左孩子B的右子树的根结点C向左上旋转提升到B结点的位置，然后把该C结点向右上旋转提升到A结点的位置。

![Screenshot_2023-07-14-14-16-06-771_com.newskyer.draw.png](../_resources/Screenshot_2023-07-14-14-16-06-771_com.newskyer.dr.png)

- $RL$平衡旋转（==先右后左双旋转==）。由于在结点A的==右孩子($R$)的左子树($L$)上==插入了新结点，A的平衡因子由－1减至－2，导致以A为根结点的子树失去平衡，需要==先右旋转后左旋转两次操作==。先将A的右孩子B的左子树的根结点C向右上旋转提升到B结点的位置，然后把该C结点向左上旋转提升到A结点的位置。

![Screenshot_2023-07-14-14-19-06-754_com.newskyer.draw.png](../_resources/Screenshot_2023-07-14-14-19-06-754_com.newskyer.dr.png)

3.平衡二叉树的删除
    1）删除结点的操作与二叉排序树一致：
   - 若删除的是叶子结点，直接删除
   - 若删除的结点只有一棵子树，则直接用子树顶替删除位置
   - 若删除的结点有两棵子树，则用前驱（或者后继）结点复制信息，并转换为对前驱（或者后继）结点的删除。
    2）删除结点后，一路向北找到最小不平衡子树，如果找不到说明此时已经平衡，不必调整
    3）找到最小不平衡子树下，“个子”（树高）最高的儿子结点和孙子结点
    4）根据孙子结点相对于最小不平衡子树根结点的位置，对其进行与插入类似的调整操作（$LL,RR,LR,RL$）
   - 若孙子在$LL$，儿子右单旋
   - 若孙子在$RR$，儿子左单旋
   - 若孙子在$LR$，孙子先左旋再右旋
   - 若孙子在$RL$，孙子先右旋再左旋
     5）若不平衡继续向上传导，则继续按3),4)步骤进行调整，直到整棵树都平衡为止。

![Screenshot_2023-07-14-14-47-19-630_com.newskyer.draw.png](../_resources/Screenshot_2023-07-14-14-47-19-630_com.newskyer.dr.png)

>平衡二叉树的插入和删除操作较为复杂，但历年真题中均有涉及，其中，平衡二叉树的插入操作是重点。这部分需要来回复习，反复记忆。

4. 平衡二叉树的查找
   在平衡二叉树上进行查找的过程与二叉排序树的相同。因此，在查找过程中，与给定值进行比较的关键字个数不超过树的深度。假设以$n_h$表示深度为$h$的平衡树中含有的==最少结点数==。由数学归纳法可以得出有$n_0=0,n_1=1,n_2=2$，并且一般的有$n_h=n_{n-1}+n_{n-2}+1$。可以证明，含有$n$个结点的平衡二叉树的最大深度为$O(log_2n)$，因此平衡二叉树的平均查找长度为$O(log_2n)$。

![Screenshot_2023-07-14-14-54-23-121_com.newskyer.draw.png](../_resources/Screenshot_2023-07-14-14-54-23-121_com.newskyer.dr.png)

>注意这个结论可以用于求解给定结点数的平衡二叉树的查找所需的最多比较次数（或者树的最大高度）。
>比如：在含有12个结点的平衡二叉树中查找某个结点的最多比较次数是多少？
>这样考虑，只有1层时，最少有1个结点；2层时，最少有2个结点；3层时，最少有$n_3=n_1+n_2+1=4$个结点；4层时，最少有$n_4=n_2+n_3+1=7$个结点；5层时，最少有$n_5=n_4+n_3+1=12$个结点。所以树的最大高度为5，最多比较次数也为5

#### 7.3.3 红黑树
1.==红黑树的定义==
    为了保持$AVL$树的平衡性，在插入和删除操作后，需要频繁的调整全树整体的拓扑结构，代价较大，为此在$AVL$树的平衡标准上进一步放宽条件，引入了红黑树的结构。
    一棵红黑树是满足如下红黑性质的==二叉排序树==：
- 每个结点或是红色，或是黑色
- 根结点是黑色的
- 叶结点（虚构的外部结点，$NULL$结点）都是黑色的
- 不存在两个相邻的红结点（即任意红色结点的父结点和孩子结点均是黑色的）
- 对每个结点，从该结点到任意一个叶子结点的简单路径上，所含的黑色结点的数量相同。
> 也可以概括为：左根右（二叉排序树定义），根叶黑（性质2，3），不红红（性质4），黑路同（性质5）

与折半查找树和B树类似，为了便于对红黑树的实现和理解，引入了$n+1$个外部结点，以保证红黑树中每个结点（内部结点）的左，右孩子均非空。下图所示是一棵红黑树：

![Screenshot_2023-07-14-15-26-53-705_com.newskyer.draw.png](../_resources/Screenshot_2023-07-14-15-26-53-705_com.newskyer.dr.png)
    从某结点出发（不含该结点）到达一个叶子结点的任意一个简单路径上的黑结点的总数称为该结点的==黑高==（记为$bh$），黑高的概念是由性质5确定的。根结点的黑高称为红黑树的黑高。
    对于红黑树有下面两个重要结论：
- 从根到叶结点的最长路径不大于最短路径的2倍（换句话说任意结点的左右子树高度之差不超过2倍）。
- 有$n$个内部结点的红黑树的高度$h \leq 2log_2(n+1)$
- 新插入红黑树中的非根结点初始着为红色
由结论2可以得知，红黑树的查找效率为$O(log_2n)$量级，与$AVL$树一致。

2.红黑树的插入
- 先查找，确定插入位置（原理同二叉排序树）
- 新结点是根－－染为黑色
- 新结点非根－－先染为红色
  - 若插入新结点后依然满足红黑树定义，则插入结束
  - 若插入新结点后不满足红黑树定义（事实上对于非根结点只需要检查是否破坏了不红红的性质），则需要进行调整
    - 若插入结点的叔结点为黑色：则==染色（指的是红黑颜色取反）+旋转==。（属于什么类型看儿结点相对于爷结点的位置）
      - $LL$型：右单旋，父换爷+染色（父结点和爷结点染色）
      - $RR$型：左单旋，父换爷+染色（父结点和爷结点染色）
      - $LR$型：先左后右双旋，儿换爷+染色（儿结点和爷结点染色）
      - $RL$型：先右后左双旋，儿换爷+染色（儿结点和爷结点染色）
    - 若插入结点的叔结点为红色：则叔，父，爷结点均染色，爷结点视为新插入的结点。
> 红黑树是2022年大纲新增的考点，至今仍为考察过，按以前的出题规律，新增的考点第一次考察时往往不会太难，所以重点关注红黑树的概念以及相关性质和结论。最难最难考到插入操作，至于删除操作，太过复杂，考察概率极低。

## 7.4 $B$树和$B+$树
### 7.4.1 $B$树及其基本操作
所谓$m$阶$B$树是所有结点的平衡因子均等于0的$m$路平衡查找树
一棵$m$阶$B$树或空树，是满足以下特性的$m$叉树：
- 树中每个结点至多有$m$棵子树，即至多含有$m-1$个关键字
- 若根结点不是叶子结点，则至少有两棵子树
- 除根结点外的所有非叶结点至少有$\lceil m/2 \rceil$棵子树，即至少含有$\lceil m/2 \rceil-1$个关键字
- 所有非叶结点的结构如下：

<center>

|$n$|$P_0$|$K_1$|$P_1$|$K_2$|$...$|$K_N$|$P_N$|
|-|-|-|-|-|-|-|-|
</center>

其中，$K_i(i=1,2,...,n)$为结点的关键字，且满足$K_1<K_2<...<K_n$（即结点中的关键字从左到右递增有序）；$P_i(i=0,1,...,n)$为指向子树根结点的指针，且指针$P_{i-1}$所指子树中所有结点的关键字均小于$K_i$，$P_i$所指子树中所有结点的关键字均大于$K_i$，n为结点中关键字的个数。
- 所有的叶子结点都出现在同一层次上，并且不带信息（可以视为外部结点，或者类似于折半查找判定树的失败查找结点，实际上这些结点不存在，指向这些结点的指针为空）
上述性质棵归纳为下面核心的几条性质：
- 根结点的子树数量$\in [2,m]$，关键字个数$\in [1,m-1]$
- 非根非叶子（外部结点）结点的子树数量$\in [\lceil m/2 \rceil,m]$；关键字个数$\in [\lceil m/2 \rceil-1,m-1]$
- 对任意结点而言，其所有的子树高度均相同
- 结点的孩子个数（指向子树的指针个数）等于该结点中关键字个数加1
- 结点中的关键字从左到右递增有序，关键字两侧均有指向子树的指针，左侧指针所指子树的所有关键字均小于该关键字，右侧指针所指子树的所有关键字值均大于该关键字。也可以看做是由该关键字将两侧的子树划分为了两个子区间。

![Screenshot_2023-07-14-17-15-47-411_com.newskyer.draw.png](../_resources/Screenshot_2023-07-14-17-15-47-411_com.newskyer.dr.png)

1.$B$树的高度（磁盘存取次数）
$B$树中的大部分操作所需的磁盘存取次数与$B$树的高度成正比。
下面对$B$树的高度进行分析（注意这里在计算时$B$树的高度时，最后一层外部结点并不包含在其中）
假设$n \geq 1$，则对任意一棵包含$n$个关键字，高度为$h$，阶数为$m$的$B$树而言：
- 最小高度：要使$B$树的高度最小，即每个结点关键字个数和分支数应该尽可能多，对于$B$树而言，每个结点最多有$m$棵子树，$m-1$个关键字，所以在一棵高度为$h$的$m$阶$B$树中关键字的个数应该满足:$n \leq (m-1)(1+m+m^2+...+m^h-1)=m^h-1$，因此有:
$$
h \geq log_m(n+1)
$$
- 最大高度：从这样的角度考虑，要使高度最大，即每个结点关键字个数和分支个数尽可能少，但$B$树每个结点最少有$\lceil m/2 \rceil$（记为$k$）个子树，$k-1$个关键字，且第一层根结点至少有一个结点，一个关键字，所以这样来看除去第一层，从第二层开始，以$k$为公比，共有$h-1$层其结点总数为：$\frac{2(1-k^{h-1})}{1-k}$，关键字总数为$\frac{2(1-k^{h-1})}{1-k} \cdot (k-1)$。所以其关键字总数应满足:$n \geq \frac{2(1-k^{h-1})}{1-k} \cdot (k-1)+1=2k^{h-1}-1$，即：
$$
h \leq log_{\lceil m/2 \rceil}((n+1)/2)+1
$$
> 不必记忆最后的公式，应该其牢记推理过程，在考场上根据题目所给条件列出不等式解即可

2.$B$树的查找
    $B$树的查找包含两个基本操作：1.在$B$树中找到结点；2.在结点内查找关键字。由于$B$树常存储在磁盘上，因此==前一个查找操作是在磁盘上进行的，而后一个查找操作是在内存中进行的==，即找到目标结点后，先将结点信息读入主存，然后在结点内采用顺序查找或二分查找查找关键字。
    在$B$树上查找到某个结点后，先在结点内部的关键字有序表中进行查找，若找到则查找成功，否则按照对应的指针信息到所指的子树中去查找。例如在上图的$B$树中查找关键字42，首先从根结点开始，根结点只有一个关键字且42>22，若存在，则必在关键字22点右边子树上，于是指针指向右子树，从36开始查找，而36<42<45，若存在，必在36和45中间的子树上，在该子结点中查找到42，查找成功。（若查找到外部结点，即指针为空时，说明查找失败，树中没有对应的关键字）
3.$B$树的插入
    将关键字`key`插入$B$树的过程如下：
- 定位。利用$B$树的查找算法，找到插入该关键字的最底层中的某个非叶结点。注意：插入位置一定是最底层中的某个非叶子结点。
- 插入。在$B$树中，每个非失败结点的关键字个数都在区间$[\lceil m/2 \rceil-1,m-1]$内，若插入后的结点关键字个数小于$m$，则可以直接插入；插入后检查被插入结点内的关键字个数，当插入后的结点关键字个数大于$m-1$时，必须对结点进行分裂。
- 分裂的方法是：取一个新结点，在插入`key`的后的原结点，从中间位置($\lceil m/2 \rceil$)将其中的关键字分为两部分，左部分包含的关键字放在原结点中，右部分包含的关键字放到新结点中，中间$\lceil m/2 \rceil$位置的结点插入原结点的父结点。若此时导致其父结点的关键字个数也超过了上限，则继续这种分裂操作，直至这个过程传到根结点为至，此时$B$树的高度加1。
  对于下面$m=3$的$B$树,所有结点中最多有$m-1=2$个关键字，若某个结点中已经含有了两个关键字，则结点已满。如下图，$B$树插入一个关键字60后，结点内的关键字个数超过了2，则进行结点分裂，52上移到根结点，原结点中以52为界分裂出两个同级结点。
  
![Screenshot_2023-07-16-14-14-12-751_com.newskyer.draw.png](../_resources/Screenshot_2023-07-16-14-14-12-751_com.newskyer.dr.png)
4.$B$树的删除
    $B$树中进行删除操作可能会使得删除后结点中的关键字个数小于$\lceil m/2 \rceil-1$，因此将涉及结点的“合并”问题。
    当被删关键字$k$不在终端结点（最底层非外部结点）中时，可以用$k$的直接前驱（或后继）$k'$来替代，进而转换为删除相应结点$k'$（这点与二叉排序树相同），关键字$k'$必定落在某个终端结点中，则转换成了被删关键字在终端中的情形。因此只需要讨论删除终端结点中的关键的情形：

![Screenshot_2023-07-16-14-32-25-723_com.newskyer.draw.png](../_resources/Screenshot_2023-07-16-14-32-25-723_com.newskyer.dr.png)
    当被删关键字在终端结点中时，有下列三种情况：
- 直接删除关键字。若被删关键字所在结点的关键字个数$\geq \lceil m/2 \rceil$，表明删除该关键字后仍满足$B$的定义，则直接删除该关键字。
- 兄弟够借。若被删关键字所在结点删除前的关键字个数$=\lceil m/2 \rceil-1$，且与该结点相邻的右（或左）兄弟结点的关键字个数$\geq \lceil m/2 \rceil$，则需要调整该结点，右（或左）兄弟结点及其双亲结点（父子换位法），以此达到新的平衡。如下，在删除4阶$B$的关键字65时，右兄弟关键字个数$\geq \lceil m/2 \rceil=2$，将71取代原来的65，74调整到71的位置。此时并未产生结点合并的情况。
- 兄弟不够借。此时会产生结点的合并，若被删结点所在结点的关键字个数及其与该结点相邻的左右兄弟结点的关键字个数均$=\lceil m/2 \rceil-1$，则将关键字删除后与左（或右）兄弟结点及双亲结点中的关键字进行合并。在下图中，删除4阶$B$的关键字5，它及其右兄弟结点的关键字个数$=\lceil m/2 \rceil-1=1$，故在5删除后将60合并到65结点中。

![Screenshot_2023-07-16-14-36-58-452_com.newskyer.draw.png](../_resources/Screenshot_2023-07-16-14-36-58-452_com.newskyer.dr.png)
    在合并过程中，双亲结点中的关键字个数会减一。若其双亲结点时根结点且关键字个数减少至0，则直接将根结点删除，将合并后的新结点作为根；若双亲结点不是根结点，且关键字个数减少到$\lceil m/2 \rceil-2$，则又要与它自己的兄弟结点进行调整或合并操作，并重复上述步骤，直至符合$B$树定义。
### 7.4.2 $B+$树的基本概念
$B+$树是为了应数据库所需而出现的一种$B$树的变形树。
    一棵$m$阶$B+$树应满足以下条件：
- 每个分支结点最多有$m$棵子树
- 非叶根结点至少有两棵子树，其他每个分支结点至少会有$\lceil m/2 \rceil$棵子树
- 结点的子树个数与关键字个数相等
- 所有的叶结点包含全部关键字及其指向相应记录的指针，叶结点中将关键字按大小顺序排列，并且相邻叶结点按大小顺序相互链接起来
- 所有分支结点（可看作索引的索引）中仅包含它的各个子结点（即下一级的索引块）中关键字的最大值及指向其子结点的指针
$m$阶的$B+$树与$m$阶的$B$树的==主要差异==如下：
> $B$树可以看做每层结点是在对有序序列做区间分割，且关键字实际（指向真实存储地址）分布在各层结点中，而$B+$树类似于多层索引结构，每层关键字是下一层索引块的最大值，非叶结点的关键字只其索引作用，关键字真正的指针均存放在叶结点中。

- 在$B+$树中，具有$n$个关键字的结点只含有$n$棵子树，即每个关键字对应一棵子树；而在$B$树中，具有$n$个关键字的结点含有$n+1$棵子树(n个结点将区间划分出n+1个区间)
- 在$B+$树中，每个结点（非根内部结点）的关键字个数$n$的范围是$[\lceil m/2 \rceil,m]$（而根结点$[2,m]$）；而在$B$树中，每个结点（非根内部结点）的关键字个数$n$的取值范围是$[\lceil m/2 \rceil-1,m-1]$（根结点$[2,m-1]$）。
- 在$B+$树中，叶结点包含了所有的关键字，非叶结点中出现的关键字也会出现在叶结点中（即每个关键字在树中可能不止出现一次）；而在$B$树中，关键字分布在各层结点中（即每个关键字在树中仅出现一次）。
- 在$B+$树中，仅仅叶结点包含信息（指向实际存储地址），所有的非叶结点仅起索引作用，非叶结点中的每个索引项只含有对应子树的最大关键字值和指向该子树的指针。所以在$B+$树中不论查找成功与否一定需要查找到叶结点层（即使非叶结点索引值等于查找关键字，也仍需查找到叶结点层的对应结点关键字值，只有在叶结点中的关键字才会存放其存储地址），而在$B$树可能在任意层查找到关键字。
    下图呈现了一棵4阶$B+$树。可以看出，分支结点的某个关键字是其子树中最大关键字的副本。通常在$B+$树中有两个头指针，一个指向根结点，另一个指向关键字最小的叶结点。因此$B+$树可以进行两种查找运算：一种是从最小关键字开始顺序查找（便于数据库经常进行的范围查询操作），另一种是从根结点开始的多路查找。
>补充：B+树对于B树而言拥有更少的磁盘I/O次数（每个非叶结点中只含有索引信息，一次I/O可读入更多索引结点）；更稳定的查找效率（不论查找成功与否，查找路径的长度唯一，都需要从根结点到叶结点）；便于数据库的范围查询。
>这部分的内容历年真题中均有涉及，是重点及难点。对于B树重点需要掌握其定义以及插入，删除操作。B+树则仅需掌握其定义，重点关注其与B树的区别。

## 7.5 散列表（$Hash$（哈希）表）
### 7.5.1 散列表的基本概念
前面的查找方法是建立在与关键字比较的基础上的，其查找的效率取决于比较的次数。
散列函数：一个把查找表中的关键字映射称为该关键字对应的地址的函数，记为$Hash(key)=Addr$（这里的地址可以是数组下标，索引或内存地址等）
散列函数可能会把两个及两个以上的不同关键字映射到同一地址，称这种情况为==冲突==，这些发生碰撞的不同关键字称为==同义词==。一方面，设计好的散列函数应尽量减少这样的冲突，另一方面，由于这样的冲突往往是不可避免的，所以还需设计好处理冲突的方法。
散列表：根据关键字而直接进行访问的数据结构，也即:==散列表建立了关键字和存储地址之间的一种直接映射关系==。
### 7.5.2 散列函数的构造方法
1. 直接定址法
直接取关键字的某个线性函数值作为散列地址，散列函数为：
$$
H(key)=key \quad or \quad H(key)=a \times key + b
$$
其中，$a$和$b$为常数。这种计算方法最为简单，且不会产生冲突，它适合关键字的分布基本连续的情况，若关键字分布不连续，空位较多，则会造成存储空间的浪费。
2. 除留余数法
这是一种最简单，最常用的方法，假定散列表表长为$m$，取一个不大于$m$但最接近或等于$m$的质数$p$，利用下公式把关键字映射为散列地址，散列函数为：
$$
H(key)=key \% p
$$
除留余数法的关键是选好$p$，使得每个关键字通过该函数转换后等概率的映射到散列空间的任意一个地址，从而尽可能的减少冲突的可能。
3. 数字分析法
设关键字是$r$进制（如十进制），而$r$个数码在各位上出现的频率不一定相同，可能在某些位上分布均匀一些，每种数码出现的机会均等；而在某些位上分布不均匀，此时应该选取数码分布较为均匀的若干位作为散列地址。（身份证号码）
4.平方取中法
这种方法取关键字的平方值的中间几位作为散列地址。具体取多少位视情况而定。这种方法得到的散列地址与关键字的每位都有关系，因此使得散列地址分布比较均匀，适用于关键字的每位取值都不够均匀或均小于散列地址所需的位数。
### 7.5.3 处理冲突的方法
任何设计出来的散列函数都不可能绝对的避免冲突。为此，必须考虑发生冲突时应该如何处理，即为产生冲突的关键字寻找下一个“空”的$Hash$地址。用$H_i$表示处理冲突中第$i$次探测得到的散列地址，假设得到的另一个散列地址$H_1$仍然冲突，只能继续求下一个$H_2$，依次类推，直到$H_k$不发生冲突为止，则$H_k$为关键字在表中的地址。
1. 开放定址法
   所谓开放定址，是指可存放新表项的空闲地址既向它的同义表项开放，又向它的非同义表项开放。其数学递推公式为：
$$
H_i=(H(key)+d_i) \% m
$$
其中，$H(key)$为散列函数；$i=0,1,2,...,k (k \leq m-1)$;$m$表示散列表表长；$d_i$为递增序列。
    取定某一增量序列后，对应的处理方法就是确定的。通常有以下4种取法：
- 线性探测法。当$d_i=0,1,2,...,m-1$时，称为线性探测法。这种方法的特点是：冲突发生时，顺序查看表中下一个单元（探测到表尾地址$m-1$时，下一个探测地址是表首地址0），直到找到一个空闲单元（当表未满时一定可以找到一个空闲单元）或查遍全表。线性探测法可能使第$i$散列地址的同义词存入第$i+1$个散列地址，这样本应该存入第$i+1$个散列地址的元素就争夺第$i+2$个散列地址的元素的地址......从而造成大量元素在相邻的散列地址上“聚集”（或堆积）起来，大大降低了查找效率
- 平方(二次)探测法。当$d_i=0^2,1^2,-1^2,2^2,-2^2,...,k^2,-k^2$时，称为平方探测法，其中$k \leq m/2$，散列表长度$m$必须是一个可以表示成$4i+3$的素数。平方探测法是一种处理冲突的好方法，可以避免堆积问题，它的缺点是不能探测到散列表上的所有单元，但至少可以探测到一半单元。
- 伪随机序列法。当$d_i=random(m)$时，称为伪随机序列法。
- 再散列函数法：除了原式的散列函数$H(key)$外，多准备几个散列函数，当发生冲突时，用下一个散列函数计算一个新的散列地址，直到不冲突为止：
$$
H_i=RH_i(key) \quad i=1,2,3,...,k
$$
2.拉链法（链接法，$chaining$）
显然，对于不同的关键字可能会通过散列函数映射到同一地址，为了避免非同义词的冲突，可以把所有的同义词存储在一个线性表中，这个线性链表由其散列地址唯一标识。假设散列地址为$i$的同义词链表的头指针存放在散列表的第$i$的单元中，因而查找，插入和删除操作都在同义词链中进行。拉链法使用于经常进行插入和删除的情况。下图为关键字序列为$\{19,14,23,01,68,20,84,27,55,11,10,79 \}$，散列函数为$H(key)=key \% 13$，用拉链法处理冲突建立的哈希表：

<center>
<img src="../_resources/Screenshot_2023-07-16-17-00-11-890_com.newskyer.dr.png" alt="图片描述" width="400" height="300">
</center>

### 7.5.3 散列查找及其性能分析
散列表的查找效率取决于三个因素：散列函数，处理冲突的方法以及装填因子。
装填因子。散列表的装填因子一般记为$\alpha$，定义为一个表的装满程度，即
$$
\alpha=\frac{表中记录n}{散列表长度m}
$$
这部分的重点在于查找长度$ASL$的计算，下面以开放定址中的线性探测为例，说明一些需要注意的点：
考虑这样一个关键字序列$\{19,14,23,01,68,20,84,27,55,11,10,79 \}$，散列函数为$H(key)=key \% 13$：
1.查找关键字序列中存在的元素：
![Screenshot_2023-07-16-17-10-29-441_tv.danmaku.bilibilihd.png](../_resources/Screenshot_2023-07-16-17-10-29-441_tv.danmaku.bili.png)
比如查找27，$H(key)=27%13=1$(冲突)->$H_1=2$(冲突)->$H_2=3$(冲突)->$H_3=4$(查找成功) ，所以27的查找长度为4
2.查找关键字序列中不存在的元素：
![Screenshot_2023-07-16-17-14-21-861_tv.danmaku.bili.png](../_resources/Screenshot_2023-07-16-17-14-21-861_tv.danmaku.bili.png)
比如查找21，$H(key)=21%13=8$(冲突)->$H_1=9$(冲突)->$H_2=10$(冲突)->$H_3=11$(冲突)->$H_4=12$(冲突)->$H_5=11$(失败) ，查找长度为6
>注意这里查找失败时，最后一个空位置的判断也要算作一次比较

3.删除元素：
在开放定址的情形下，不能简单的将被删结点的空间置空，否则将截断在它填入散列表的同义词结点的查找路径，解决办法是做一个删除标记，从逻辑上删除结点，但在查找时应该继续向后探测。
比如在上例中删除下标为2的元素后查找27：
![Screenshot_2023-07-16-17-20-37-724_tv.danmaku.bili.png](../_resources/Screenshot_2023-07-16-17-20-37-724_tv.danmaku.bili.png)
如果只是简单的在物理上删除结点，那么在查找27时，指针将会在2处跳出，并返回查找失败，但事实上散列表中是存在该关键字的，所以采用了上述的处理办法后，$H(key)=27%13=1$(冲突)->$H_1=2$(冲突)->$H_2=3$(冲突)->$H_3=4$(查找成功) ，查找长度为4
4.查找效率分析($ASL$)
查找成功的平均长度：
对于上面的例子而言，使用线性探测法依次对每个元素需要查找成功的次数进行计算：如下:
![Screenshot_2023-07-16-17-32-09-942_tv.danmaku.bili.png](../_resources/Screenshot_2023-07-16-17-32-09-942_tv.danmaku.bili.png)
$19 \% 13=6->1次 \quad 27 \% 13=1->4次 \quad 55 \% 13=3->3次$
$14 \% 13=1->1次 \quad 68 \% 13=3->1次 \quad 11 \% 13=11->1次$
$23 \% 13=10->1次 \quad 20 \% 13=7->1次 \quad 10 \% 13=10->3次$
$1 \% 13=1->2次 \quad 84 \% 13=6->3次 \quad 79 \% 13=3->9次$
$$
ASL_{成功}=\frac{1+1+1+2+4+1+1+3+3+1+3+9}{12}=2.5
$$
查找失败的平均长度：
查找失败的位置个数是取模的大小，对于上面的例子，假设映射到0位置，那么查找失败，比较次数为1；映射到1位置，则根据线性探测法，后面的每一个位置都需要比较才能确定查找失败（包括后面的空值位置），比较次数为13，依次类推，上例的查找失败的平均长度为：
$$
ASL_{失败}=\frac{1+13+12+11+10+9+8+7+6+5+4+3+2}{13}=7
$$
>拉链法的查找效率同理，但需要注意的是拉链法中若某个散列地址下没有挂载同义词链表，即该地址的指针为空指针，这里的空指针不计入比较次数中

# 8.排序
## 8.1 排序的基本概念
排序：即重新排列表中的元素，使表中的元素满足按关键字有序的过程。
==算法的稳定性==:若待排序表中有两个元素$R_i$和$R_j$，其对应的关键字值相同即$key_i=key_j$，且在排序前，$R_i$在$R_j$之前，若使用某一种排序算法排序后，$R_i$仍在$R_j$前面，则称这个排序算法是==稳定的==，反之则称为不稳定的。
>对于不稳定的排序算法，只需举出一组关键字的实例，说明其不稳定即可

内部排序和外部排序：在排序过程中，根据数据元素是否完全在内存中，可将排序算法分为两类：
- 内部排序，是指在排序期间元素全部存放在内存中的排序
- 外部排序，是指在排序期间元素无法全部存放在内存中，在排序的过程中会进行内存与外存的$I/O$。
>大多数的内部排序算法只使用于顺序存储的线性表
>后续排序算法中若未明确说明，默认排序结果为升序

## 8.2 插入排序
插入排序的基本思想是每次将一个待排序的记录按其关键字大小插入前面已排好序的子序列，直到全部记录插入完成。
### 8.2.1 直接插入排序
根据上面的思想，可以得出一个最简单和最直观的直接插入排序算法。假设在排序过程中，待排序表$L[1...n]$在某次排序过程中的某一时刻状态如下：

<center>
    
|$有序序列L[1...i-1]$|$L(i)$|$无序序列[i+1...n]$|
|-|-|-|

</center>

要将元素$L(i)$插入已有序的子序列$L[1...i-1]$，需要执行下面的操作：
- 查找出$L(i)$在$L[1...i-1]$中的插入位置$k$
- 将$L[k...i-1]$中的所有元素依次后移一个位置
- 将$L(i)$复制到$L(k)$

![Screenshot_2023-07-18-16-14-04-347_com.newskyer.draw.png](../_resources/Screenshot_2023-07-18-16-14-04-347_com.newskyer.dr.png)
直接插入排序算法的性能分析如下：
空间效率：仅使用了常数个辅助单元，因而空间复杂度为$O(1)$。
时间效率：在最好情况下，表中元素已经有序，此时每插入一个元素，都只需要比较一次而不用移动元素，因而时间复杂度为$O(n)$；最坏情况下，表中元素顺序刚好与排序结果中的元素顺序相反，总的比较次数最大，总的移动元素次数也最大，总的时间复杂度为$O(n^2)$。
平均情况下，考虑待排元素表中元素是随机的，取平均下，直接插入排序算法的时间复杂度为$O(n^2)$
稳定性：每次插入元素时总是从后向前先比较再移动，所以不会发生相同元素相对位置改变的情况，因此直接插入排序是一个==稳定的==排序方法。

### 8.2.2 折半插入排序
在上述的直接插入排序中，不难看出每趟插入的过程中都干了两件事：1.从前面的有序子表中查找出待插入元素应该被插入的位置；2.给插入位置腾出空间，将待插入元素复制到表中的插入位置。注意到上面的算法中，总是边比较边移动元素，折半插入排序的思路是把这两个操作分离，即先使用折半查找找出元素的待插入位置，然后统一的移动待插入位置之后的所有元素。
从上述算法中，不难看出折半插入排序仅减少了元素直接的比较次数，约为$O(nlog_2n)$，该比较次数与待排序表的初始状态无关；而元素的移动次数并未改变。因此，折半插入排序的时间复杂度仍是$O(n^2)$。折半插入排序是一种==稳定的==排序方法。
>注意折半插入由于使用到了折半查找，所以需要待排序线性表使用顺序存储。

### 8.2.3 希尔排序
希尔排序的基本思想是：先将待排序表分割成若干形如$L[i,i+d,i+2d,...,i+kd]$的“特殊”子表，即把相隔某个“增量”的记录组成一个子表，对各个子表分别进行插入排序，当整个表中的元素已呈“基本有序”时，再对全体记录进行一次直接插入排序。
希尔排序的过程如下：先取一个小于$n$的步长$d_1$，把表中的全部记录分为$d_1$组，所有距离为$d_1$的倍数的记录放在同一组，在各组内进行直接插入排序；然后取第二个步长$d_2<d_1$，重复上述步骤，直到所取到的$d_t=1$，即所以记录已放在同一组中，再进行直接插入排序，由于此时已经具有较好的局部有序性，故可以很快得到结果。下面展示了一个实例：

![Screenshot_2023-07-18-16-17-20-790_com.newskyer.draw.png](../_resources/Screenshot_2023-07-18-16-17-20-790_com.newskyer.dr.png)
希尔排序算法的性能分析如下：
空间效率：仅使用了常数个辅助单元，因而空间复杂度为$O(1)$
时间效率：由于希尔排序的时间复杂度依赖于增量序列的函数，这涉及数学上尚未结局的难题，故其时间复杂度分析比较困难。当$n$在某个特定范围时，希尔排序的时间复杂度约为$O(n^{1.3})$。最坏情况下希尔排序的时间复杂度为$O(n^2)$
稳定性：当相同关键字的记录被划分到不同子表时，可能会改变它们之间的相对次序，因此希尔排序是一种==不稳定的==的排序方法。
>希尔排序算法也仅适用于线性表为顺序存储的情况

## 8.3 交换排序
交换排序的思想在于根据序列中两个元素关键字的比较结果来调整（对换）这两个记录在序列中的位置。
### 8.3.1 冒泡排序
冒泡排序的基本思想是：从后往前（或者从前往后）两两比较相邻元素的值，若为逆序（即$A[i-1]>A[i]$），则交换它们，直到序列比较完。称其为第一趟冒泡，结果是将最小的元素依次交换到了待排序序列的第一个位置（或将最大的元素交换到待排序序列的最后一个位置）。下一趟冒泡时，前一趟已经确定位置的元素不在参与比较，每趟冒泡的结果是把当前的未排序序列中的最小值（或最大值）放到了最终的序列位置.....这样最多只需要$n-1$趟冒泡就能把所有元素排好序，下图展示了一个冒泡排序的实例：
> 有的待排序列可能不需要$n-1$趟就已经完成了最终有序序列的调整

![Screenshot_2023-07-18-16-30-31-537_com.newskyer.draw.png](../_resources/Screenshot_2023-07-18-16-30-31-537_com.newskyer.dr.png)
冒泡排序的代码如下：
```cpp
void BubbleSort(ElemType A[],int n){
    for(int i=0;i<n-1;i++){
        bool flag=false; //表示本趟冒泡是否发生交换
        for(int j=n-1;j>i;j--){ //一趟冒泡
            if(A[j-1]>A[j]){ //若为逆序
            swap(A[j-1],A[j]); //交换
            flag=true; 
            }
        }
        if(!flag) return; //若本趟遍历后没有发生交换，说明此时表已经有序，直接return，此时冒泡的趟数可能没有走完n-1趟
    }
}
```
冒泡排序的效率分析如下：
空间效率：仅使用了常数个辅助单元，空间复杂度为$O(1)$
时间效率：最好情况下时间复杂度为$O(n)$，最坏情况时间复杂度为$O(n^2)$，平均时间复杂度为$O(n^2)$。
稳定性：由于$i>j$且$A[i]=A[j]$时不会发生交换，因此冒泡排序是一种==稳定==的排序方法。
>注意：冒泡排序中所产生的有序子序列一定是全局有序的（不同于直接插入排序，直接插入排序的序列仅局部有序），也即有序子序列中的元素一定全部小于（或大于）无序子序列中所有元素都关键字，这样每趟排序都会将一个元素放到其最终的位置上。

### 8.3.2 **快速排序**
快速排序的思想是基于分治的；在待排序表$L[1...n]$中任取一个元素`privot`作为枢轴（或称基准，通常取首元素），通过一趟排序将待排序表分为独立的两部分$L[1...k-1]$和$L[k+1...n]$，使得$L[1...k-1]$中的所有元素小于`privot`，$L[k+1...n]$中的所有元素大于或等于`privot`，则`privot`放在了其最终的位置$L(k)$上，这个过程称为一次划分。然后分别递归对两个子表重复上述过程，直至每部分内只有一个元素或空格为止，即所有元素都放在了最终的位置上。
一趟快速排序的过程是一个交替搜索和交换的过程，下面通过一个实例来说明，设两个指针`i`和`j`，初值分别为`low`和`high`，取第一个元素49为枢轴赋值到变量`privot`。

![Screenshot_2023-07-18-17-02-34-645_com.newskyer.draw.png](../_resources/Screenshot_2023-07-18-17-02-34-645_com.newskyer.dr.png)
![Screenshot_2023-07-18-17-02-46-838_com.newskyer.draw.png](../_resources/Screenshot_2023-07-18-17-02-46-838_com.newskyer.dr.png)
快速排序的代码十分重要，在数据结构部分的代码大题中，可能会碰到某些问题先进行排序会减少最后整体的时间复杂度，这时候就需要一个排序模板来先进排序，若题目没有要求则直接套快排模板，下面给出了一个ACWing上的快排模板，代码应熟稔于心：
>下面快排模板的思想与上面给出的略有不同，下面给出的模板书写上更加简洁，不必纠结实现的具体细节，照背即可，但是快排的思想以上面为主
```cpp
void quick_sort(int q[], int l, int r) {
    if (l >= r)   return; // 如果左边界大于等于右边界，说明区间为空或者只有一个元素，无需排序，直接返回
    // 选择枢轴元素x为中间元素
    int x = q[l + r >> 1],i = l - 1,j = r + 1; 
    // 开始快速排序过程
    while (i < j) {
        do i++; while (q[i] < x);  // 左指针向右移动，直到找到一个大于等于枢轴元素x的值
        do j--; while (q[j] > x);  // 右指针向左移动，直到找到一个小于等于枢轴元素x的值
        if (i < j)  swap(q[i], q[j]); // 如果左指针i还在右指针j的左侧，则交换q[i]和q[j]，将较大值放在右边，较小值放在左边
    }
    // 递归对左半部分和右半部分进行快速排序
    quick_sort(q, l, j); // 左半部分，左指针为l，右指针为j
    quick_sort(q, j + 1, r); // 右半部分，左指针为j+1，右指针为r
}

int main() {
    int n;
    scanf("%d", &n); 
    int q[n]; 
    for (int i = 0; i < n; i++) 
        scanf("%d", &q[i]);
    quick_sort(q, 0, n - 1); // 调用快速排序函数对数组q进行排序，左边界为0，右边界为n-1
    for (int i = 0; i < n; i++) 
        printf("%d ", q[i]);
    return 0;
}
```
快速排序算法的性能分析如下：
空间效率：由于快速排序是递归的，需要借助递归工作栈，其容量与递归调用的最大深度一致。最好情况下为$O(log_2n)$；最坏情况下为$O(n)$；平均情况下，栈的深度为$O(log_2n)$。
时间效率：快速排序的运行时间与划分是否对称有关，快速排序的最坏情况发生在两个区域分别包含$n-1$个元素和0个元素时，这种最大限度的不对称发生在每一层的递归上，即对应与初始排序表基本有序或基本逆序时，就得到最坏情况下的时间复杂度为$O(n^2)$。最理想情况下，枢轴元素每次都做到了最平衡的画法，得到的两个子问题的大小都不大于$n/2$，在这种情况下，快速排序的速度最快，时间复杂度为$O(log_2n)$。由于带排序列基本是随机存放的，基本有序的情况很少，所以快排的平均时间复杂度和最佳时间复杂度近似，所以快排的平均时间复杂度为$O(log_2n)$。
>快速排序是所有内部排序算法中平均性能最优的排序算法

稳定性：在划分过程中，若右端区间有两个关键字相同，且均小于基准值，则在交换到左侧区间后，两者的相对位置会发生改变。也即快排是一种==不稳定==的排序方法。
>注意在快排中，并不产生有序子序列，但每趟排序后都会将上一趟划分各个无序子表的枢轴元素放到最终的位置上，即每一趟都至少会确定一个枢轴元素的最终位置

## 8.4 选择排序
选择排序的基本思想是：每一趟（如第$i$趟）在后面$n-i+1(i=1,2,...,n-1)$个待排序元素中选取关键字最小的元素，作为有序子序列的第$i$个元素，直到走完$n-1$趟，待排序元素只剩一个，此时序列已经有序。
>本章中堆排序是历年考察的重点

### 8.4.1 简单选择排序
根据上面选择排序的思想，可以很容易得到简单排序算法的思想：假设排序表为$L[1...n]$，第$i$趟排序即从$L[i...n]$中选择关键字最小的元素与$L(i)$交换，每趟排序可以确定一个元素的最终位置，这样经过$n-1$趟就可以获得最终的有序序列。
简单选择排序的性能如下：
空间效率：仅使用常数个辅助单元，故空间效率为$O(1)$
时间效率：由于元素间比较次数与序列的初始状态无关，始终是$n(n－1)/2$次，因此时间复杂度始终是$O(n^2)$
稳定性：简单选择排序是一种==不稳定的==排序方法

### 8.4.2 堆排序
堆（$Heap$）的定义如下：$n$个关键字序列$L[1...n]$满足下列定义时：
- $L(i) \geq L(2i) 且 L(i) \geq L(2i+1)$ 大根堆
- $L(i) \leq L(2i) 且 L(i) \leq L(2i+1)$ 小根堆 $1 \leq i \leq \lfloor n/2 \rfloor$
将堆看做是完全二叉树的顺序存储，上面的定义可简化为：大根堆即满足在完全二叉树中任意结点关键字均大于等于左右子结点（反之为小根堆）。
堆排序的思路：首先将存放在数组中的$n$个元素建成初始堆（大根堆），堆顶元素即为最大值，然后将待排序序列的最后一个关键字与堆顶元素交换，此时堆被破坏，然后对堆进行调整，此时之前交换的最后一个关键字不计入堆内，调整完毕后，继续将待排序序列的最后一个关键字与堆顶元素交换，如此往复$n-1$趟。不难发现堆排序的关键在于解决两个问题：1.如何构建初始堆？2.在交换堆顶元素后，如何进行调整使其重新变成堆？
- 构建初始堆：$n$个结点的完全二叉树，最后一个分支结点为$\lfloor n/2 \rfloor$，只需要从最后一个分支结点开始，依次向前对每个分支结点进行调整，如果当前结点不满足堆的定义，则将当前结点左右孩子中的最大值与根结点交换。交换后，可能会破坏下一级的堆，于是按照上面的方法继续调整，直到整棵树满足堆的定义。
- 交换堆顶元素与待排序最后一个元素后，堆的性质被破坏，那么对交换到根结点的小元素进行不断的下坠调整，直到再次满足大根堆定义。
对于堆而言还有两个基本操作，插入和删除：
- 堆的插入操作，在对堆进行插入操作时，先将新结点放在堆的末端，再对这个结点进行“上升”操作（根父结点作比较，不满足堆定义则交换），直到无法上升为止。
- 堆的删除操作，在对堆进行删除操作时，先将被删除元素用堆的最后一个堆底替代，然后该元素不断“下坠”，直到无法下坠为止。
堆排序算法的性能分析如下：
空间效率：仅使用了常数个辅助单元，所以空间复杂度为$O(1)$
时间效率：建堆的时间为$O(n)$，之后有$n-1$次向下调整操作，每次调整的时间复杂度为$O(h)$，其中$h$为完全二叉树的高度，所以堆排序的时间复杂度为$O(nlog_2n)$
稳定性：堆排序是一种==不稳定的==排序方法。
>选择排序都是不稳定的

## 8.5 归并排序和基数排序
### 8.5.1 归并排序
归并排序是将两个或两个以上的有序表合并成一个新的有序表。假定待排序表含有$n$个记录，则可将其视为$n$个有序的子表，每个子表的长度为1，然后两两归并，得到$\lceil n/2 \rceil$个长度为2或1的有序表然后继续两两归并......如此重复，直到合并成一个长度为$n$的有序表为止，这样排序称为2路归并排序。下图展示了一个2路归并的实例：
![Screenshot_2023-07-19-15-47-00-740_com.newskyer.draw.png](../_resources/Screenshot_2023-07-19-15-47-00-740_com.newskyer.dr.png)
2路归并排序算法的性能分析如下：
空间效率：由于`Merge()`操作中，辅助空间刚好为$n$个单元，所以算法的空间复杂度为$O(n)$
时间效率：每趟归并的时间复杂度为$O(n)$，共需进行$\lceil log_2n \rceil$趟归并，所以算法的时间复杂度为$O(nlog_2n)$
稳定性：2路归并排序算法是==稳定的==排序方法
>一般而言，对于$N$个元素进行$k$路归并排序时，排序的趟数$m$满足$k^m=N$，从而$m=log_kN$，所以$m=\lceil log_kN \rceil$
### 8.5.2 基数排序
> 基数排序不是基于比较的排序方法，其适用于：1.数据元素关键字可以方便的拆分为$d$组，且d较小；2.每组关键字的取值范围不大，即$r$较小；3.数据元素个数$n$较大。

假设长度为$n$的线性表中每个结点$a_j$的关键字由$d$元组（$k_j^{d-1},k_j^{d-2},...,k_j^{1},k_j^{0}$，数字有多少位）组成，满足$0 \leq k^i_j \leq r-1$，$r$即为基数，就是每一位能有多少个取值。$k_j^{d-1}$为最高位关键字，$k_j^{0}$为最低位关键字。
基数排序得到递减序列的过程如下：
初始化：设置$r$个空队列，$Q_0,Q_1,...,Q_{r-1}$。
按照各个关键字==权重递增次序==（个，十，百...），依次对$d$个关键字做“分配”和“收集”操作。
分配：顺序扫描每个元素若当前处理的关键字为$=x$，则将该元素插入到$Q_x$队尾。
收集：把$Q_{r-1},...,Q_1,Q_0$各个队列中的结点依次出队并链接得到第二次操作的初始序列（若要得到递增序列，将收集的队列方向取反即可）
下面结合实例说明：
假设对如下10个记录进行排序：
![Screenshot_2023-07-19-16-17-19-080_com.newskyer.draw.png](../_resources/Screenshot_2023-07-19-16-17-19-080_com.newskyer.dr.png)
基数为10，建立10个链队列，第一趟分配用最低位（即个位）进行，注意队头与队尾方向，入队是每次在队尾插入元素，即链表的末端插入，出队时则从链头出队。第一趟分配和收集如下所示：
![Screenshot_2023-07-19-16-20-34-798_com.newskyer.draw.png](../_resources/Screenshot_2023-07-19-16-20-34-798_com.newskyer.dr.png)
第二趟分配使用次低位（即十位）进行，将所有十位相等的记录分配到同一个队列，依次往复，直到第三趟分配和收集后，整个排序结束。
![Screenshot_2023-07-19-16-23-06-982_com.newskyer.draw.png](../_resources/Screenshot_2023-07-19-16-23-06-982_com.newskyer.dr.png)
![Screenshot_2023-07-19-16-23-27-870_com.newskyer.draw.png](../_resources/Screenshot_2023-07-19-16-23-27-870_com.newskyer.dr.png)
基数排序算法的效率分析如下：
空间效率：一趟排序需要辅助空间为$r$个辅助队列，因此基数排序的空间复杂度为$O(r)$
时间效率：基数排序需要进行$d$趟（多少位）分配和收集，一趟分配需要$O(n)$，一趟收集需要$O(r)$，所以基数排序的时间复杂度为$O(d(n+r))$，它与序列的初始状态无关。
稳定性：基数排序是一种==稳定==的排序方法

## 8.6 各种内部排序算法的比较
重点记忆下面的这张对比表
![Screenshot_2023-07-19-16-33-56-220_com.newskyer.draw.png](../_resources/Screenshot_2023-07-19-16-33-56-220_com.newskyer.dr.png)

## 8.7 外部排序
>这里2023年直接考了一个大题10分，考的是置换－选择排序生成初始归并段的过程，24再考的概率不大，但是还是可能出小题，有些很复杂的概念比如败者树这种考了直接给，最佳归并树是比较可能出小题的。
### 8.7.1 外部排序的基本方法
外部排序通常采用归并排序法，其包含两个阶段：1.根据内存缓冲区的大小，将外存上的文件分为若干长度为$l$的子文件，依次读入内存并利用内部排序方法对其进行排序，并将排序后得到的有序子文件重新写回外存，称这些有序字文件为初始归并段（或顺串）；2.对这些归并段进行逐趟归并，使归并段（有序子文件）逐渐由小到大，直至整个文件有序为止。
>这个过程中（二路归并为例，k路归并需要k个输入缓冲区）在内存区至少要开辟三个缓冲区，两个缓冲区用作输入缓冲，一个缓冲区用作输出缓冲，缓冲区大小一般与块大小一致

一般而言：外部排序的总时间=内部排序所需时间+外存信息读取时间+内部归并所需的时间
显然，外存信息读写时间远大于内部排序及归并的时间，因此应尽量减少磁盘的I/O次数。
采用多路归并可以减少归并次数，从而减少磁盘I/O次数
对$r$个初始归并段，做$k$路归并，则归并树可以用$k$叉树来表示，若树高为$h$，则归并趟数$h-1=\lceil log_kr\rceil$
### 8.7.2 多路平衡归并与败者树（太复杂了，考了直接给了）
### 8.7.3 置换-选择排序（生成尽量长的初始归并段）
设初始带排文件$FI$，初始归并段输出文件为$FO$，内存工作区为$WA$，$FO$和$WA$初始为空，$WA$可容纳$w$个记录。置换－选择排序算法步骤如下：
1. 从$FI$输入$w$个记录到工作区$WA$
2. 将$WA$中选出其中关键字取最小值的记录，记为$MINIMAX$记录
3. 将$MINIMAX$记录输出到$FO$中
4. 若$FI$不为空，则从$FI$输入下一个记录到$WA$中。
5. 从$WA$中所有关键字比$MINIMAX$记录的关键字大的记录中选出最小的关键字记录，并将其作为新的$MINIMAX$记录
6. 重复3~5，直到在$WA$中选不出新的$MINIMAX$记录为止（即此时在$WA$中所有关键字值都小于$MINIMAX$记录），由此得到一个初始归并段，输出一个归并段的结束标志到$FO$中
7. 重复2~6，直至$WA$为空。由此得到全部初始归并段。
### 8.7.4 最佳归并树（多叉广义哈夫曼树）
文件经过置换－选择排序后得到的是长度不等的初始归并段，那么如何组织长度不等的初始归并段的归并顺序，使得I/O次数最少？现假设由置换－选择排序得到了9个初始归并段，其长度依次为$\{9,30,12,18,3,17,2,6,24\}$，先进行3路平衡归并，其归并树如下：
![Screenshot_2023-07-19-17-21-52-698_com.newskyer.draw.png](../_resources/Screenshot_2023-07-19-17-21-52-698_com.newskyer.dr.png)
在上图中，树的带权路径长度$WPL$为归并过程中的==总读记录数==，所以$I/O次数=2 \times WPL=484$。显然，这里的归并方案显然不是最佳，$WPL$并非最小，可以借助哈夫曼树的思想，推广到m叉树的情形，利用哈夫曼构造的最佳归并树的$WPL$一定是最小的。
但仍然存在这样的问题，如果初始归并段不足以构成一棵严格的$k$叉树时，为了保证得到最佳归并树，需要添加长度为0的==“虚段”==，按照哈夫曼树的原则，权为0的叶子应该离树根最远。那么如何判定添加虚段的数目？
设度为0的结点有$n_0(=n)$个，度为$k$的结点有$n_k$个，则对严格$k$叉树而言有$k \times n_k+1=n_0+n_k$（严格$k$叉树只有度为0和$k$的结点），由此可得$n_k=(n_0-1)/(k-1)$。
- 若$(n_0-1)\%(k-1)=0$，则说明这$n_0$个叶结点（初始归并段）正好可以构成$k$叉归并树，此时，内结点有$n_k$个。
- 若$(n_0-1)\%(k-1)=u \neq 0$，则说明对于这$n_0$个叶结点，其中有$u$个多余，不能包含在归并树中，为构造包含所有$n_0$个初始归并段的$k$叉归并树，应在原有的$n_k$个内结点的基础上再增加1个内结点，==即再加上==$k-u-1$个空归并段，凑成整除，就可以建立归并树。
比如用8个归并段构成3叉树，$(n_0-1)\%(k-1)=(8-1)\%(3-1)=1$。说明7个归并段刚好可以凑成一个严格3叉树，此时再添加$3-1-1=1$个空归并段，凑成整除，就可以构成一棵严格3叉树。